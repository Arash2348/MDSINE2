<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>mdsine2.logistic_growth API documentation</title>
<meta name="description" content="Logistic growth parameters for the posterior" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mdsine2.logistic_growth</code></h1>
</header>
<section id="section-intro">
<p>Logistic growth parameters for the posterior</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;Logistic growth parameters for the posterior
&#39;&#39;&#39;
import logging
import time
import numpy as np
import os

from .util import expected_n_clusters, build_prior_covariance, build_prior_mean, sample_categorical_log, \
    log_det, pinv
from .perturbations import PerturbationMagnitudes
from .interactions import ClusterInteractionValue
from .names import STRNAMES, STRNAMES

from . import pylab as pl

from . import visualization
import matplotlib.pyplot as plt

class PriorVarMH(pl.variables.SICS):
    &#39;&#39;&#39;This is the posterior for the prior variance of either the growth
    or self-interaction parameter. We update with a MH update since this 
    prior is not conjugate.

    Parameters
    ----------
    prior : pl.variables.SICS
        This is the prior of this distribution - which is a Squared
        Inverse Chi Squared (SICS) distribution
    child_name : str
        This is the name of the variable that this is a prior variance
        for. This is either the name of the growth parameter or the 
        self-interactions parameter
    kwargs : dict
        These are the other parameters for the initialization.
    &#39;&#39;&#39;

    def __init__(self, prior, child_name, **kwargs):
        if child_name == STRNAMES.GROWTH_VALUE:
            kwargs[&#39;name&#39;] = STRNAMES.PRIOR_VAR_GROWTH
        elif child_name == STRNAMES.SELF_INTERACTION_VALUE:
            kwargs[&#39;name&#39;] = STRNAMES.PRIOR_VAR_SELF_INTERACTIONS
        else:
            raise ValueError(&#39;`child_name` ({}) not recognized&#39;.format(child_name))
        pl.variables.SICS.__init__(self, dtype=float, **kwargs)
        self.child_name = child_name
        self.add_prior(prior)
        self.proposal = pl.variables.SICS(dof=None, scale=None, value=None)

    def __str__(self):
        # If this fails, it is because we are dividing by 0 sampler_iter
        # If which case we just return the value 
        try:
            s = &#39;Value: {}, Acceptance rate: {}&#39;.format(
                self.value, np.mean(self.acceptances[
                    np.max([self.sample_iter-50, 0]):self.sample_iter]))
        except:
            s = str(self.value)
        return s

    def initialize(self, value_option, dof_option, scale_option, 
        proposal_option, target_acceptance_rate, tune, end_tune,
        value=None, dof=None, scale=None, proposal_dof=None, delay=0):
        &#39;&#39;&#39;Initialize the parameters of the distribution and the 
        proposal distribution

        Parameters
        ----------
        value_option : str
            Different ways to initialize the values
            Options
                &#39;manual&#39;
                    Set the value manually, `value` must also be specified
                &#39;unregularized&#39;
                    Do unregularized regression and the value is set to the
                    variance of the growth values
                &#39;prior-mean&#39;, &#39;auto&#39;
                    Set the value to the prior of the mean
        scale_option : str
            Different ways to initialize the scale of the prior
            Options
                &#39;manual&#39;
                    Set the value manually, `scale` must also be specified
                &#39;auto&#39;, &#39;inflated-median&#39;
                    We set the scale such that the mean of the prior is
                    equal to the median growth values calculated
                    with linear regression squared and inflated by 100.
        dof_option : str
            How informative the prior should be (setting the dof)
                &#39;diffuse&#39;: set to the mimumum value (2)
                &#39;weak&#39;: set so that 10% of the posterior comes from the prior
                &#39;strong&#39;: set so that 50% of the posterior comes from the prior
                &#39;manual&#39;: set to the value provided in the parameter `shape`
                &#39;auto&#39;: Set to &#39;weak&#39;
        proposal_option : str
            How to set the initial dof of the proposal - this will get adjusted with
            tuning
                &#39;tight&#39;, &#39;auto&#39;
                    Set the dof to be 15, relatively strong initially
                &#39;diffuse&#39;
                    Set the dof to be 2.5, relatively diffuse initially
                &#39;manual&#39;
                    Set the dof with the parameter `proposal_dof&#39;
        target_acceptance_rate : float, str
            This is the target_acceptance rate. Options:
                &#39;auto&#39;, &#39;optimal&#39;
                    Set to 0.44
                float
                    This is the value you want
        tune : str, int
            This is how often you want to update the proposal dof
                int
                &#39;auto&#39;
                    Set to every 50 iterations
        end_tune : str, int
            This is when to stop the tuning
                &#39;half-burnin&#39;, &#39;auto&#39;
                    Half of burnin, rounded down
                int
        delay : int
            How many iterations to delay updating the value of the variance
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Set the proposal dof
        if not pl.isstr(proposal_option):
            raise TypeError(&#39;`proposal_option` ({}) must be a str&#39;.format(
                type(proposal_option)))
        elif proposal_option == &#39;manual&#39;:
            if not pl.isnumeric(proposal_dof):
                raise TypeError(&#39;`proposal_dof` ({}) must be a numeric&#39;.format(
                    type(proposal_dof)))
            if proposal_dof &lt; 2:
                raise ValueError(&#39;`proposal_dof` ({}) not proper&#39;.format(proposal_dof))
        elif proposal_option in [&#39;tight&#39;, &#39;auto&#39;]:
            proposal_dof = 15
        elif proposal_option == &#39;diffuse&#39;:
            proposal_dof = 2.5
        else:
            raise ValueError(&#39;`proposal_option` ({}) not recognized&#39;.format(
                proposal_option))
        self.proposal.dof.value = proposal_dof

        # Set the propsal parameters
        if pl.isstr(target_acceptance_rate):
            if target_acceptance_rate in [&#39;optimal&#39;, &#39;auto&#39;]:
                target_acceptance_rate = 0.44
            else:
                raise ValueError(&#39;`target_acceptance_rate` ({}) not recognized&#39;.format(
                    target_acceptance_rate))
        elif pl.isfloat(target_acceptance_rate):
            if target_acceptance_rate &lt; 0 or target_acceptance_rate &gt; 1:
                raise ValueError(&#39;`target_acceptance_rate` ({}) out of range&#39;.format(
                    target_acceptance_rate))
        else:
            raise TypeError(&#39;`target_acceptance_rate` ({}) type not recognized&#39;.format(
                type(target_acceptance_rate)))
        self.target_acceptance_rate = target_acceptance_rate

        if pl.isstr(tune):
            if tune in [&#39;auto&#39;]:
                tune = 50
            else:
                raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(tune))
        elif pl.isint(tune):
            if tune &lt; 0:
                raise ValueError(&#39;`tune` ({}) must be &gt; 0&#39;.format(
                    tune))
        else:
            raise TypeError(&#39;`tune` ({}) type not recognized&#39;.format(type(tune)))
        self.tune = tune

        if pl.isstr(end_tune):
            if end_tune in [&#39;auto&#39;, &#39;half-burnin&#39;]:
                end_tune = int(self.G.inference.burnin/2)
            else:
                raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(end_tune))
        elif pl.isint(end_tune):
            if end_tune &lt; 0 or end_tune &gt; self.G.inference.burnin:
                raise ValueError(&#39;`end_tune` ({}) out of range (0, {})&#39;.format(
                    end_tune, self.G.inference.burnin))
        else:
            raise TypeError(&#39;`end_tune` ({}) type not recognized&#39;.format(type(end_tune)))
        self.end_tune = end_tune

        # Set the prior dof
        if not pl.isstr(dof_option):
            raise TypeError(&#39;`dof_option` ({}) must be a str&#39;.format(type(dof_option)))
        if dof_option == &#39;manual&#39;:
            if not pl.isnumeric(dof):
                raise TypeError(&#39;`dof` ({}) must be a numeric&#39;.format(type(dof)))
            if dof &lt; 2:
                raise ValueError(&#39;`dof` ({}) must be &gt;= 2&#39;.format(dof))
        elif dof_option == &#39;diffuse&#39;:
            dof = 2.5
        elif dof_option in [&#39;weak&#39;, &#39;auto&#39;]:
            dof = len(self.G.data.asvs)/9
        elif dof_option == &#39;strong&#39;:
            dof = len(self.G.data.asvs)/2
        else:
            raise ValueError(&#39;`dof_option` ({}) not recognized&#39;.format(dof_option))
        if dof &lt; 2:
            raise ValueError(&#39;`dof` ({}) must be strictly larger than 2 to be a proper&#39; \
                &#39; prior&#39;.format(dof))
        self.prior.dof.override_value(dof)

        # Set the prior scale
        if not pl.isstr(scale_option):
            raise TypeError(&#39;`scale_option` ({}) must be a str&#39;.format(type(scale_option)))
        if scale_option == &#39;manual&#39;:
            if not pl.isnumeric(scale):
                raise TypeError(&#39;`scale` ({}) must be a numeric&#39;.format(type(scale)))
            if scale &lt;= 0:
                raise ValueError(&#39;`scale` ({}) must be positive&#39;.format(scale))
        elif scale_option in [&#39;auto&#39;, &#39;inflated-median&#39;]:
            # Perform linear regression
            rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y
            if self.child_name == STRNAMES.GROWTH_VALUE:
                mean = 1e4*(np.median(mean[:self.G.data.n_asvs]) ** 2)
            else:
                mean = 1e4*(np.median(mean[self.G.data.n_asvs:]) ** 2)

            # Calculate the scale
            scale = mean * (self.prior.dof.value - 2) / self.prior.dof.value
        else:
            raise ValueError(&#39;`scale_option` ({}) not recognized&#39;.format(scale_option))
        self.prior.scale.override_value(scale)

        # Set the initial value of the prior
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isnumeric(value):
                raise ValueError(&#39;If `value_option` == &#34;manual&#34;, value ({}) &#39; \
                    &#39;must be a numeric (float, int)&#39;.format(value.__class__))
        elif value_option in [&#39;inflated-median&#39;]:
            # No interactions
            rhs = [
                STRNAMES.GROWTH_VALUE,
                STRNAMES.SELF_INTERACTION_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y
            if self.child_name == STRNAMES.GROWTH_VALUE:
                value = 1e4*(np.median(mean[:self.G.data.n_asvs]) ** 2)
            else:
                value = 1e4*(np.median(mean[self.G.data.n_asvs:]) ** 2)
        elif value_option in [&#39;prior-mean&#39;, &#39;auto&#39;]:
            value = self.prior.mean()
        else:
            raise ValueError(&#39;`value_option` &#34;{}&#34; not recognized&#39;.format(value_option))
        self.value = value

    def update_dof(self):
        &#39;&#39;&#39;Updat the `dof` parameter so that we adjust the acceptance
        rate to `target_acceptance_rate`
        &#39;&#39;&#39;
        if self.sample_iter == 0:
            self.temp_acceptances = 0
            self.acceptances = np.zeros(self.G.inference.n_samples, dtype=bool)
        
        elif self.sample_iter &gt; self.end_tune:
            # Don&#39;t do any more updates
            return
        
        elif self.sample_iter % self.tune == 0:
            # Update dof
            acceptance_rate = self.temp_acceptances / self.tune
            if acceptance_rate &gt; self.target_acceptance_rate:
                self.proposal.dof.value = self.proposal.dof.value * 1.5
            else:
                self.proposal.dof.value = self.proposal.dof.value / 1.5
            self.temp_acceptances = 0

    def update(self):
        &#39;&#39;&#39;First we check if we need to tune the dof, which we do during
        the first half of burnin. We calculate the likelihoods in logspace
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return
        self.update_dof()

        # Get necessary data of the respective parameter
        var = self.G[self.child_name]
        x = var.value.ravel()
        mu = var.prior.mean.value
        low = var.low
        high = var.high

        # propose a new value
        prev_value = self.value
        prev_value_std = math.sqrt(prev_value)
        self.proposal.scale.value = self.value
        new_value = self.proposal.sample() # Sample a new value
        new_value_std = math.sqrt(new_value)

        # Calculate the target distribution ll
        prev_target_ll = 0
        for i in range(len(x)):
            prev_target_ll += pl.random.truncnormal.logpdf(
                value=x[i], mean=mu, std=prev_value_std,
                low=low, high=high)
        new_target_ll = 0
        for i in range(len(x)):
            new_target_ll += pl.random.truncnormal.logpdf(
                value=x[i], mean=mu, std=new_value_std,
                low=low, high=high)

        # Normalize by the ll of the proposal
        prev_prop_ll = self.proposal.logpdf(value=prev_value)
        new_prop_ll = self.proposal.logpdf(value=new_value)

        # Accept or reject
        r = (new_target_ll - prev_prop_ll) - \
            (prev_target_ll - new_prop_ll)
        u = np.log(pl.random.misc.fast_sample_standard_uniform())

        # print(&#39;\n\n\n{} prior_var\n----------&#39;.format(self.child_name))
        # print(&#39;prev_value&#39;, prev_value)
        # print(&#39;prev_target_ll&#39;, prev_target_ll)
        # print(&#39;prev_prop_ll&#39;, prev_prop_ll)
        # print(&#39;new value&#39;, new_value)
        # print(&#39;new_target_ll&#39;, new_target_ll)
        # print(&#39;new_prop_ll&#39;, new_prop_ll)
        # print(&#39;mu&#39;, mu)
        # print(&#39;prev_value_std&#39;, prev_value_std)
        # print(&#39;new_value_std&#39;, new_value_std)
        # print(&#39;\nr&#39;, r, u)

        if r &gt;= u:
            self.acceptances[self.sample_iter] = True
            self.value = new_value
            self.temp_acceptances += 1
        else:
            self.value = prev_value

    def visualize_posterior(self, path, f, section=&#39;posterior&#39;):
        &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
        learned values to the file `f`.

        Parameters
        ----------
        path : str
            This is the path to write the files to
        f : _io.TextIOWrapper
            File that we are writing the values to
        section : str
            Section of the trace to compute on. Options:
                &#39;posterior&#39; : posterior samples
                &#39;burnin&#39; : burn-in samples
                &#39;entire&#39; : both burn-in and posterior samples

        Returns
        -------
        _io.TextIOWrapper
        &#39;&#39;&#39;
        f.write(&#39;\n\n###################################\n&#39;)
        f.write(self.name)
        f.write(&#39;\n###################################\n&#39;)
        if not self.G.inference.tracer.is_being_traced(self):
            f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
            return f
        summ = pl.summary(self, section=section)
        for k,v in summ.items():
            f.write(&#39;\t{}: {}\n&#39;.format(k,v))

        # Plot the traces
        ax1, ax2 = visualization.render_trace(var=self, plt_type=&#39;both&#39;, section=section,
            include_burnin=True, log_scale=True, rasterized=True)

        # Plot the prior over the posterior
        l,h = ax1.get_xlim()
        xs = np.arange(l,h,step=(h-l)/100) 
        ys = []
        for x in xs:
            ys.append(pl.random.sics.pdf(value=x, 
                dof=self.prior.dof.value,
                scale=self.prior.scale.value))
        ax1.plot(xs, ys, label=&#39;prior&#39;, alpha=0.5, color=&#39;red&#39;, rasterized=True)
        ax1.legend()

        # Plot the acceptance rate over the trace
        ax3 = ax2.twinx()
        ax3 = visualization.render_acceptance_rate_trace(var=self, ax=ax3, 
            label=&#39;Acceptance Rate&#39;, color=&#39;red&#39;, scatter=False, rasterized=True)
        ax3.legend()
        fig = plt.gcf()
        fig.tight_layout()
        fig.suptitle(self.name)
        plt.savefig(path)
        plt.close()

        return f


class PriorMeanMH(pl.variables.TruncatedNormal):
    &#39;&#39;&#39;This implements the posterior for the prior mean of the either
    the growths or the self-interactions

    Parameters
    ----------
    &#39;&#39;&#39;
    def __init__(self, prior, child_name, **kwargs):
        if child_name == STRNAMES.GROWTH_VALUE:
            kwargs[&#39;name&#39;] = STRNAMES.PRIOR_MEAN_GROWTH
        elif child_name == STRNAMES.SELF_INTERACTION_VALUE:
            kwargs[&#39;name&#39;] = STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS
        else:
            raise ValueError(&#39;`child_name` ({}) not recognized&#39;.format(child_name))
        pl.variables.TruncatedNormal.__init__(self, mean=None, var=None, dtype=float, **kwargs)
        self.child_name = child_name
        self.add_prior(prior)
        self.proposal = pl.variables.TruncatedNormal(mean=None, var=None, value=None)

    def __str__(self):
        # If this fails, it is because we are dividing by 0 sampler_iter
        # If which case we just return the value 
        try:
            s = &#39;Value: {}, Acceptance rate: {}&#39;.format(
                self.value, np.mean(self.acceptances[
                    np.max([self.sample_iter-50, 0]):self.sample_iter]))
        except:
            s = str(self.value)
        return s

    def initialize(self, value_option, mean_option, var_option,
        truncation_settings, proposal_option, target_acceptance_rate,
        tune, end_tune, value=None, mean=None, var=None, proposal_var=None,
        delay=0):
        &#39;&#39;&#39;These are the parameters to initialize the parameters
        of the class. Depending whether it is a self-interaction
        or a growth, it does it differently.

        Parameters
        ----------
        value_option : str
            How to initialize the value. Options:
                &#39;auto&#39;, &#39;prior-mean&#39;
                    Set to the prior mean
                &#39;linear-regression&#39;
                    Set the values from an unregularized linear regression
                &#39;manual&#39;
                    `value` must also be specified
        truncation_settings: str, tuple
            How to set the truncation parameters. The proposal trucation will
            be set the same way.
                tuple - (low,high)
                    These are the truncation parameters
                &#39;auto&#39;
                    If self-interactions, &#39;negative&#39;. If growths, &#39;positive&#39;
                &#39;positive&#39;
                    (0, \infty)
                &#39;negative&#39;
                    (-\infty, 0)
                &#39;in-vivo&#39;
                    Not implemented
        mean_option : str
            How to set the mean
                &#39;auto&#39;, &#39;median-linear-regression&#39;
                    Set the mean to the median of the values from an
                    unregularized linear-regression
                &#39;manual&#39;
                    `mean` must also be specified
        var_option : str
            How to set the var
                &#39;auto&#39;, &#39;diffuse-linear-regression&#39;
                    Set the var to 10^4 * median(a_l)
                &#39;manaul&#39;
                    `var` must also be specified.
        proposal_option : str
            How to initialize the proposal variance:
                &#39;auto&#39;
                    mean**2 / 100
                &#39;manual&#39;
                    `proposal_var` must also be supplied
        target_acceptance_rate : str, float
            If float, this is the target acceptance rate
            If str: 
                &#39;optimal&#39;, &#39;auto&#39;: 0.44
        tune : str, int
            How often to tune the proposal. If str:
                &#39;auto&#39;: 50
        end_tune : str, int
            When to stop tuning the proposal. If str:
                &#39;auto&#39;, &#39;half-burnin&#39;: Half of burnin
        &#39;&#39;&#39;
        self._there_are_perturbations = self.G.perturbations is not None
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Set the propsal parameters
        if pl.isstr(target_acceptance_rate):
            if target_acceptance_rate in [&#39;optimal&#39;, &#39;auto&#39;]:
                target_acceptance_rate = 0.44
            else:
                raise ValueError(&#39;`target_acceptance_rate` ({}) not recognized&#39;.format(
                    target_acceptance_rate))
        elif pl.isfloat(target_acceptance_rate):
            if target_acceptance_rate &lt; 0 or target_acceptance_rate &gt; 1:
                raise ValueError(&#39;`target_acceptance_rate` ({}) out of range&#39;.format(
                    target_acceptance_rate))
        else:
            raise TypeError(&#39;`target_acceptance_rate` ({}) type not recognized&#39;.format(
                type(target_acceptance_rate)))
        self.target_acceptance_rate = target_acceptance_rate

        if pl.isstr(tune):
            if tune in [&#39;auto&#39;]:
                tune = 50
            else:
                raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(tune))
        elif pl.isint(tune):
            if tune &lt; 0:
                raise ValueError(&#39;`tune` ({}) must be &gt; 0&#39;.format(
                    tune))
        else:
            raise TypeError(&#39;`tune` ({}) type not recognized&#39;.format(type(tune)))
        self.tune = tune

        if pl.isstr(end_tune):
            if end_tune in [&#39;auto&#39;, &#39;half-burnin&#39;]:
                end_tune = int(self.G.inference.burnin/2)
            else:
                raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(end_tune))
        elif pl.isint(end_tune):
            if end_tune &lt; 0 or end_tune &gt; self.G.inference.burnin:
                raise ValueError(&#39;`end_tune` ({}) out of range (0, {})&#39;.format(
                    end_tune, self.G.inference.burnin))
        else:
            raise TypeError(&#39;`end_tune` ({}) type not recognized&#39;.format(type(end_tune)))
        self.end_tune = end_tune

        # Set the truncation settings
        if truncation_settings is None:
            truncation_settings = &#39;positive&#39;
        if pl.isstr(truncation_settings):
            if truncation_settings == &#39;positive&#39;:
                self.low = 0.
                self.high = float(&#39;inf&#39;)
            # elif truncation_settings == &#39;negative&#39;:
            #     self.low = float(&#39;-inf&#39;)
            #     self.high = 0
            elif truncation_settings == &#39;in-vivo&#39;:
                self.low = 0.1
                self.high = np.log(10)
            else:
                raise ValueError(&#39;`truncation_settings` ({}) not recognized&#39;.format(
                    truncation_settings))
        elif pl.istuple(truncation_settings):
            if len(truncation_settings) != 2:
                raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                    &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
            l,h = truncation_settings

            if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
                raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                    type(l), type(h)))
            if l &lt; 0 or h &lt; 0:
                raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
            if h &lt;= l:
                raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
            self.high = h
            self.low = l
        else:
            raise TypeError(&#39;`truncation_settings` ({}) type not recognized&#39;)
        self.proposal.high = self.high
        self.proposal.low = self.low

        # Set the mean
        if not pl.isstr(mean_option):
            raise TypeError(&#39;`mean_option` ({}) must be a str&#39;.format(type(mean_option)))
        if mean_option == &#39;manual&#39;:
            if not pl.isnumeric(mean):
                raise TypeError(&#39;`mean` ({}) must be a numeric&#39;.format(type(mean)))
        elif mean_option in [&#39;auto&#39;, &#39;median-linear-regression&#39;]:
            # Perform linear regression
            if self.child_name == STRNAMES.GROWTH_VALUE:
                rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
                lhs = []
            else:
                rhs = [STRNAMES.SELF_INTERACTION_VALUE]
                lhs = [STRNAMES.GROWTH_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, 
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y

            if self.child_name == STRNAMES.GROWTH_VALUE:
                mean = np.median(mean[:self.G.data.n_asvs])
            else:
                mean = np.median(mean)
        else:
            raise ValueError(&#39;`mean_option` ({}) not recognized&#39;.format(mean_option))
        self.prior.mean.override_value(mean)

        # Set the var
        if not pl.isstr(var_option):
            raise TypeError(&#39;`var_option` ({}) must be a str&#39;.format(type(var_option)))
        if var_option == &#39;manual&#39;:
            if not pl.isnumeric(var):
                raise TypeError(&#39;`var` ({}) must be a numeric&#39;.format(type(var)))
        elif var_option in [&#39;auto&#39;, &#39;diffuse-linear-regression&#39;]:
            # Perform linear regression
            if self.child_name == STRNAMES.GROWTH_VALUE:
                rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
                lhs = []
            else:
                rhs = [STRNAMES.SELF_INTERACTION_VALUE]
                lhs = [STRNAMES.GROWTH_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, 
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y

            if self.child_name == STRNAMES.GROWTH_VALUE:
                mean = np.median(mean[:self.G.data.n_asvs])
            else:
                mean = np.median(mean)
            var = 1e4 * (mean**2)
        else:
            raise ValueError(&#39;`var_option` ({}) not recognized&#39;.format(var_option))
        self.prior.var.override_value(var)

        # Set the value
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isnumeric(value):
                raise TypeError(&#39;`value` ({}) must be a numeric&#39;.format(type(value)))
        elif value_option in [&#39;linear-regression&#39;]:
            # Perform linear regression
            if self.child_name == STRNAMES.GROWTH_VALUE:
                rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
                lhs = []
            else:
                rhs = [STRNAMES.SELF_INTERACTION_VALUE]
                lhs = [STRNAMES.GROWTH_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, 
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y

            if self.child_name == STRNAMES.GROWTH_VALUE:
                value = mean[:self.G.data.n_asvs]
            else:
                value = mean
        elif value_option in [&#39;auto&#39;, &#39;prior-mean&#39;]:
            value = self.prior.mean.value
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
        self.value = value

        # Set the proposal variance
        if not pl.isstr(proposal_option):
            raise TypeError(&#39;`proposal_option` ({}) must be a str&#39;.format(
                type(proposal_option)))
        elif proposal_option == &#39;manual&#39;:
            if not pl.isnumeric(proposal_var):
                raise TypeError(&#39;`proposal_var` ({}) must be a numeric&#39;.format(
                    type(proposal_var)))
            if proposal_var &lt;= 0:
                raise ValueError(&#39;`proposal_var` ({}) not proper&#39;.format(proposal_var))
        elif proposal_option in [&#39;auto&#39;]:
            proposal_var = (self.value ** 2)/10
        else:
            raise ValueError(&#39;`proposal_option` ({}) not recognized&#39;.format(
                proposal_option))
        self.proposal.var.value = proposal_var

    def update_var(self):
        &#39;&#39;&#39;Update the `var` parameter so that we adjust the acceptance
        rate to `target_acceptance_rate`
        &#39;&#39;&#39;
        if self.sample_iter == 0:
            self.temp_acceptances = 0
            self.acceptances = np.zeros(self.G.inference.n_samples, dtype=bool)
        
        elif self.sample_iter &gt; self.end_tune:
            # Don&#39;t do any more updates
            return
        
        elif self.sample_iter % self.tune == 0:
            # Update var
            acceptance_rate = self.temp_acceptances / self.tune
            if acceptance_rate &gt; self.target_acceptance_rate:
                self.proposal.var.value *= 1.5
            else:
                self.proposal.var.value /= 1.5
            self.temp_acceptances = 0

    def update(self):
        &#39;&#39;&#39;First we check if we need to tune the var, which we do during
        the first half of burnin. We calculate the likelihoods in logspace
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return
        self.update_var()
        proposal_std = np.sqrt(self.proposal.var.value)

        # Get necessary data of the respective parameter
        variable = self.G[self.child_name]
        x = variable.value.ravel()
        std = np.sqrt(variable.prior.var.value)

        low = variable.low
        high = variable.high

        # propose a new value for the mean
        prev_mean = self.value
        self.proposal.mean.value = self.value
        new_mean = self.proposal.sample() # Sample a new value

        # Calculate the target distribution ll
        prev_target_ll = pl.random.truncnormal.logpdf( 
            value=prev_mean, mean=self.prior.mean.value, 
            std=np.sqrt(self.prior.var.value), low=self.low,
            high=self.high)
        for i in range(len(x)):
            prev_target_ll += pl.random.truncnormal.logpdf(
                value=x[i], mean=prev_mean, std=std,
                low=low, high=high)
        new_target_ll = pl.random.truncnormal.logpdf( 
            value=new_mean, mean=self.prior.mean.value, 
            std=np.sqrt(self.prior.var.value), low=self.low,
            high=self.high)
        for i in range(len(x)):
            new_target_ll += pl.random.truncnormal.logpdf(
                value=x[i], mean=new_mean, std=std,
                low=low, high=high)

        # Normalize by the ll of the proposal
        prev_prop_ll = pl.random.truncnormal.logpdf(
            value=prev_mean, mean=new_mean, std=proposal_std,
            low=low, high=high)
        
        new_prop_ll = pl.random.truncnormal.logpdf(
            value=new_mean, mean=prev_mean, std=proposal_std,
            low=low, high=high)

        # Accept or reject
        r = (new_target_ll - prev_prop_ll) - \
            (prev_target_ll - new_prop_ll)
        u = np.log(pl.random.misc.fast_sample_standard_uniform())

        # print(&#39;\n\n\n{} prior_mean\n----------&#39;.format(self.child_name))
        # print(&#39;x&#39;, x)
        # print(&#39;prev_mean&#39;, prev_mean)
        # print(&#39;prev_target_ll&#39;, prev_target_ll)
        # print(&#39;prev_prop_ll&#39;, prev_prop_ll)
        # print(&#39;new mean&#39;, new_mean)
        # print(&#39;new_target_ll&#39;, new_target_ll)
        # print(&#39;new_prop_ll&#39;, new_prop_ll)
        # print(&#39;\nr&#39;, r, u)

        if r &gt;= u:
            self.acceptances[self.sample_iter] = True
            self.value = new_mean
            self.temp_acceptances += 1
        else:
            self.value = prev_mean

    def visualize_posterior(self, path, f, section=&#39;posterior&#39;):
        &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
        learned values to the file `f`.

        Parameters
        ----------
        path : str
            This is the path to write the files to
        f : _io.TextIOWrapper
            File that we are writing the values to
        section : str
            Section of the trace to compute on. Options:
                &#39;posterior&#39; : posterior samples
                &#39;burnin&#39; : burn-in samples
                &#39;entire&#39; : both burn-in and posterior samples

        Returns
        -------
        _io.TextIOWrapper
        &#39;&#39;&#39;
        f.write(&#39;\n\n###################################\n&#39;)
        f.write(self.name)
        f.write(&#39;\n###################################\n&#39;)
        if not self.G.inference.tracer.is_being_traced(self):
            f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
            return f
        summ = pl.summary(self, section=section)
        for k,v in summ.items():
            f.write(&#39;\t{}: {}\n&#39;.format(k,v))

        # Plot the traces
        ax1, ax2 = visualization.render_trace(var=self, plt_type=&#39;both&#39;, section=section,
            include_burnin=True, log_scale=True, rasterized=True)

        # Plot the prior over the posterior
        l,h = ax1.get_xlim()
        xs = np.arange(l,h,step=(h-l)/100) 
        ys = []
        for x in xs:
            ys.append(pl.random.sics.pdf(value=x, 
                dof=self.prior.dof.value,
                scale=self.prior.scale.value))
        ax1.plot(xs, ys, label=&#39;prior&#39;, alpha=0.5, color=&#39;red&#39;, rasterized=True)
        ax1.legend()

        # Plot the acceptance rate over the trace
        ax3 = ax2.twinx()
        ax3 = visualization.render_acceptance_rate_trace(var=self, ax=ax3, 
            label=&#39;Acceptance Rate&#39;, color=&#39;red&#39;, scatter=False, rasterized=True)
        ax3.legend()
        fig = plt.gcf()
        fig.tight_layout()
        fig.suptitle(self.name)
        plt.savefig(path)
        plt.close()

        return f


class Growth(pl.variables.TruncatedNormal):
    &#39;&#39;&#39;Growth values of Lotka-Voltera
    &#39;&#39;&#39;
    def __init__(self, prior, **kwargs):
        kwargs[&#39;name&#39;] = STRNAMES.GROWTH_VALUE
        pl.variables.TruncatedNormal.__init__(self, mean=None, var=None, low=0.,
            high=float(&#39;inf&#39;), dtype=float, **kwargs)
        self.set_value_shape(shape=(len(self.G.data.asvs),))
        self.add_prior(prior)
        self.delay = 0
        self._initialized = False

    def __str__(self):
        return str(self.value)

    def update_str(self):
        return

    def initialize(self, value_option, truncation_settings,
        value=None, delay=0, mean=None):
        &#39;&#39;&#39;Initialize the growth values and hyperparamters

        Parameters
        ----------
        value_option : str
            How to initialize the values.
            Options:
                &#39;manual&#39;
                    Set the values manually. `value` must also be specified.
                &#39;linear regression&#39;
                    Set the values of the growth using linear regression
                &#39;ones&#39;
                    Set all of the values to 1.
                &#39;auto&#39;
                    Alias for &#39;ones&#39;
                &#39;prior-mean&#39;
                    Set to the mean of the prior
        value : array
            Only necessary if `value_option` is &#39;manual&#39;
        delay : int
            How many MCMC iterations to delay starting to update
        truncation_settings : str, tuple, None
            These are the settings of how you set the upper and lower limit of the
            truncated distribution. If it is None, it will default to &#39;standard&#39;.
            Options
                &#39;positive&#39;, None
                    Only constrains the values to being positive
                    low=0., high=float(&#39;inf&#39;)
                &#39;in-vivo&#39;, &#39;auto&#39;
                    Tighter constraint on the growth values.
                    low=0.1, high=ln(10)
                    These values have the following meaning
                        The slowest growing microbe will grow an order of magnitude in ~10 days
                        The fastest growing microbe will grow an order of magnitude in 1 day
                tuple(low, high)
                    These are manually specified values for the low and high
        &#39;&#39;&#39;
        self._initialized = True
        self._there_are_perturbations = self.G.perturbations is not None
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Truncation settings
        if truncation_settings is None:
            truncation_settings = &#39;positive&#39;
        if pl.isstr(truncation_settings):
            if truncation_settings == &#39;positive&#39;:
                self.low = 0.
                self.high = float(&#39;inf&#39;)
            elif truncation_settings in [&#39;in-vivo&#39;, &#39;auto&#39;]:
                self.low = 0.1
                self.high = math.log(10)
            else:
                raise ValueError(&#39;`truncation_settings` ({}) not recognized&#39;.format(
                    truncation_settings))
        elif pl.istuple(truncation_settings):
            if len(truncation_settings) != 2:
                raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                    &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
            l,h = truncation_settings

            if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
                raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                    type(l), type(h)))
            if l &lt; 0 or h &lt; 0:
                raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
            if h &lt;= l:
                raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
            self.high = h
            self.low = l
        else:
            raise TypeError(&#39;`truncation_settings` ({}) type not recognized&#39;)

        # Setting the value
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isarray(value):
                value = np.ones(len(self.G.data.asvs))*value
            if len(value) != self.G.data.n_asvs:
                raise ValueError(&#39;`value` ({}) must be ({}) long&#39;.format(
                    len(value), len(self.G.data.asvs)))
            self.value = value
        elif value_option == &#39;linear-regression&#39;:
            rhs = [
                STRNAMES.GROWTH_VALUE,
                STRNAMES.SELF_INTERACTION_VALUE
            ]
            lhs = []
            X = self.G.data.construct_rhs(
                keys=rhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = (cov @ X.transpose().dot(y)).ravel()
            self.value = np.absolute(mean[:len(self.G.data.asvs)])
        elif value_option in [&#39;auto&#39;, &#39;ones&#39;]:
            self.value = np.ones(len(self.G.data.asvs), dtype=float)
        elif value_option == &#39;prior-mean&#39;:
            self.value = self.prior.mean.value * np.ones(self.G.data.n_asvs)
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

        logging.info(&#39;Growth value initialization: {}&#39;.format(self.value))
        logging.info(&#39;Growth prior mean: {}&#39;.format(self.prior.mean.value))
        logging.info(&#39;Growth truncation settings: {}&#39;.format((self.low, self.high)))

    def update(self):
        &#39;&#39;&#39;Update the values using a truncated normal
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return

        self.calculate_posterior()
        self.sample()

        if not pl.isarray(self.value):
            # This will happen if there is 1 ASV
            self.value = np.array([self.value])

        if np.any(np.isnan(self.value)):
            logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
            logging.critical(&#39;var: {}&#39;.format(self.var.value))
            logging.critical(&#39;value: {}&#39;.format(self.value))
            raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))

        if self._there_are_perturbations:
            # If there are perturbations then we need to update their
            # matrix because the growths changed
            self.G.data.design_matrices[STRNAMES.PERT_VALUE].update_values()

    def calculate_posterior(self):
        rhs = [STRNAMES.GROWTH_VALUE]
        if self._there_are_perturbations:
            lhs = [
                STRNAMES.SELF_INTERACTION_VALUE,
                STRNAMES.CLUSTER_INTERACTION_VALUE]
        else:
            lhs = [
                STRNAMES.SELF_INTERACTION_VALUE,
                STRNAMES.CLUSTER_INTERACTION_VALUE]
        X = self.G.data.construct_rhs(keys=rhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{
                &#39;with_perturbations&#39;:self._there_are_perturbations}})
        y = self.G.data.construct_lhs(keys=lhs)
        # X = X.toarray()

        process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
            cov=False, sparse=True)

        prior_prec = build_prior_covariance(G=self.G, cov=False,
            order=rhs, sparse=True)
        prior_mean = build_prior_mean(G=self.G, order=rhs).reshape(-1,1)
        pm = prior_prec @ prior_mean

        prec = X.T @ process_prec @ X + prior_prec
        cov = pinv(prec, self)

        self.mean.value = np.asarray(cov @ (X.T @ process_prec.dot(y) + pm)).ravel()
        self.var.value = np.diag(cov)

    def visualize_posterior(self, basepath, f, section=&#39;posterior&#39;, asv_formatter=&#39;%(name)s&#39;, 
        true_value=None):
        &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
        learned values to the file `f`.

        Parameters
        ----------
        basepath : str
            This is the loction to write the files to
        f : _io.TextIOWrapper
            File that we are writing the values to
        section : str
            Section of the trace to compute on. Options:
                &#39;posterior&#39; : posterior samples
                &#39;burnin&#39; : burn-in samples
                &#39;entire&#39; : both burn-in and posterior samples
        true_value : np.ndarray
            Ground truth values of the variable

        Returns
        -------
        _io.TextIOWrapper
        &#39;&#39;&#39;
        f.write(&#39;\n\n###################################\n&#39;)
        f.write(self.name)
        f.write(&#39;\n###################################\n&#39;)
        if not self.G.inference.tracer.is_being_traced(self):
            f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
            return f

        asvs = self.G.data.subjects.asvs
        summ = pl.summary(self, section=section)
        for key,arr in summ.items():
            f.write(&#39;{}\n&#39;.format(key))
            for idx,ele in enumerate(arr):
                prefix = &#39;&#39;
                if asv_formatter is not None:
                    prefix = pl.asvname_formatter(format=asv_formatter, asv=asvs[idx], asvs=asvs)
                f.write(&#39;\t&#39; + prefix + &#39;{}\n&#39;.format(ele)) 

        if section == &#39;posterior&#39;:
            len_posterior = self.G.inference.sample_iter + 1 - self.G.inference.burnin
        elif section == &#39;burnin&#39;:
            len_posterior = self.G.inference.burnin
        else:
            len_posterior = self.G.inference.sample_iter + 1

        # Plot the prior on top of the posterior
        if self.G.tracer.is_being_traced(STRNAMES.PRIOR_MEAN_GROWTH):
            prior_mean_trace = self.G[STRNAMES.PRIOR_MEAN_GROWTH].get_trace_from_disk(
                    section=section)
        else:
            prior_mean_trace = self.prior.mean.value * np.ones(len_posterior, dtype=float)
        if self.G.tracer.is_being_traced(STRNAMES.PRIOR_VAR_GROWTH):
            prior_std_trace = np.sqrt(
                self.G[STRNAMES.PRIOR_VAR_GROWTH].get_trace_from_disk(section=section))
        else:
            prior_std_trace = np.sqrt(self.prior.var.value) * np.ones(len_posterior, dtype=float)

        for idx in range(len(asvs)):
            fig = plt.figure()
            ax_posterior = fig.add_subplot(1,2,1)
            visualization.render_trace(var=self, idx=idx, plt_type=&#39;hist&#39;,
                label=section, color=&#39;blue&#39;, ax=ax_posterior, section=section,
                include_burnin=True, rasterized=True)

            # Get the limits and only look at the posterior within 20% range +- of
            # this number
            low_x, high_x = ax_posterior.get_xlim()

            arr = np.zeros(len(prior_std_trace), dtype=float)
            for i in range(len(prior_std_trace)):
                arr[i] = pl.random.truncnormal.sample(mean=prior_mean_trace[i], std=prior_std_trace[i], 
                    low=self.low, high=self.high)
            visualization.render_trace(var=arr, plt_type=&#39;hist&#39;, 
                label=&#39;prior&#39;, color=&#39;red&#39;, ax=ax_posterior, rasterized=True)

            if true_value is not None:
                ax_posterior.axvline(x=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                    label=&#39;True Value&#39;)

            ax_posterior.legend()
            ax_posterior.set_xlim(left=low_x*.8, right=high_x*1.2)

            # plot the trace
            ax_trace = fig.add_subplot(1,2,2)
            visualization.render_trace(var=self, idx=idx, plt_type=&#39;trace&#39;, 
                ax=ax_trace, section=section, include_burnin=True, rasterized=True)

            if true_value is not None:
                ax_trace.axhline(y=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                    label=&#39;True Value&#39;)
                ax_trace.legend()

            if asv_formatter is not None:
                asvname = pl.asvname_formatter(
                    format=asv_formatter,
                    asv=asvs[idx],
                    asvs=asvs)
            else:
                asvname = asvs[idx].name
            asvname = asvname.replace(&#39;/&#39;, &#39;_&#39;).replace(&#39; &#39;, &#39;_&#39;)

            fig.suptitle(&#39;Growth {}&#39;.format(asvname))
            fig.tight_layout()
            fig.subplots_adjust(top=0.85)
            plt.savefig(basepath + &#39;{}.pdf&#39;.format(asvs[idx].name))
            plt.close()

        return f


class SelfInteractions(pl.variables.TruncatedNormal):
    &#39;&#39;&#39;self-interactions of Lotka-Voltera

    Since our dynamics subtract this parameter, this parameter must be positive
    &#39;&#39;&#39;
    def __init__(self, prior, **kwargs):
        kwargs[&#39;name&#39;] = STRNAMES.SELF_INTERACTION_VALUE
        pl.variables.TruncatedNormal.__init__(self, mean=None, var=None, low=0.,
            high=float(&#39;inf&#39;), dtype=float, **kwargs)
        self.set_value_shape(shape=(len(self.G.data.asvs),))
        self.add_prior(prior)

    def __str__(self):
        return str(self.value)

    def update_str(self):
        return

    def initialize(self, value_option, truncation_settings,
        value=None, delay=0, mean=None, q=None, rescale_value=None):
        &#39;&#39;&#39;Initialize the self-interactions values and hyperparamters

        Parameters
        ----------
        value_option : str
            How to initialize the values.
            Options:
               &#39;manual&#39;
                    Set the values manually. `value` must also be specified.
                &#39;fixed-growth&#39;
                    Fix the growth values and then sample the self-interactions
                &#39;strict-enforcement-partial&#39;
                    Do an unregularized regression then take the absolute value of the numbers.
                    We assume there are no interactions and we index out the time points that have
                    perturbations in them. We assume that we do not know the growths (the growths
                    are being regressed as well).
                &#39;strict-enforcement-full&#39;
                    Do an unregularized regression then take the absolute value of the numbers.
                    We assume there are no interactions and we index out the time points that have
                    perturbations in them. We assume that we know the growths (the growths are on
                    the lhs)
                &#39;steady-state&#39;, &#39;auto&#39;
                    Set to the steady state values. Must also provide the quantile with the
                    parameter `q`. In here we assume that the steady state is the `q`th quantile
                    of the off perturbation data
                &#39;prior-mean&#39;
                    Set the value to the mean of the prior
        truncation_settings : str, 2-tuple
            How to set the truncations for the normal distribution
            (low,high)
                These are the low and high values
            &#39;negative&#39;
                Truncated (-inf, 0)
            &#39;positive&#39;, &#39;auto&#39;
                Truncated (0, inf)
            &#39;human&#39;
                This assumes that the range of the steady state abundances of the human gut
                fluctuate between 1e2 and  1e13. We requie that the growth value be initialized first.
                We set the vlaues to be (growth.high/1e14, growth.low/1e2)
            &#39;mouse&#39;
                This assumes that the range of the steady state abundances of the mouse gut
                fluctuate between 1e2 and  1e12. We requie that the growth value be initialized first.
                We set the vlaues to be (growth.high/1e13, growth.low/1e2)
        value : array
            Only necessary if `value_option` is &#39;manual&#39;
        mean : array
            Only necessary if `mean_option` is &#39;manual&#39;
        delay : int
            How many MCMC iterations to delay starting to update
        rescale_value : None, float
            This is the rescale value of the qPCR. This will rescale the truncation settings.
            This is only used for either the &#39;mouse&#39; or &#39;human&#39; settings
        &#39;&#39;&#39;
        self._there_are_perturbations = self.G.perturbations is not None
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Set truncation settings
        if pl.isstr(truncation_settings):
            # if truncation_settings == &#39;negative&#39;:
            #     self.low = float(&#39;-inf&#39;)
            #     self.high= 0
            if truncation_settings in [&#39;mouse&#39;, &#39;human&#39;]:
                growth = self.G[STRNAMES.GROWTH_VALUE]
                if not growth._initialized:
                    raise ValueError(&#39;Growth values `{}` must be initialized first&#39;.format(
                        STRNAMES.GROWTH_VALUE))
                if truncation_settings == &#39;mouse&#39;:
                    high = 1e13
                else:
                    high = 1e14
                low = 1e2
                if rescale_value is not None:
                    if not pl.isnumeric(rescale_value):
                        raise TypeError(&#39;`rescale_value` ({}) must be a numeric&#39;.format(
                            type(rescale_value)))
                    if rescale_value &lt;= 0:
                        raise ValueError(&#39;`rescale_value` ({}) must be &gt; 0&#39;.format(rescale_value))
                    high *= rescale_value
                    low *= rescale_value
                self.low = growth.high/low
                self.high = growth.low/high
            elif truncation_settings in [&#39;auto&#39;, &#39;positive&#39;]:
                self.low = 0
                self.high = float(&#39;inf&#39;)
            else:
                raise ValueError(&#39;`truncation_settings) ({}) not recognized&#39;.format(
                    truncation_settings))
        elif pl.istuple(truncation_settings):
            if len(truncation_settings) != 2:
                raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                    &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
            l,h = truncation_settings

            if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
                raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                    type(l), type(h)))
            if l &lt; 0 or h &lt; 0:
                raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
            if h &lt;= l:
                raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
            self.high = h
            self.low = l
        else:
            raise TypeError(&#39;`truncation_settings` ({}) must be a tuple or str&#39;.format(
                type(truncation_settings)))

        # Set value option
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isarray(value):
                value = np.ones(len(self.G.data.asvs))*value
            if len(value) != self.G.data.n_asvs:
                raise ValueError(&#39;`value` ({}) must be ({}) long&#39;.format(
                    len(value), len(self.G.data.asvs)))
            self.value = value
        elif value_option == &#39;fixed-growth&#39;:
            X = self.G.data.construct_rhs(keys=[STRNAMES.SELF_INTERACTION_VALUE],
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=[STRNAMES.GROWTH_VALUE], kwargs_dict={
                STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            prec = X.T @ X
            cov = pinv(prec, self)
            self.value = np.absolute((cov @ X.transpose().dot(y)).ravel())
        elif &#39;strict-enforcement&#39; in value_option:
            if &#39;full&#39; in value_option:
                rhs = [STRNAMES.SELF_INTERACTION_VALUE]
                lhs = [STRNAMES.GROWTH_VALUE]
            elif &#39;partial&#39; in value_option:
                lhs = []
                rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            else:
                raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
            X = self.G.data.construct_rhs(
                keys=rhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = (cov @ X.transpose().dot(y)).ravel()
            self.value = np.absolute(mean[len(self.G.data.asvs):])
        elif value_option == &#39;prior-mean&#39;:
            self.value = self.prior.mean.value * np.ones(self.G.data.n_asvs)
        elif value_option in [&#39;steady-state&#39;, &#39;auto&#39;]:
            # check quantile
            if not pl.isnumeric(q):
                raise TypeError(&#39;`q` ({}) must be numeric&#39;.format(type(q)))
            if q &lt; 0 or q &gt; 1:
                raise ValueError(&#39;`q` ({}) must be [0,1]&#39;.format(q))

            # Get the data off perturbation
            datas = None
            for ridx in range(self.G.data.n_replicates):
                if self._there_are_perturbations:
                    # Exclude the data thats in a perturbation
                    base_idx = 0
                    for start,end in self.G.data.tidxs_in_perturbation[ridx]:
                        if datas is None:
                            datas = self.G.data.data[ridx][:,base_idx:start]
                        else:
                            datas = np.hstack((datas, self.G.data.data[ridx][:,base_idx:start]))
                        base_idx = end
                    if end != self.G.data.data[ridx].shape[1]:
                        datas = np.hstack((datas, self.G.data.data[ridx][:,base_idx:]))
                else:
                    if datas is None:
                        datas = self.G.data.data[ridx]
                    else:
                        datas = np.hstack((datas, self.G.data.data[ridx]))

            # Set the steady-state for each ASV
            ss = np.quantile(datas, q=q, axis=1)

            # Get the self-interactions by using the values of the growth terms
            self.value = 1/ss
        elif value_option == &#39;linear-regression&#39;:
            
            rhs = [STRNAMES.SELF_INTERACTION_VALUE]
            lhs = [STRNAMES.GROWTH_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}})

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y
            self.value = np.asarray(mean).ravel()
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

        logging.info(&#39;Self-interactions value initialization: {}&#39;.format(self.value))
        logging.info(&#39;Self-interactions truncation settings: {}&#39;.format((self.low, self.high)))

    def update(self):
        if self.sample_iter &lt; self.delay:
            return

        self.calculate_posterior()
        self.sample()

        if not pl.isarray(self.value):
            # This will happen if there is 1 ASV
            self.value = np.array([self.value])

        if np.any(np.isnan(self.value)):
            logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
            logging.critical(&#39;var: {}&#39;.format(self.var.value))
            logging.critical(&#39;value: {}&#39;.format(self.value))
            raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))

    def calculate_posterior(self):

        rhs = [STRNAMES.SELF_INTERACTION_VALUE]
        if self._there_are_perturbations:
            lhs = [
                STRNAMES.GROWTH_VALUE,
                STRNAMES.CLUSTER_INTERACTION_VALUE]
        else:
            lhs = [
                STRNAMES.GROWTH_VALUE,
                STRNAMES.CLUSTER_INTERACTION_VALUE]
        X = self.G.data.construct_rhs(keys=rhs)
        y = self.G.data.construct_lhs(keys=lhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{
                &#39;with_perturbations&#39;:self._there_are_perturbations}})
        process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
            cov=False, sparse=True)
        prior_prec = build_prior_covariance(G=self.G, cov=False,
            order=rhs, sparse=True)

        pm = prior_prec @ (self.prior.mean.value * np.ones(self.G.data.n_asvs).reshape(-1,1))

        prec = X.T @ process_prec @ X + prior_prec
        cov = pinv(prec, self)
        self.mean.value = np.asarray(cov @ (X.T @ process_prec.dot(y) + pm)).ravel()
        self.var.value = np.diag(cov)

    def visualize_posterior(self, basepath, f, section=&#39;posterior&#39;, asv_formatter=&#39;%(name)s&#39;, 
        true_value=None):
        &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
        learned values to the file `f`.

        Parameters
        ----------
        basepath : str
            This is the loction to write the files to
        f : _io.TextIOWrapper
            File that we are writing the values to
        section : str
            Section of the trace to compute on. Options:
                &#39;posterior&#39; : posterior samples
                &#39;burnin&#39; : burn-in samples
                &#39;entire&#39; : both burn-in and posterior samples
        true_value : np.ndarray
            Ground truth values of the variable

        Returns
        -------
        _io.TextIOWrapper
        &#39;&#39;&#39;
        f.write(&#39;\n\n###################################\n&#39;)
        f.write(self.name)
        f.write(&#39;\n###################################\n&#39;)
        if not self.G.inference.tracer.is_being_traced(self):
            f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
            return f

        asvs = self.G.data.subjects.asvs
        summ = pl.summary(self, section=section)
        for key,arr in summ.items():
            f.write(&#39;{}\n&#39;.format(key))
            for idx,ele in enumerate(arr):
                prefix = &#39;&#39;
                if asv_formatter is not None:
                    prefix = pl.asvname_formatter(format=asv_formatter, asv=asvs[idx], asvs=asvs)
                f.write(&#39;\t&#39; + prefix + &#39;{}\n&#39;.format(ele)) 

        if section == &#39;posterior&#39;:
            len_posterior = self.G.inference.sample_iter + 1 - self.G.inference.burnin
        elif section == &#39;burnin&#39;:
            len_posterior = self.G.inference.burnin
        else:
            len_posterior = self.G.inference.sample_iter + 1

        # Plot the prior on top of the posterior
        if self.G.tracer.is_being_traced(STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS):
            prior_mean_trace = self.G[STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS].get_trace_from_disk(
                    section=section)
        else:
            prior_mean_trace = self.prior.mean.value * np.ones(len_posterior, dtype=float)
        if self.G.tracer.is_being_traced(STRNAMES.PRIOR_VAR_SELF_INTERACTIONS):
            prior_std_trace = np.sqrt(
                self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].get_trace_from_disk(section=section))
        else:
            prior_std_trace = np.sqrt(self.prior.var.value) * np.ones(len_posterior, dtype=float)

        for idx in range(len(asvs)):
            fig = plt.figure()
            ax_posterior = fig.add_subplot(1,2,1)
            visualization.render_trace(var=self, idx=idx, plt_type=&#39;hist&#39;,
                label=section, color=&#39;blue&#39;, ax=ax_posterior, section=section,
                include_burnin=True, rasterized=True, log_scale=True)

            # Get the limits and only look at the posterior within 20% range +- of
            # this number
            low_x, high_x = ax_posterior.get_xlim()

            arr = np.zeros(len(prior_std_trace), dtype=float)
            for i in range(len(prior_std_trace)):
                arr[i] = pl.random.truncnormal.sample(mean=prior_mean_trace[i], std=prior_std_trace[i], 
                    low=self.low, high=self.high)
            visualization.render_trace(var=arr, plt_type=&#39;hist&#39;, log_scale=True,
                label=&#39;prior&#39;, color=&#39;red&#39;, ax=ax_posterior, rasterized=True)

            if true_value is not None:
                ax_posterior.axvline(x=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                    label=&#39;True Value&#39;)

            ax_posterior.legend()
            ax_posterior.set_xlim(left=low_x*.8, right=high_x*1.2)

            # plot the trace
            ax_trace = fig.add_subplot(1,2,2)
            visualization.render_trace(var=self, idx=idx, plt_type=&#39;trace&#39;, 
                ax=ax_trace, section=section, include_burnin=True, rasterized=True,
                log_scale=True)

            if true_value is not None:
                ax_trace.axhline(y=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                    label=&#39;True Value&#39;)
                ax_trace.legend()

            if asv_formatter is not None:
                asvname = pl.asvname_formatter(
                    format=asv_formatter,
                    asv=asvs[idx],
                    asvs=asvs)
            else:
                asvname = asvs[idx].name
            asvname = asvname.replace(&#39;/&#39;, &#39;_&#39;).replace(&#39; &#39;, &#39;_&#39;)

            fig.suptitle(&#39;Self-Interactions {}&#39;.format(asvname))
            fig.tight_layout()
            fig.subplots_adjust(top=0.85)
            plt.savefig(basepath + &#39;{}.pdf&#39;.format(asvs[idx].name))
            plt.close()

        return f
    

class RegressCoeff(pl.variables.MVN):
    &#39;&#39;&#39;This is the posterior of the regression coefficients.
    The current posterior assumes a prior mean of 0.

    This class samples the growth, self-interactions, and cluster
    interactions jointly.

    Parameters
    ----------
    growth : posterior.Growth
        This is the class that has the growth variables
    self_interactions : posterior.SelfInteractions
        The self interaction terms for the ASVs
    interactions : ClusterInteractionValue
        These are the cluster interaction values
    pert_mag : PerturbationMagnitudes, None
        These are the magnitudes of the perturbation parameters (per clsuter)
        Set to None if there are no perturbations
    &#39;&#39;&#39;
    def __init__(self, growth, self_interactions, interactions,
        pert_mag, **kwargs):

        if not issubclass(growth.__class__, Growth):
            raise ValueError(&#39;`growth` ({}) must be a subclass of the Growth &#39; \
                &#39;class&#39;.format(type(growth)))
        if not issubclass(self_interactions.__class__, SelfInteractions):
            raise ValueError(&#39;`self_interactions` ({}) must be a subclass of the SelfInteractions &#39; \
                &#39;class&#39;.format(type(self_interactions)))
        if not issubclass(interactions.__class__, ClusterInteractionValue):
            raise ValueError(&#39;`interactions` ({}) must be a subclass of the Interactions &#39; \
                &#39;class&#39;.format(type(interactions)))
        if pert_mag is not None:
            if not issubclass(pert_mag.__class__, PerturbationMagnitudes):
                raise ValueError(&#39;`pert_mag` ({}) must be a subclass of the PerturbationMagnitudes &#39; \
                    &#39;class&#39;.format(type(pert_mag)))


        kwargs[&#39;name&#39;] = STRNAMES.GLV_PARAMETERS
        pl.variables.MVN.__init__(self, mean=None, cov=None, dtype=float, **kwargs)

        self.n_asvs = self.G.data.n_asvs
        self.growth = growth
        self.self_interactions = self_interactions
        self.interactions = interactions
        self.pert_mag = pert_mag
        self.clustering = interactions.clustering

        # These serve no functional purpose but we do it so that they are
        # connected in the graph structure. Each of these should have their
        # prior already initialized
        self.add_parent(self.growth)
        self.add_parent(self.self_interactions)
        self.add_parent(self.interactions)

    def __str__(self):
        &#39;&#39;&#39;Make it more readable
        &#39;&#39;&#39;
        try:
            a = &#39;Growth:\n{}\nSelf Interactions:\n{}\nInteractions:\n{}\nPerturbations:\n{}\n&#39; \
                &#39;Acceptances:\n{}&#39;.format(
                self.growth.value, self.self_interactions.value,
                str(self.G[STRNAMES.CLUSTER_INTERACTION_VALUE]),
                str(self.pert_mag), np.mean(
                    self.acceptances[ np.max([self.sample_iter-50, 0]):self.sample_iter], axis=0))
        except:
            a = &#39;Growth:\n{}\nSelf Interactions:\n{}\nInteractions:\n{}\nPerturbations:\n{}&#39;.format(
                self.growth.value, self.self_interactions.value,
                str(self.G[STRNAMES.CLUSTER_INTERACTION_VALUE]),
                str(self.pert_mag))
        return a

    def initialize(self, update_jointly_pert_inter, update_jointly_growth_si, 
        tune=None, end_tune=None):
        &#39;&#39;&#39;The interior objects are initialized by themselves. Define which variables
        get updated together.

        Note that the interactions and perturbations will always be updated before the
        growth rates and the self-interactions

        Interactions and perturbations
        ------------------------------
        These are conjugate and have a normal prior. If these are said to be updated
        jointly then we can sample directly with Gibbs sampling.

        Growths and self-interactions
        -----------------------------
        These are conjugate and have a truncated normal prior. If they are set to be 
        updated together, then we must do MH because we cannot sample from a truncated
        multivariate gaussian.

        Parameters
        ----------
        update_jointly_pert_inter : bool
            If True, update the interactions and the perturbations jointly.
            If False, update the interactions and perturbations separately - you
            randomly choose which one to update first.
        update_jointly_growth_si : bool
            If True, update the interactions and the perturbations jointly.
            If False, update the interactions and perturbations separately - you
            randomly choose which one to update first.
        &#39;&#39;&#39;
        self._there_are_perturbations = self.G.perturbations is not None
        if not pl.isbool(update_jointly_growth_si):
            raise TypeError(&#39;`update_jointly_growth_si` ({}) must be a bool&#39;.format(
                type(update_jointly_growth_si)))
        if not pl.isbool(update_jointly_pert_inter):
            raise TypeError(&#39;`update_jointly_pert_inter` ({}) must be a bool&#39;.format(
                type(update_jointly_pert_inter)))

        self.update_jointly_growth_si = update_jointly_growth_si
        self.update_jointly_pert_inter = update_jointly_pert_inter
        self.sample_iter = 0

        if self.update_jointly_growth_si:
            raise NotImplementedError(&#39;Not Implemented&#39;)
                
    # @profile
    def asarray(self):
        &#39;&#39;&#39;
        Builds the full regression coefficient vector. If `asv_id` and
        `cid` are None, build the entire thing. Else build it for
        the ASV or cluster specifically.

        Parameters
        ----------
        &#39;&#39;&#39;
        # build the entire thing
        a = np.append(self.growth.value, self.self_interactions.value)
        a = np.append(a, self.interactions.obj.get_values(use_indicators=True))
        return a

    def update(self):
        &#39;&#39;&#39;Either updated jointly using multivariate normal or update independently
        using truncated normal distributions for growth and self-interactions.

        Always update the one that the interactions is in first
        &#39;&#39;&#39;
        self._update_perts_and_inter()
        if self._there_are_perturbations:
            self.G.data.design_matrices[STRNAMES.GROWTH_VALUE].build_with_perturbations()
        
        self._update_growth_and_self_interactions()
        self.sample_iter += 1

        if self._there_are_perturbations:
            # If there are perturbations then we need to update their
            # matrix because the growths changed
            self.G.data.design_matrices[STRNAMES.PERT_VALUE].update_values()

    # @profile
    def _update_perts_and_inter(self):
        &#39;&#39;&#39;Update the with Gibbs sampling of a multivariate normal.

        Parameters
        ----------
        args : tuple
            This is a tuple of length &gt; 1 that holds the variables on what to update
            together
        &#39;&#39;&#39;
        if not self.update_jointly_pert_inter:
            # Update separately
            if pl.random.misc.fast_sample_standard_uniform() &lt; 0.5:
                self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].update()
                if self._there_are_perturbations:
                    self.G[STRNAMES.PERT_VALUE].update()
            else:
                if self._there_are_perturbations:
                    self.G[STRNAMES.PERT_VALUE].update()
                self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].update()
        else:
            # Update jointly
            rhs = []
            lhs = []
            if self.interactions.obj.sample_iter &gt;= \
                self.interactions.delay:
                rhs.append(STRNAMES.CLUSTER_INTERACTION_VALUE)
            else:
                lhs.append(STRNAMES.CLUSTER_INTERACTION_VALUE)
            if self._there_are_perturbations:
                if self.pert_mag.sample_iter &gt;= self.pert_mag.delay:
                    rhs.append(STRNAMES.PERT_VALUE)
                else:
                    lhs.append(STRNAMES.PERT_VALUE)

            if len(rhs) == 0:
                return

            lhs += [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            X = self.G.data.construct_rhs(keys=rhs)
            if X.shape[1] == 0:
                logging.info(&#39;No columns, skipping&#39;)
                return
            y = self.G.data.construct_lhs(keys=lhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;: False}})

            process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
                cov=False, sparse=True)
            prior_prec = build_prior_covariance(G=self.G, cov=False,
                order=rhs, sparse=True)
            prior_means = build_prior_mean(G=self.G,order=rhs).reshape(-1,1)

            # Make the prior covariance matrix and process varaince
            prec = X.T @ process_prec @ X + prior_prec
            self.cov.value = pinv(prec, self)
            self.mean.value = np.asarray(self.cov.value @ (X.T @ process_prec.dot(y) + \
                prior_prec @ prior_means)).ravel()

            # sample posterior jointly and then assign the values to each coefficient
            # type, respectfully
            try:
                value = self.sample()
            except:
                logging.critical(&#39;failed here, updating separately&#39;)
                self.pert_mag.update()
                self.interactions.update()
                return

            i = 0
            if STRNAMES.CLUSTER_INTERACTION_VALUE in rhs:
                l = self.interactions.obj.num_pos_indicators()
                self.interactions.value = value[:l]
                self.interactions.set_values(arr=value[:l], use_indicators=True)
                self.interactions.update_str()
                i += l
            if self._there_are_perturbations:
                if STRNAMES.PERT_VALUE in rhs:
                    self.pert_mag.value = value[i:]
                    self.pert_mag.set_values(arr=value[i:], use_indicators=True)
                    self.pert_mag.update_str()
                    self.G.data.design_matrices[STRNAMES.GROWTH_VALUE].update_value()
                    # self.G.data.design_matrices[STRNAMES.PERT_VALUE].build()

    def _update_acceptances(self):
        if self.growth.sample_iter == 0:
            self.temp_acceptances= np.zeros(len(self.G.data.asvs), dtype=int)
            self.acceptances = np.zeros(shape=(self.G.inference.n_samples, 
                len(self.G.data.asvs)), dtype=bool)
        elif self.growth.sample_iter &gt; self.end_tune:
            return
        elif self.growth.sample_iter % self.tune == 0:
            self.temp_acceptances = np.zeros(len(self.G.data.asvs), dtype=int)

    def _update_growth_and_self_interactions(self):
        &#39;&#39;&#39;Update the growth and self-interactions
        Our proposal is the posterior distribution.
        &#39;&#39;&#39;
        if not self.update_jointly_growth_si:
            # Update separately
            self.growth.update()
            self.self_interactions.update()
        else:
            # Update together
            raise NotImplementedError(&#39;Not Implemented&#39;)

    def add_trace(self):
        &#39;&#39;&#39;Trace values for growth, self-interactions, and cluster interaction values
        &#39;&#39;&#39;
        self.growth.add_trace()
        self.self_interactions.add_trace()
        self.interactions.add_trace()
        if self._there_are_perturbations:
            self.pert_mag.add_trace()

    def set_trace(self):
        self.growth.set_trace()
        self.self_interactions.set_trace()
        self.interactions.set_trace()
        if self._there_are_perturbations:
            self.pert_mag.set_trace()

    def add_init_value(self):
        self.growth.add_init_value()
        self.self_interactions.add_init_value()
        self.interactions.add_init_value()
        if self._there_are_perturbations:
            self.pert_mag.add_init_value()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mdsine2.logistic_growth.Growth"><code class="flex name class">
<span>class <span class="ident">Growth</span></span>
<span>(</span><span>prior, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Growth values of Lotka-Voltera</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Growth(pl.variables.TruncatedNormal):
    &#39;&#39;&#39;Growth values of Lotka-Voltera
    &#39;&#39;&#39;
    def __init__(self, prior, **kwargs):
        kwargs[&#39;name&#39;] = STRNAMES.GROWTH_VALUE
        pl.variables.TruncatedNormal.__init__(self, mean=None, var=None, low=0.,
            high=float(&#39;inf&#39;), dtype=float, **kwargs)
        self.set_value_shape(shape=(len(self.G.data.asvs),))
        self.add_prior(prior)
        self.delay = 0
        self._initialized = False

    def __str__(self):
        return str(self.value)

    def update_str(self):
        return

    def initialize(self, value_option, truncation_settings,
        value=None, delay=0, mean=None):
        &#39;&#39;&#39;Initialize the growth values and hyperparamters

        Parameters
        ----------
        value_option : str
            How to initialize the values.
            Options:
                &#39;manual&#39;
                    Set the values manually. `value` must also be specified.
                &#39;linear regression&#39;
                    Set the values of the growth using linear regression
                &#39;ones&#39;
                    Set all of the values to 1.
                &#39;auto&#39;
                    Alias for &#39;ones&#39;
                &#39;prior-mean&#39;
                    Set to the mean of the prior
        value : array
            Only necessary if `value_option` is &#39;manual&#39;
        delay : int
            How many MCMC iterations to delay starting to update
        truncation_settings : str, tuple, None
            These are the settings of how you set the upper and lower limit of the
            truncated distribution. If it is None, it will default to &#39;standard&#39;.
            Options
                &#39;positive&#39;, None
                    Only constrains the values to being positive
                    low=0., high=float(&#39;inf&#39;)
                &#39;in-vivo&#39;, &#39;auto&#39;
                    Tighter constraint on the growth values.
                    low=0.1, high=ln(10)
                    These values have the following meaning
                        The slowest growing microbe will grow an order of magnitude in ~10 days
                        The fastest growing microbe will grow an order of magnitude in 1 day
                tuple(low, high)
                    These are manually specified values for the low and high
        &#39;&#39;&#39;
        self._initialized = True
        self._there_are_perturbations = self.G.perturbations is not None
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Truncation settings
        if truncation_settings is None:
            truncation_settings = &#39;positive&#39;
        if pl.isstr(truncation_settings):
            if truncation_settings == &#39;positive&#39;:
                self.low = 0.
                self.high = float(&#39;inf&#39;)
            elif truncation_settings in [&#39;in-vivo&#39;, &#39;auto&#39;]:
                self.low = 0.1
                self.high = math.log(10)
            else:
                raise ValueError(&#39;`truncation_settings` ({}) not recognized&#39;.format(
                    truncation_settings))
        elif pl.istuple(truncation_settings):
            if len(truncation_settings) != 2:
                raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                    &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
            l,h = truncation_settings

            if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
                raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                    type(l), type(h)))
            if l &lt; 0 or h &lt; 0:
                raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
            if h &lt;= l:
                raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
            self.high = h
            self.low = l
        else:
            raise TypeError(&#39;`truncation_settings` ({}) type not recognized&#39;)

        # Setting the value
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isarray(value):
                value = np.ones(len(self.G.data.asvs))*value
            if len(value) != self.G.data.n_asvs:
                raise ValueError(&#39;`value` ({}) must be ({}) long&#39;.format(
                    len(value), len(self.G.data.asvs)))
            self.value = value
        elif value_option == &#39;linear-regression&#39;:
            rhs = [
                STRNAMES.GROWTH_VALUE,
                STRNAMES.SELF_INTERACTION_VALUE
            ]
            lhs = []
            X = self.G.data.construct_rhs(
                keys=rhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = (cov @ X.transpose().dot(y)).ravel()
            self.value = np.absolute(mean[:len(self.G.data.asvs)])
        elif value_option in [&#39;auto&#39;, &#39;ones&#39;]:
            self.value = np.ones(len(self.G.data.asvs), dtype=float)
        elif value_option == &#39;prior-mean&#39;:
            self.value = self.prior.mean.value * np.ones(self.G.data.n_asvs)
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

        logging.info(&#39;Growth value initialization: {}&#39;.format(self.value))
        logging.info(&#39;Growth prior mean: {}&#39;.format(self.prior.mean.value))
        logging.info(&#39;Growth truncation settings: {}&#39;.format((self.low, self.high)))

    def update(self):
        &#39;&#39;&#39;Update the values using a truncated normal
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return

        self.calculate_posterior()
        self.sample()

        if not pl.isarray(self.value):
            # This will happen if there is 1 ASV
            self.value = np.array([self.value])

        if np.any(np.isnan(self.value)):
            logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
            logging.critical(&#39;var: {}&#39;.format(self.var.value))
            logging.critical(&#39;value: {}&#39;.format(self.value))
            raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))

        if self._there_are_perturbations:
            # If there are perturbations then we need to update their
            # matrix because the growths changed
            self.G.data.design_matrices[STRNAMES.PERT_VALUE].update_values()

    def calculate_posterior(self):
        rhs = [STRNAMES.GROWTH_VALUE]
        if self._there_are_perturbations:
            lhs = [
                STRNAMES.SELF_INTERACTION_VALUE,
                STRNAMES.CLUSTER_INTERACTION_VALUE]
        else:
            lhs = [
                STRNAMES.SELF_INTERACTION_VALUE,
                STRNAMES.CLUSTER_INTERACTION_VALUE]
        X = self.G.data.construct_rhs(keys=rhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{
                &#39;with_perturbations&#39;:self._there_are_perturbations}})
        y = self.G.data.construct_lhs(keys=lhs)
        # X = X.toarray()

        process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
            cov=False, sparse=True)

        prior_prec = build_prior_covariance(G=self.G, cov=False,
            order=rhs, sparse=True)
        prior_mean = build_prior_mean(G=self.G, order=rhs).reshape(-1,1)
        pm = prior_prec @ prior_mean

        prec = X.T @ process_prec @ X + prior_prec
        cov = pinv(prec, self)

        self.mean.value = np.asarray(cov @ (X.T @ process_prec.dot(y) + pm)).ravel()
        self.var.value = np.diag(cov)

    def visualize_posterior(self, basepath, f, section=&#39;posterior&#39;, asv_formatter=&#39;%(name)s&#39;, 
        true_value=None):
        &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
        learned values to the file `f`.

        Parameters
        ----------
        basepath : str
            This is the loction to write the files to
        f : _io.TextIOWrapper
            File that we are writing the values to
        section : str
            Section of the trace to compute on. Options:
                &#39;posterior&#39; : posterior samples
                &#39;burnin&#39; : burn-in samples
                &#39;entire&#39; : both burn-in and posterior samples
        true_value : np.ndarray
            Ground truth values of the variable

        Returns
        -------
        _io.TextIOWrapper
        &#39;&#39;&#39;
        f.write(&#39;\n\n###################################\n&#39;)
        f.write(self.name)
        f.write(&#39;\n###################################\n&#39;)
        if not self.G.inference.tracer.is_being_traced(self):
            f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
            return f

        asvs = self.G.data.subjects.asvs
        summ = pl.summary(self, section=section)
        for key,arr in summ.items():
            f.write(&#39;{}\n&#39;.format(key))
            for idx,ele in enumerate(arr):
                prefix = &#39;&#39;
                if asv_formatter is not None:
                    prefix = pl.asvname_formatter(format=asv_formatter, asv=asvs[idx], asvs=asvs)
                f.write(&#39;\t&#39; + prefix + &#39;{}\n&#39;.format(ele)) 

        if section == &#39;posterior&#39;:
            len_posterior = self.G.inference.sample_iter + 1 - self.G.inference.burnin
        elif section == &#39;burnin&#39;:
            len_posterior = self.G.inference.burnin
        else:
            len_posterior = self.G.inference.sample_iter + 1

        # Plot the prior on top of the posterior
        if self.G.tracer.is_being_traced(STRNAMES.PRIOR_MEAN_GROWTH):
            prior_mean_trace = self.G[STRNAMES.PRIOR_MEAN_GROWTH].get_trace_from_disk(
                    section=section)
        else:
            prior_mean_trace = self.prior.mean.value * np.ones(len_posterior, dtype=float)
        if self.G.tracer.is_being_traced(STRNAMES.PRIOR_VAR_GROWTH):
            prior_std_trace = np.sqrt(
                self.G[STRNAMES.PRIOR_VAR_GROWTH].get_trace_from_disk(section=section))
        else:
            prior_std_trace = np.sqrt(self.prior.var.value) * np.ones(len_posterior, dtype=float)

        for idx in range(len(asvs)):
            fig = plt.figure()
            ax_posterior = fig.add_subplot(1,2,1)
            visualization.render_trace(var=self, idx=idx, plt_type=&#39;hist&#39;,
                label=section, color=&#39;blue&#39;, ax=ax_posterior, section=section,
                include_burnin=True, rasterized=True)

            # Get the limits and only look at the posterior within 20% range +- of
            # this number
            low_x, high_x = ax_posterior.get_xlim()

            arr = np.zeros(len(prior_std_trace), dtype=float)
            for i in range(len(prior_std_trace)):
                arr[i] = pl.random.truncnormal.sample(mean=prior_mean_trace[i], std=prior_std_trace[i], 
                    low=self.low, high=self.high)
            visualization.render_trace(var=arr, plt_type=&#39;hist&#39;, 
                label=&#39;prior&#39;, color=&#39;red&#39;, ax=ax_posterior, rasterized=True)

            if true_value is not None:
                ax_posterior.axvline(x=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                    label=&#39;True Value&#39;)

            ax_posterior.legend()
            ax_posterior.set_xlim(left=low_x*.8, right=high_x*1.2)

            # plot the trace
            ax_trace = fig.add_subplot(1,2,2)
            visualization.render_trace(var=self, idx=idx, plt_type=&#39;trace&#39;, 
                ax=ax_trace, section=section, include_burnin=True, rasterized=True)

            if true_value is not None:
                ax_trace.axhline(y=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                    label=&#39;True Value&#39;)
                ax_trace.legend()

            if asv_formatter is not None:
                asvname = pl.asvname_formatter(
                    format=asv_formatter,
                    asv=asvs[idx],
                    asvs=asvs)
            else:
                asvname = asvs[idx].name
            asvname = asvname.replace(&#39;/&#39;, &#39;_&#39;).replace(&#39; &#39;, &#39;_&#39;)

            fig.suptitle(&#39;Growth {}&#39;.format(asvname))
            fig.tight_layout()
            fig.subplots_adjust(top=0.85)
            plt.savefig(basepath + &#39;{}.pdf&#39;.format(asvs[idx].name))
            plt.close()

        return f</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.TruncatedNormal" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal">TruncatedNormal</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.logistic_growth.Growth.calculate_posterior"><code class="name flex">
<span>def <span class="ident">calculate_posterior</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_posterior(self):
    rhs = [STRNAMES.GROWTH_VALUE]
    if self._there_are_perturbations:
        lhs = [
            STRNAMES.SELF_INTERACTION_VALUE,
            STRNAMES.CLUSTER_INTERACTION_VALUE]
    else:
        lhs = [
            STRNAMES.SELF_INTERACTION_VALUE,
            STRNAMES.CLUSTER_INTERACTION_VALUE]
    X = self.G.data.construct_rhs(keys=rhs,
        kwargs_dict={STRNAMES.GROWTH_VALUE:{
            &#39;with_perturbations&#39;:self._there_are_perturbations}})
    y = self.G.data.construct_lhs(keys=lhs)
    # X = X.toarray()

    process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
        cov=False, sparse=True)

    prior_prec = build_prior_covariance(G=self.G, cov=False,
        order=rhs, sparse=True)
    prior_mean = build_prior_mean(G=self.G, order=rhs).reshape(-1,1)
    pm = prior_prec @ prior_mean

    prec = X.T @ process_prec @ X + prior_prec
    cov = pinv(prec, self)

    self.mean.value = np.asarray(cov @ (X.T @ process_prec.dot(y) + pm)).ravel()
    self.var.value = np.diag(cov)</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.Growth.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, value_option, truncation_settings, value=None, delay=0, mean=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the growth values and hyperparamters</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>value_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to initialize the values.
Options:
'manual'
Set the values manually. <code>value</code> must also be specified.
'linear regression'
Set the values of the growth using linear regression
'ones'
Set all of the values to 1.
'auto'
Alias for 'ones'
'prior-mean'
Set to the mean of the prior</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>array</code></dt>
<dd>Only necessary if <code>value_option</code> is 'manual'</dd>
<dt><strong><code>delay</code></strong> :&ensp;<code>int</code></dt>
<dd>How many MCMC iterations to delay starting to update</dd>
<dt><strong><code>truncation_settings</code></strong> :&ensp;<code>str, tuple, None</code></dt>
<dd>These are the settings of how you set the upper and lower limit of the
truncated distribution. If it is None, it will default to 'standard'.
Options
'positive', None
Only constrains the values to being positive
low=0., high=float('inf')
'in-vivo', 'auto'
Tighter constraint on the growth values.
low=0.1, high=ln(10)
These values have the following meaning
The slowest growing microbe will grow an order of magnitude in ~10 days
The fastest growing microbe will grow an order of magnitude in 1 day
tuple(low, high)
These are manually specified values for the low and high</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, value_option, truncation_settings,
    value=None, delay=0, mean=None):
    &#39;&#39;&#39;Initialize the growth values and hyperparamters

    Parameters
    ----------
    value_option : str
        How to initialize the values.
        Options:
            &#39;manual&#39;
                Set the values manually. `value` must also be specified.
            &#39;linear regression&#39;
                Set the values of the growth using linear regression
            &#39;ones&#39;
                Set all of the values to 1.
            &#39;auto&#39;
                Alias for &#39;ones&#39;
            &#39;prior-mean&#39;
                Set to the mean of the prior
    value : array
        Only necessary if `value_option` is &#39;manual&#39;
    delay : int
        How many MCMC iterations to delay starting to update
    truncation_settings : str, tuple, None
        These are the settings of how you set the upper and lower limit of the
        truncated distribution. If it is None, it will default to &#39;standard&#39;.
        Options
            &#39;positive&#39;, None
                Only constrains the values to being positive
                low=0., high=float(&#39;inf&#39;)
            &#39;in-vivo&#39;, &#39;auto&#39;
                Tighter constraint on the growth values.
                low=0.1, high=ln(10)
                These values have the following meaning
                    The slowest growing microbe will grow an order of magnitude in ~10 days
                    The fastest growing microbe will grow an order of magnitude in 1 day
            tuple(low, high)
                These are manually specified values for the low and high
    &#39;&#39;&#39;
    self._initialized = True
    self._there_are_perturbations = self.G.perturbations is not None
    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    self.delay = delay

    # Truncation settings
    if truncation_settings is None:
        truncation_settings = &#39;positive&#39;
    if pl.isstr(truncation_settings):
        if truncation_settings == &#39;positive&#39;:
            self.low = 0.
            self.high = float(&#39;inf&#39;)
        elif truncation_settings in [&#39;in-vivo&#39;, &#39;auto&#39;]:
            self.low = 0.1
            self.high = math.log(10)
        else:
            raise ValueError(&#39;`truncation_settings` ({}) not recognized&#39;.format(
                truncation_settings))
    elif pl.istuple(truncation_settings):
        if len(truncation_settings) != 2:
            raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
        l,h = truncation_settings

        if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
            raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                type(l), type(h)))
        if l &lt; 0 or h &lt; 0:
            raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
        if h &lt;= l:
            raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
        self.high = h
        self.low = l
    else:
        raise TypeError(&#39;`truncation_settings` ({}) type not recognized&#39;)

    # Setting the value
    if not pl.isstr(value_option):
        raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
    if value_option == &#39;manual&#39;:
        if not pl.isarray(value):
            value = np.ones(len(self.G.data.asvs))*value
        if len(value) != self.G.data.n_asvs:
            raise ValueError(&#39;`value` ({}) must be ({}) long&#39;.format(
                len(value), len(self.G.data.asvs)))
        self.value = value
    elif value_option == &#39;linear-regression&#39;:
        rhs = [
            STRNAMES.GROWTH_VALUE,
            STRNAMES.SELF_INTERACTION_VALUE
        ]
        lhs = []
        X = self.G.data.construct_rhs(
            keys=rhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True)

        prec = X.T @ X
        cov = pinv(prec, self)
        mean = (cov @ X.transpose().dot(y)).ravel()
        self.value = np.absolute(mean[:len(self.G.data.asvs)])
    elif value_option in [&#39;auto&#39;, &#39;ones&#39;]:
        self.value = np.ones(len(self.G.data.asvs), dtype=float)
    elif value_option == &#39;prior-mean&#39;:
        self.value = self.prior.mean.value * np.ones(self.G.data.n_asvs)
    else:
        raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

    logging.info(&#39;Growth value initialization: {}&#39;.format(self.value))
    logging.info(&#39;Growth prior mean: {}&#39;.format(self.prior.mean.value))
    logging.info(&#39;Growth truncation settings: {}&#39;.format((self.low, self.high)))</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.Growth.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the values using a truncated normal</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#39;&#39;&#39;Update the values using a truncated normal
    &#39;&#39;&#39;
    if self.sample_iter &lt; self.delay:
        return

    self.calculate_posterior()
    self.sample()

    if not pl.isarray(self.value):
        # This will happen if there is 1 ASV
        self.value = np.array([self.value])

    if np.any(np.isnan(self.value)):
        logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
        logging.critical(&#39;var: {}&#39;.format(self.var.value))
        logging.critical(&#39;value: {}&#39;.format(self.value))
        raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))

    if self._there_are_perturbations:
        # If there are perturbations then we need to update their
        # matrix because the growths changed
        self.G.data.design_matrices[STRNAMES.PERT_VALUE].update_values()</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.Growth.update_str"><code class="name flex">
<span>def <span class="ident">update_str</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_str(self):
    return</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.Growth.visualize_posterior"><code class="name flex">
<span>def <span class="ident">visualize_posterior</span></span>(<span>self, basepath, f, section='posterior', asv_formatter='%(name)s', true_value=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Render the traces in the folder <code>basepath</code> and write the
learned values to the file <code>f</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>basepath</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the loction to write the files to</dd>
<dt><strong><code>f</code></strong> :&ensp;<code>_io.TextIOWrapper</code></dt>
<dd>File that we are writing the values to</dd>
<dt><strong><code>section</code></strong> :&ensp;<code>str</code></dt>
<dd>Section of the trace to compute on. Options:
'posterior' : posterior samples
'burnin' : burn-in samples
'entire' : both burn-in and posterior samples</dd>
<dt><strong><code>true_value</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Ground truth values of the variable</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>_io.TextIOWrapper</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualize_posterior(self, basepath, f, section=&#39;posterior&#39;, asv_formatter=&#39;%(name)s&#39;, 
    true_value=None):
    &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
    learned values to the file `f`.

    Parameters
    ----------
    basepath : str
        This is the loction to write the files to
    f : _io.TextIOWrapper
        File that we are writing the values to
    section : str
        Section of the trace to compute on. Options:
            &#39;posterior&#39; : posterior samples
            &#39;burnin&#39; : burn-in samples
            &#39;entire&#39; : both burn-in and posterior samples
    true_value : np.ndarray
        Ground truth values of the variable

    Returns
    -------
    _io.TextIOWrapper
    &#39;&#39;&#39;
    f.write(&#39;\n\n###################################\n&#39;)
    f.write(self.name)
    f.write(&#39;\n###################################\n&#39;)
    if not self.G.inference.tracer.is_being_traced(self):
        f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
        return f

    asvs = self.G.data.subjects.asvs
    summ = pl.summary(self, section=section)
    for key,arr in summ.items():
        f.write(&#39;{}\n&#39;.format(key))
        for idx,ele in enumerate(arr):
            prefix = &#39;&#39;
            if asv_formatter is not None:
                prefix = pl.asvname_formatter(format=asv_formatter, asv=asvs[idx], asvs=asvs)
            f.write(&#39;\t&#39; + prefix + &#39;{}\n&#39;.format(ele)) 

    if section == &#39;posterior&#39;:
        len_posterior = self.G.inference.sample_iter + 1 - self.G.inference.burnin
    elif section == &#39;burnin&#39;:
        len_posterior = self.G.inference.burnin
    else:
        len_posterior = self.G.inference.sample_iter + 1

    # Plot the prior on top of the posterior
    if self.G.tracer.is_being_traced(STRNAMES.PRIOR_MEAN_GROWTH):
        prior_mean_trace = self.G[STRNAMES.PRIOR_MEAN_GROWTH].get_trace_from_disk(
                section=section)
    else:
        prior_mean_trace = self.prior.mean.value * np.ones(len_posterior, dtype=float)
    if self.G.tracer.is_being_traced(STRNAMES.PRIOR_VAR_GROWTH):
        prior_std_trace = np.sqrt(
            self.G[STRNAMES.PRIOR_VAR_GROWTH].get_trace_from_disk(section=section))
    else:
        prior_std_trace = np.sqrt(self.prior.var.value) * np.ones(len_posterior, dtype=float)

    for idx in range(len(asvs)):
        fig = plt.figure()
        ax_posterior = fig.add_subplot(1,2,1)
        visualization.render_trace(var=self, idx=idx, plt_type=&#39;hist&#39;,
            label=section, color=&#39;blue&#39;, ax=ax_posterior, section=section,
            include_burnin=True, rasterized=True)

        # Get the limits and only look at the posterior within 20% range +- of
        # this number
        low_x, high_x = ax_posterior.get_xlim()

        arr = np.zeros(len(prior_std_trace), dtype=float)
        for i in range(len(prior_std_trace)):
            arr[i] = pl.random.truncnormal.sample(mean=prior_mean_trace[i], std=prior_std_trace[i], 
                low=self.low, high=self.high)
        visualization.render_trace(var=arr, plt_type=&#39;hist&#39;, 
            label=&#39;prior&#39;, color=&#39;red&#39;, ax=ax_posterior, rasterized=True)

        if true_value is not None:
            ax_posterior.axvline(x=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                label=&#39;True Value&#39;)

        ax_posterior.legend()
        ax_posterior.set_xlim(left=low_x*.8, right=high_x*1.2)

        # plot the trace
        ax_trace = fig.add_subplot(1,2,2)
        visualization.render_trace(var=self, idx=idx, plt_type=&#39;trace&#39;, 
            ax=ax_trace, section=section, include_burnin=True, rasterized=True)

        if true_value is not None:
            ax_trace.axhline(y=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                label=&#39;True Value&#39;)
            ax_trace.legend()

        if asv_formatter is not None:
            asvname = pl.asvname_formatter(
                format=asv_formatter,
                asv=asvs[idx],
                asvs=asvs)
        else:
            asvname = asvs[idx].name
        asvname = asvname.replace(&#39;/&#39;, &#39;_&#39;).replace(&#39; &#39;, &#39;_&#39;)

        fig.suptitle(&#39;Growth {}&#39;.format(asvname))
        fig.tight_layout()
        fig.subplots_adjust(top=0.85)
        plt.savefig(basepath + &#39;{}.pdf&#39;.format(asvs[idx].name))
        plt.close()

    return f</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.TruncatedNormal" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal">TruncatedNormal</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.cdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.cdf">cdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.logcdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.logcdf">logcdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.logpdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.logpdf">logpdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.pdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.pdf">pdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.sample" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.logistic_growth.PriorMeanMH"><code class="flex name class">
<span>class <span class="ident">PriorMeanMH</span></span>
<span>(</span><span>prior, child_name, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This implements the posterior for the prior mean of the either
the growths or the self-interactions</p>
<h2 id="parameters">Parameters</h2></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PriorMeanMH(pl.variables.TruncatedNormal):
    &#39;&#39;&#39;This implements the posterior for the prior mean of the either
    the growths or the self-interactions

    Parameters
    ----------
    &#39;&#39;&#39;
    def __init__(self, prior, child_name, **kwargs):
        if child_name == STRNAMES.GROWTH_VALUE:
            kwargs[&#39;name&#39;] = STRNAMES.PRIOR_MEAN_GROWTH
        elif child_name == STRNAMES.SELF_INTERACTION_VALUE:
            kwargs[&#39;name&#39;] = STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS
        else:
            raise ValueError(&#39;`child_name` ({}) not recognized&#39;.format(child_name))
        pl.variables.TruncatedNormal.__init__(self, mean=None, var=None, dtype=float, **kwargs)
        self.child_name = child_name
        self.add_prior(prior)
        self.proposal = pl.variables.TruncatedNormal(mean=None, var=None, value=None)

    def __str__(self):
        # If this fails, it is because we are dividing by 0 sampler_iter
        # If which case we just return the value 
        try:
            s = &#39;Value: {}, Acceptance rate: {}&#39;.format(
                self.value, np.mean(self.acceptances[
                    np.max([self.sample_iter-50, 0]):self.sample_iter]))
        except:
            s = str(self.value)
        return s

    def initialize(self, value_option, mean_option, var_option,
        truncation_settings, proposal_option, target_acceptance_rate,
        tune, end_tune, value=None, mean=None, var=None, proposal_var=None,
        delay=0):
        &#39;&#39;&#39;These are the parameters to initialize the parameters
        of the class. Depending whether it is a self-interaction
        or a growth, it does it differently.

        Parameters
        ----------
        value_option : str
            How to initialize the value. Options:
                &#39;auto&#39;, &#39;prior-mean&#39;
                    Set to the prior mean
                &#39;linear-regression&#39;
                    Set the values from an unregularized linear regression
                &#39;manual&#39;
                    `value` must also be specified
        truncation_settings: str, tuple
            How to set the truncation parameters. The proposal trucation will
            be set the same way.
                tuple - (low,high)
                    These are the truncation parameters
                &#39;auto&#39;
                    If self-interactions, &#39;negative&#39;. If growths, &#39;positive&#39;
                &#39;positive&#39;
                    (0, \infty)
                &#39;negative&#39;
                    (-\infty, 0)
                &#39;in-vivo&#39;
                    Not implemented
        mean_option : str
            How to set the mean
                &#39;auto&#39;, &#39;median-linear-regression&#39;
                    Set the mean to the median of the values from an
                    unregularized linear-regression
                &#39;manual&#39;
                    `mean` must also be specified
        var_option : str
            How to set the var
                &#39;auto&#39;, &#39;diffuse-linear-regression&#39;
                    Set the var to 10^4 * median(a_l)
                &#39;manaul&#39;
                    `var` must also be specified.
        proposal_option : str
            How to initialize the proposal variance:
                &#39;auto&#39;
                    mean**2 / 100
                &#39;manual&#39;
                    `proposal_var` must also be supplied
        target_acceptance_rate : str, float
            If float, this is the target acceptance rate
            If str: 
                &#39;optimal&#39;, &#39;auto&#39;: 0.44
        tune : str, int
            How often to tune the proposal. If str:
                &#39;auto&#39;: 50
        end_tune : str, int
            When to stop tuning the proposal. If str:
                &#39;auto&#39;, &#39;half-burnin&#39;: Half of burnin
        &#39;&#39;&#39;
        self._there_are_perturbations = self.G.perturbations is not None
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Set the propsal parameters
        if pl.isstr(target_acceptance_rate):
            if target_acceptance_rate in [&#39;optimal&#39;, &#39;auto&#39;]:
                target_acceptance_rate = 0.44
            else:
                raise ValueError(&#39;`target_acceptance_rate` ({}) not recognized&#39;.format(
                    target_acceptance_rate))
        elif pl.isfloat(target_acceptance_rate):
            if target_acceptance_rate &lt; 0 or target_acceptance_rate &gt; 1:
                raise ValueError(&#39;`target_acceptance_rate` ({}) out of range&#39;.format(
                    target_acceptance_rate))
        else:
            raise TypeError(&#39;`target_acceptance_rate` ({}) type not recognized&#39;.format(
                type(target_acceptance_rate)))
        self.target_acceptance_rate = target_acceptance_rate

        if pl.isstr(tune):
            if tune in [&#39;auto&#39;]:
                tune = 50
            else:
                raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(tune))
        elif pl.isint(tune):
            if tune &lt; 0:
                raise ValueError(&#39;`tune` ({}) must be &gt; 0&#39;.format(
                    tune))
        else:
            raise TypeError(&#39;`tune` ({}) type not recognized&#39;.format(type(tune)))
        self.tune = tune

        if pl.isstr(end_tune):
            if end_tune in [&#39;auto&#39;, &#39;half-burnin&#39;]:
                end_tune = int(self.G.inference.burnin/2)
            else:
                raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(end_tune))
        elif pl.isint(end_tune):
            if end_tune &lt; 0 or end_tune &gt; self.G.inference.burnin:
                raise ValueError(&#39;`end_tune` ({}) out of range (0, {})&#39;.format(
                    end_tune, self.G.inference.burnin))
        else:
            raise TypeError(&#39;`end_tune` ({}) type not recognized&#39;.format(type(end_tune)))
        self.end_tune = end_tune

        # Set the truncation settings
        if truncation_settings is None:
            truncation_settings = &#39;positive&#39;
        if pl.isstr(truncation_settings):
            if truncation_settings == &#39;positive&#39;:
                self.low = 0.
                self.high = float(&#39;inf&#39;)
            # elif truncation_settings == &#39;negative&#39;:
            #     self.low = float(&#39;-inf&#39;)
            #     self.high = 0
            elif truncation_settings == &#39;in-vivo&#39;:
                self.low = 0.1
                self.high = np.log(10)
            else:
                raise ValueError(&#39;`truncation_settings` ({}) not recognized&#39;.format(
                    truncation_settings))
        elif pl.istuple(truncation_settings):
            if len(truncation_settings) != 2:
                raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                    &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
            l,h = truncation_settings

            if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
                raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                    type(l), type(h)))
            if l &lt; 0 or h &lt; 0:
                raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
            if h &lt;= l:
                raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
            self.high = h
            self.low = l
        else:
            raise TypeError(&#39;`truncation_settings` ({}) type not recognized&#39;)
        self.proposal.high = self.high
        self.proposal.low = self.low

        # Set the mean
        if not pl.isstr(mean_option):
            raise TypeError(&#39;`mean_option` ({}) must be a str&#39;.format(type(mean_option)))
        if mean_option == &#39;manual&#39;:
            if not pl.isnumeric(mean):
                raise TypeError(&#39;`mean` ({}) must be a numeric&#39;.format(type(mean)))
        elif mean_option in [&#39;auto&#39;, &#39;median-linear-regression&#39;]:
            # Perform linear regression
            if self.child_name == STRNAMES.GROWTH_VALUE:
                rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
                lhs = []
            else:
                rhs = [STRNAMES.SELF_INTERACTION_VALUE]
                lhs = [STRNAMES.GROWTH_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, 
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y

            if self.child_name == STRNAMES.GROWTH_VALUE:
                mean = np.median(mean[:self.G.data.n_asvs])
            else:
                mean = np.median(mean)
        else:
            raise ValueError(&#39;`mean_option` ({}) not recognized&#39;.format(mean_option))
        self.prior.mean.override_value(mean)

        # Set the var
        if not pl.isstr(var_option):
            raise TypeError(&#39;`var_option` ({}) must be a str&#39;.format(type(var_option)))
        if var_option == &#39;manual&#39;:
            if not pl.isnumeric(var):
                raise TypeError(&#39;`var` ({}) must be a numeric&#39;.format(type(var)))
        elif var_option in [&#39;auto&#39;, &#39;diffuse-linear-regression&#39;]:
            # Perform linear regression
            if self.child_name == STRNAMES.GROWTH_VALUE:
                rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
                lhs = []
            else:
                rhs = [STRNAMES.SELF_INTERACTION_VALUE]
                lhs = [STRNAMES.GROWTH_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, 
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y

            if self.child_name == STRNAMES.GROWTH_VALUE:
                mean = np.median(mean[:self.G.data.n_asvs])
            else:
                mean = np.median(mean)
            var = 1e4 * (mean**2)
        else:
            raise ValueError(&#39;`var_option` ({}) not recognized&#39;.format(var_option))
        self.prior.var.override_value(var)

        # Set the value
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isnumeric(value):
                raise TypeError(&#39;`value` ({}) must be a numeric&#39;.format(type(value)))
        elif value_option in [&#39;linear-regression&#39;]:
            # Perform linear regression
            if self.child_name == STRNAMES.GROWTH_VALUE:
                rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
                lhs = []
            else:
                rhs = [STRNAMES.SELF_INTERACTION_VALUE]
                lhs = [STRNAMES.GROWTH_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, 
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y

            if self.child_name == STRNAMES.GROWTH_VALUE:
                value = mean[:self.G.data.n_asvs]
            else:
                value = mean
        elif value_option in [&#39;auto&#39;, &#39;prior-mean&#39;]:
            value = self.prior.mean.value
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
        self.value = value

        # Set the proposal variance
        if not pl.isstr(proposal_option):
            raise TypeError(&#39;`proposal_option` ({}) must be a str&#39;.format(
                type(proposal_option)))
        elif proposal_option == &#39;manual&#39;:
            if not pl.isnumeric(proposal_var):
                raise TypeError(&#39;`proposal_var` ({}) must be a numeric&#39;.format(
                    type(proposal_var)))
            if proposal_var &lt;= 0:
                raise ValueError(&#39;`proposal_var` ({}) not proper&#39;.format(proposal_var))
        elif proposal_option in [&#39;auto&#39;]:
            proposal_var = (self.value ** 2)/10
        else:
            raise ValueError(&#39;`proposal_option` ({}) not recognized&#39;.format(
                proposal_option))
        self.proposal.var.value = proposal_var

    def update_var(self):
        &#39;&#39;&#39;Update the `var` parameter so that we adjust the acceptance
        rate to `target_acceptance_rate`
        &#39;&#39;&#39;
        if self.sample_iter == 0:
            self.temp_acceptances = 0
            self.acceptances = np.zeros(self.G.inference.n_samples, dtype=bool)
        
        elif self.sample_iter &gt; self.end_tune:
            # Don&#39;t do any more updates
            return
        
        elif self.sample_iter % self.tune == 0:
            # Update var
            acceptance_rate = self.temp_acceptances / self.tune
            if acceptance_rate &gt; self.target_acceptance_rate:
                self.proposal.var.value *= 1.5
            else:
                self.proposal.var.value /= 1.5
            self.temp_acceptances = 0

    def update(self):
        &#39;&#39;&#39;First we check if we need to tune the var, which we do during
        the first half of burnin. We calculate the likelihoods in logspace
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return
        self.update_var()
        proposal_std = np.sqrt(self.proposal.var.value)

        # Get necessary data of the respective parameter
        variable = self.G[self.child_name]
        x = variable.value.ravel()
        std = np.sqrt(variable.prior.var.value)

        low = variable.low
        high = variable.high

        # propose a new value for the mean
        prev_mean = self.value
        self.proposal.mean.value = self.value
        new_mean = self.proposal.sample() # Sample a new value

        # Calculate the target distribution ll
        prev_target_ll = pl.random.truncnormal.logpdf( 
            value=prev_mean, mean=self.prior.mean.value, 
            std=np.sqrt(self.prior.var.value), low=self.low,
            high=self.high)
        for i in range(len(x)):
            prev_target_ll += pl.random.truncnormal.logpdf(
                value=x[i], mean=prev_mean, std=std,
                low=low, high=high)
        new_target_ll = pl.random.truncnormal.logpdf( 
            value=new_mean, mean=self.prior.mean.value, 
            std=np.sqrt(self.prior.var.value), low=self.low,
            high=self.high)
        for i in range(len(x)):
            new_target_ll += pl.random.truncnormal.logpdf(
                value=x[i], mean=new_mean, std=std,
                low=low, high=high)

        # Normalize by the ll of the proposal
        prev_prop_ll = pl.random.truncnormal.logpdf(
            value=prev_mean, mean=new_mean, std=proposal_std,
            low=low, high=high)
        
        new_prop_ll = pl.random.truncnormal.logpdf(
            value=new_mean, mean=prev_mean, std=proposal_std,
            low=low, high=high)

        # Accept or reject
        r = (new_target_ll - prev_prop_ll) - \
            (prev_target_ll - new_prop_ll)
        u = np.log(pl.random.misc.fast_sample_standard_uniform())

        # print(&#39;\n\n\n{} prior_mean\n----------&#39;.format(self.child_name))
        # print(&#39;x&#39;, x)
        # print(&#39;prev_mean&#39;, prev_mean)
        # print(&#39;prev_target_ll&#39;, prev_target_ll)
        # print(&#39;prev_prop_ll&#39;, prev_prop_ll)
        # print(&#39;new mean&#39;, new_mean)
        # print(&#39;new_target_ll&#39;, new_target_ll)
        # print(&#39;new_prop_ll&#39;, new_prop_ll)
        # print(&#39;\nr&#39;, r, u)

        if r &gt;= u:
            self.acceptances[self.sample_iter] = True
            self.value = new_mean
            self.temp_acceptances += 1
        else:
            self.value = prev_mean

    def visualize_posterior(self, path, f, section=&#39;posterior&#39;):
        &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
        learned values to the file `f`.

        Parameters
        ----------
        path : str
            This is the path to write the files to
        f : _io.TextIOWrapper
            File that we are writing the values to
        section : str
            Section of the trace to compute on. Options:
                &#39;posterior&#39; : posterior samples
                &#39;burnin&#39; : burn-in samples
                &#39;entire&#39; : both burn-in and posterior samples

        Returns
        -------
        _io.TextIOWrapper
        &#39;&#39;&#39;
        f.write(&#39;\n\n###################################\n&#39;)
        f.write(self.name)
        f.write(&#39;\n###################################\n&#39;)
        if not self.G.inference.tracer.is_being_traced(self):
            f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
            return f
        summ = pl.summary(self, section=section)
        for k,v in summ.items():
            f.write(&#39;\t{}: {}\n&#39;.format(k,v))

        # Plot the traces
        ax1, ax2 = visualization.render_trace(var=self, plt_type=&#39;both&#39;, section=section,
            include_burnin=True, log_scale=True, rasterized=True)

        # Plot the prior over the posterior
        l,h = ax1.get_xlim()
        xs = np.arange(l,h,step=(h-l)/100) 
        ys = []
        for x in xs:
            ys.append(pl.random.sics.pdf(value=x, 
                dof=self.prior.dof.value,
                scale=self.prior.scale.value))
        ax1.plot(xs, ys, label=&#39;prior&#39;, alpha=0.5, color=&#39;red&#39;, rasterized=True)
        ax1.legend()

        # Plot the acceptance rate over the trace
        ax3 = ax2.twinx()
        ax3 = visualization.render_acceptance_rate_trace(var=self, ax=ax3, 
            label=&#39;Acceptance Rate&#39;, color=&#39;red&#39;, scatter=False, rasterized=True)
        ax3.legend()
        fig = plt.gcf()
        fig.tight_layout()
        fig.suptitle(self.name)
        plt.savefig(path)
        plt.close()

        return f</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.TruncatedNormal" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal">TruncatedNormal</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.logistic_growth.PriorMeanMH.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, value_option, mean_option, var_option, truncation_settings, proposal_option, target_acceptance_rate, tune, end_tune, value=None, mean=None, var=None, proposal_var=None, delay=0)</span>
</code></dt>
<dd>
<div class="desc"><p>These are the parameters to initialize the parameters
of the class. Depending whether it is a self-interaction
or a growth, it does it differently.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>value_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to initialize the value. Options:
'auto', 'prior-mean'
Set to the prior mean
'linear-regression'
Set the values from an unregularized linear regression
'manual'
<code>value</code> must also be specified</dd>
<dt><strong><code>truncation_settings</code></strong> :&ensp;<code>str, tuple</code></dt>
<dd>How to set the truncation parameters. The proposal trucation will
be set the same way.
tuple - (low,high)
These are the truncation parameters
'auto'
If self-interactions, 'negative'. If growths, 'positive'
'positive'
(0, \infty)
'negative'
(-\infty, 0)
'in-vivo'
Not implemented</dd>
<dt><strong><code>mean_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to set the mean
'auto', 'median-linear-regression'
Set the mean to the median of the values from an
unregularized linear-regression
'manual'
<code>mean</code> must also be specified</dd>
<dt><strong><code>var_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to set the var
'auto', 'diffuse-linear-regression'
Set the var to 10^4 * median(a_l)
'manaul'
<code>var</code> must also be specified.</dd>
<dt><strong><code>proposal_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to initialize the proposal variance:
'auto'
mean**2 / 100
'manual'
<code>proposal_var</code> must also be supplied</dd>
<dt><strong><code>target_acceptance_rate</code></strong> :&ensp;<code>str, float</code></dt>
<dd>If float, this is the target acceptance rate
If str:
'optimal', 'auto': 0.44</dd>
<dt><strong><code>tune</code></strong> :&ensp;<code>str, int</code></dt>
<dd>How often to tune the proposal. If str:
'auto': 50</dd>
<dt><strong><code>end_tune</code></strong> :&ensp;<code>str, int</code></dt>
<dd>When to stop tuning the proposal. If str:
'auto', 'half-burnin': Half of burnin</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, value_option, mean_option, var_option,
    truncation_settings, proposal_option, target_acceptance_rate,
    tune, end_tune, value=None, mean=None, var=None, proposal_var=None,
    delay=0):
    &#39;&#39;&#39;These are the parameters to initialize the parameters
    of the class. Depending whether it is a self-interaction
    or a growth, it does it differently.

    Parameters
    ----------
    value_option : str
        How to initialize the value. Options:
            &#39;auto&#39;, &#39;prior-mean&#39;
                Set to the prior mean
            &#39;linear-regression&#39;
                Set the values from an unregularized linear regression
            &#39;manual&#39;
                `value` must also be specified
    truncation_settings: str, tuple
        How to set the truncation parameters. The proposal trucation will
        be set the same way.
            tuple - (low,high)
                These are the truncation parameters
            &#39;auto&#39;
                If self-interactions, &#39;negative&#39;. If growths, &#39;positive&#39;
            &#39;positive&#39;
                (0, \infty)
            &#39;negative&#39;
                (-\infty, 0)
            &#39;in-vivo&#39;
                Not implemented
    mean_option : str
        How to set the mean
            &#39;auto&#39;, &#39;median-linear-regression&#39;
                Set the mean to the median of the values from an
                unregularized linear-regression
            &#39;manual&#39;
                `mean` must also be specified
    var_option : str
        How to set the var
            &#39;auto&#39;, &#39;diffuse-linear-regression&#39;
                Set the var to 10^4 * median(a_l)
            &#39;manaul&#39;
                `var` must also be specified.
    proposal_option : str
        How to initialize the proposal variance:
            &#39;auto&#39;
                mean**2 / 100
            &#39;manual&#39;
                `proposal_var` must also be supplied
    target_acceptance_rate : str, float
        If float, this is the target acceptance rate
        If str: 
            &#39;optimal&#39;, &#39;auto&#39;: 0.44
    tune : str, int
        How often to tune the proposal. If str:
            &#39;auto&#39;: 50
    end_tune : str, int
        When to stop tuning the proposal. If str:
            &#39;auto&#39;, &#39;half-burnin&#39;: Half of burnin
    &#39;&#39;&#39;
    self._there_are_perturbations = self.G.perturbations is not None
    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    self.delay = delay

    # Set the propsal parameters
    if pl.isstr(target_acceptance_rate):
        if target_acceptance_rate in [&#39;optimal&#39;, &#39;auto&#39;]:
            target_acceptance_rate = 0.44
        else:
            raise ValueError(&#39;`target_acceptance_rate` ({}) not recognized&#39;.format(
                target_acceptance_rate))
    elif pl.isfloat(target_acceptance_rate):
        if target_acceptance_rate &lt; 0 or target_acceptance_rate &gt; 1:
            raise ValueError(&#39;`target_acceptance_rate` ({}) out of range&#39;.format(
                target_acceptance_rate))
    else:
        raise TypeError(&#39;`target_acceptance_rate` ({}) type not recognized&#39;.format(
            type(target_acceptance_rate)))
    self.target_acceptance_rate = target_acceptance_rate

    if pl.isstr(tune):
        if tune in [&#39;auto&#39;]:
            tune = 50
        else:
            raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(tune))
    elif pl.isint(tune):
        if tune &lt; 0:
            raise ValueError(&#39;`tune` ({}) must be &gt; 0&#39;.format(
                tune))
    else:
        raise TypeError(&#39;`tune` ({}) type not recognized&#39;.format(type(tune)))
    self.tune = tune

    if pl.isstr(end_tune):
        if end_tune in [&#39;auto&#39;, &#39;half-burnin&#39;]:
            end_tune = int(self.G.inference.burnin/2)
        else:
            raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(end_tune))
    elif pl.isint(end_tune):
        if end_tune &lt; 0 or end_tune &gt; self.G.inference.burnin:
            raise ValueError(&#39;`end_tune` ({}) out of range (0, {})&#39;.format(
                end_tune, self.G.inference.burnin))
    else:
        raise TypeError(&#39;`end_tune` ({}) type not recognized&#39;.format(type(end_tune)))
    self.end_tune = end_tune

    # Set the truncation settings
    if truncation_settings is None:
        truncation_settings = &#39;positive&#39;
    if pl.isstr(truncation_settings):
        if truncation_settings == &#39;positive&#39;:
            self.low = 0.
            self.high = float(&#39;inf&#39;)
        # elif truncation_settings == &#39;negative&#39;:
        #     self.low = float(&#39;-inf&#39;)
        #     self.high = 0
        elif truncation_settings == &#39;in-vivo&#39;:
            self.low = 0.1
            self.high = np.log(10)
        else:
            raise ValueError(&#39;`truncation_settings` ({}) not recognized&#39;.format(
                truncation_settings))
    elif pl.istuple(truncation_settings):
        if len(truncation_settings) != 2:
            raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
        l,h = truncation_settings

        if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
            raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                type(l), type(h)))
        if l &lt; 0 or h &lt; 0:
            raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
        if h &lt;= l:
            raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
        self.high = h
        self.low = l
    else:
        raise TypeError(&#39;`truncation_settings` ({}) type not recognized&#39;)
    self.proposal.high = self.high
    self.proposal.low = self.low

    # Set the mean
    if not pl.isstr(mean_option):
        raise TypeError(&#39;`mean_option` ({}) must be a str&#39;.format(type(mean_option)))
    if mean_option == &#39;manual&#39;:
        if not pl.isnumeric(mean):
            raise TypeError(&#39;`mean` ({}) must be a numeric&#39;.format(type(mean)))
    elif mean_option in [&#39;auto&#39;, &#39;median-linear-regression&#39;]:
        # Perform linear regression
        if self.child_name == STRNAMES.GROWTH_VALUE:
            rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            lhs = []
        else:
            rhs = [STRNAMES.SELF_INTERACTION_VALUE]
            lhs = [STRNAMES.GROWTH_VALUE]
        X = self.G.data.construct_rhs(keys=rhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(keys=lhs, 
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)

        prec = X.T @ X
        cov = pinv(prec, self)
        mean = cov @ X.T @ y

        if self.child_name == STRNAMES.GROWTH_VALUE:
            mean = np.median(mean[:self.G.data.n_asvs])
        else:
            mean = np.median(mean)
    else:
        raise ValueError(&#39;`mean_option` ({}) not recognized&#39;.format(mean_option))
    self.prior.mean.override_value(mean)

    # Set the var
    if not pl.isstr(var_option):
        raise TypeError(&#39;`var_option` ({}) must be a str&#39;.format(type(var_option)))
    if var_option == &#39;manual&#39;:
        if not pl.isnumeric(var):
            raise TypeError(&#39;`var` ({}) must be a numeric&#39;.format(type(var)))
    elif var_option in [&#39;auto&#39;, &#39;diffuse-linear-regression&#39;]:
        # Perform linear regression
        if self.child_name == STRNAMES.GROWTH_VALUE:
            rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            lhs = []
        else:
            rhs = [STRNAMES.SELF_INTERACTION_VALUE]
            lhs = [STRNAMES.GROWTH_VALUE]
        X = self.G.data.construct_rhs(keys=rhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(keys=lhs, 
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)

        prec = X.T @ X
        cov = pinv(prec, self)
        mean = cov @ X.T @ y

        if self.child_name == STRNAMES.GROWTH_VALUE:
            mean = np.median(mean[:self.G.data.n_asvs])
        else:
            mean = np.median(mean)
        var = 1e4 * (mean**2)
    else:
        raise ValueError(&#39;`var_option` ({}) not recognized&#39;.format(var_option))
    self.prior.var.override_value(var)

    # Set the value
    if not pl.isstr(value_option):
        raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
    if value_option == &#39;manual&#39;:
        if not pl.isnumeric(value):
            raise TypeError(&#39;`value` ({}) must be a numeric&#39;.format(type(value)))
    elif value_option in [&#39;linear-regression&#39;]:
        # Perform linear regression
        if self.child_name == STRNAMES.GROWTH_VALUE:
            rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            lhs = []
        else:
            rhs = [STRNAMES.SELF_INTERACTION_VALUE]
            lhs = [STRNAMES.GROWTH_VALUE]
        X = self.G.data.construct_rhs(keys=rhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(keys=lhs, 
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)

        prec = X.T @ X
        cov = pinv(prec, self)
        mean = cov @ X.T @ y

        if self.child_name == STRNAMES.GROWTH_VALUE:
            value = mean[:self.G.data.n_asvs]
        else:
            value = mean
    elif value_option in [&#39;auto&#39;, &#39;prior-mean&#39;]:
        value = self.prior.mean.value
    else:
        raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
    self.value = value

    # Set the proposal variance
    if not pl.isstr(proposal_option):
        raise TypeError(&#39;`proposal_option` ({}) must be a str&#39;.format(
            type(proposal_option)))
    elif proposal_option == &#39;manual&#39;:
        if not pl.isnumeric(proposal_var):
            raise TypeError(&#39;`proposal_var` ({}) must be a numeric&#39;.format(
                type(proposal_var)))
        if proposal_var &lt;= 0:
            raise ValueError(&#39;`proposal_var` ({}) not proper&#39;.format(proposal_var))
    elif proposal_option in [&#39;auto&#39;]:
        proposal_var = (self.value ** 2)/10
    else:
        raise ValueError(&#39;`proposal_option` ({}) not recognized&#39;.format(
            proposal_option))
    self.proposal.var.value = proposal_var</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.PriorMeanMH.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>First we check if we need to tune the var, which we do during
the first half of burnin. We calculate the likelihoods in logspace</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#39;&#39;&#39;First we check if we need to tune the var, which we do during
    the first half of burnin. We calculate the likelihoods in logspace
    &#39;&#39;&#39;
    if self.sample_iter &lt; self.delay:
        return
    self.update_var()
    proposal_std = np.sqrt(self.proposal.var.value)

    # Get necessary data of the respective parameter
    variable = self.G[self.child_name]
    x = variable.value.ravel()
    std = np.sqrt(variable.prior.var.value)

    low = variable.low
    high = variable.high

    # propose a new value for the mean
    prev_mean = self.value
    self.proposal.mean.value = self.value
    new_mean = self.proposal.sample() # Sample a new value

    # Calculate the target distribution ll
    prev_target_ll = pl.random.truncnormal.logpdf( 
        value=prev_mean, mean=self.prior.mean.value, 
        std=np.sqrt(self.prior.var.value), low=self.low,
        high=self.high)
    for i in range(len(x)):
        prev_target_ll += pl.random.truncnormal.logpdf(
            value=x[i], mean=prev_mean, std=std,
            low=low, high=high)
    new_target_ll = pl.random.truncnormal.logpdf( 
        value=new_mean, mean=self.prior.mean.value, 
        std=np.sqrt(self.prior.var.value), low=self.low,
        high=self.high)
    for i in range(len(x)):
        new_target_ll += pl.random.truncnormal.logpdf(
            value=x[i], mean=new_mean, std=std,
            low=low, high=high)

    # Normalize by the ll of the proposal
    prev_prop_ll = pl.random.truncnormal.logpdf(
        value=prev_mean, mean=new_mean, std=proposal_std,
        low=low, high=high)
    
    new_prop_ll = pl.random.truncnormal.logpdf(
        value=new_mean, mean=prev_mean, std=proposal_std,
        low=low, high=high)

    # Accept or reject
    r = (new_target_ll - prev_prop_ll) - \
        (prev_target_ll - new_prop_ll)
    u = np.log(pl.random.misc.fast_sample_standard_uniform())

    # print(&#39;\n\n\n{} prior_mean\n----------&#39;.format(self.child_name))
    # print(&#39;x&#39;, x)
    # print(&#39;prev_mean&#39;, prev_mean)
    # print(&#39;prev_target_ll&#39;, prev_target_ll)
    # print(&#39;prev_prop_ll&#39;, prev_prop_ll)
    # print(&#39;new mean&#39;, new_mean)
    # print(&#39;new_target_ll&#39;, new_target_ll)
    # print(&#39;new_prop_ll&#39;, new_prop_ll)
    # print(&#39;\nr&#39;, r, u)

    if r &gt;= u:
        self.acceptances[self.sample_iter] = True
        self.value = new_mean
        self.temp_acceptances += 1
    else:
        self.value = prev_mean</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.PriorMeanMH.update_var"><code class="name flex">
<span>def <span class="ident">update_var</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the <code>var</code> parameter so that we adjust the acceptance
rate to <code>target_acceptance_rate</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_var(self):
    &#39;&#39;&#39;Update the `var` parameter so that we adjust the acceptance
    rate to `target_acceptance_rate`
    &#39;&#39;&#39;
    if self.sample_iter == 0:
        self.temp_acceptances = 0
        self.acceptances = np.zeros(self.G.inference.n_samples, dtype=bool)
    
    elif self.sample_iter &gt; self.end_tune:
        # Don&#39;t do any more updates
        return
    
    elif self.sample_iter % self.tune == 0:
        # Update var
        acceptance_rate = self.temp_acceptances / self.tune
        if acceptance_rate &gt; self.target_acceptance_rate:
            self.proposal.var.value *= 1.5
        else:
            self.proposal.var.value /= 1.5
        self.temp_acceptances = 0</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.PriorMeanMH.visualize_posterior"><code class="name flex">
<span>def <span class="ident">visualize_posterior</span></span>(<span>self, path, f, section='posterior')</span>
</code></dt>
<dd>
<div class="desc"><p>Render the traces in the folder <code>basepath</code> and write the
learned values to the file <code>f</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the path to write the files to</dd>
<dt><strong><code>f</code></strong> :&ensp;<code>_io.TextIOWrapper</code></dt>
<dd>File that we are writing the values to</dd>
<dt><strong><code>section</code></strong> :&ensp;<code>str</code></dt>
<dd>Section of the trace to compute on. Options:
'posterior' : posterior samples
'burnin' : burn-in samples
'entire' : both burn-in and posterior samples</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>_io.TextIOWrapper</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualize_posterior(self, path, f, section=&#39;posterior&#39;):
    &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
    learned values to the file `f`.

    Parameters
    ----------
    path : str
        This is the path to write the files to
    f : _io.TextIOWrapper
        File that we are writing the values to
    section : str
        Section of the trace to compute on. Options:
            &#39;posterior&#39; : posterior samples
            &#39;burnin&#39; : burn-in samples
            &#39;entire&#39; : both burn-in and posterior samples

    Returns
    -------
    _io.TextIOWrapper
    &#39;&#39;&#39;
    f.write(&#39;\n\n###################################\n&#39;)
    f.write(self.name)
    f.write(&#39;\n###################################\n&#39;)
    if not self.G.inference.tracer.is_being_traced(self):
        f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
        return f
    summ = pl.summary(self, section=section)
    for k,v in summ.items():
        f.write(&#39;\t{}: {}\n&#39;.format(k,v))

    # Plot the traces
    ax1, ax2 = visualization.render_trace(var=self, plt_type=&#39;both&#39;, section=section,
        include_burnin=True, log_scale=True, rasterized=True)

    # Plot the prior over the posterior
    l,h = ax1.get_xlim()
    xs = np.arange(l,h,step=(h-l)/100) 
    ys = []
    for x in xs:
        ys.append(pl.random.sics.pdf(value=x, 
            dof=self.prior.dof.value,
            scale=self.prior.scale.value))
    ax1.plot(xs, ys, label=&#39;prior&#39;, alpha=0.5, color=&#39;red&#39;, rasterized=True)
    ax1.legend()

    # Plot the acceptance rate over the trace
    ax3 = ax2.twinx()
    ax3 = visualization.render_acceptance_rate_trace(var=self, ax=ax3, 
        label=&#39;Acceptance Rate&#39;, color=&#39;red&#39;, scatter=False, rasterized=True)
    ax3.legend()
    fig = plt.gcf()
    fig.tight_layout()
    fig.suptitle(self.name)
    plt.savefig(path)
    plt.close()

    return f</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.TruncatedNormal" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal">TruncatedNormal</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.cdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.cdf">cdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.logcdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.logcdf">logcdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.logpdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.logpdf">logpdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.pdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.pdf">pdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.sample" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.logistic_growth.PriorVarMH"><code class="flex name class">
<span>class <span class="ident">PriorVarMH</span></span>
<span>(</span><span>prior, child_name, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the posterior for the prior variance of either the growth
or self-interaction parameter. We update with a MH update since this
prior is not conjugate.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>prior</code></strong> :&ensp;<code>pl.variables.SICS</code></dt>
<dd>This is the prior of this distribution - which is a Squared
Inverse Chi Squared (SICS) distribution</dd>
<dt><strong><code>child_name</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the name of the variable that this is a prior variance
for. This is either the name of the growth parameter or the
self-interactions parameter</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>These are the other parameters for the initialization.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PriorVarMH(pl.variables.SICS):
    &#39;&#39;&#39;This is the posterior for the prior variance of either the growth
    or self-interaction parameter. We update with a MH update since this 
    prior is not conjugate.

    Parameters
    ----------
    prior : pl.variables.SICS
        This is the prior of this distribution - which is a Squared
        Inverse Chi Squared (SICS) distribution
    child_name : str
        This is the name of the variable that this is a prior variance
        for. This is either the name of the growth parameter or the 
        self-interactions parameter
    kwargs : dict
        These are the other parameters for the initialization.
    &#39;&#39;&#39;

    def __init__(self, prior, child_name, **kwargs):
        if child_name == STRNAMES.GROWTH_VALUE:
            kwargs[&#39;name&#39;] = STRNAMES.PRIOR_VAR_GROWTH
        elif child_name == STRNAMES.SELF_INTERACTION_VALUE:
            kwargs[&#39;name&#39;] = STRNAMES.PRIOR_VAR_SELF_INTERACTIONS
        else:
            raise ValueError(&#39;`child_name` ({}) not recognized&#39;.format(child_name))
        pl.variables.SICS.__init__(self, dtype=float, **kwargs)
        self.child_name = child_name
        self.add_prior(prior)
        self.proposal = pl.variables.SICS(dof=None, scale=None, value=None)

    def __str__(self):
        # If this fails, it is because we are dividing by 0 sampler_iter
        # If which case we just return the value 
        try:
            s = &#39;Value: {}, Acceptance rate: {}&#39;.format(
                self.value, np.mean(self.acceptances[
                    np.max([self.sample_iter-50, 0]):self.sample_iter]))
        except:
            s = str(self.value)
        return s

    def initialize(self, value_option, dof_option, scale_option, 
        proposal_option, target_acceptance_rate, tune, end_tune,
        value=None, dof=None, scale=None, proposal_dof=None, delay=0):
        &#39;&#39;&#39;Initialize the parameters of the distribution and the 
        proposal distribution

        Parameters
        ----------
        value_option : str
            Different ways to initialize the values
            Options
                &#39;manual&#39;
                    Set the value manually, `value` must also be specified
                &#39;unregularized&#39;
                    Do unregularized regression and the value is set to the
                    variance of the growth values
                &#39;prior-mean&#39;, &#39;auto&#39;
                    Set the value to the prior of the mean
        scale_option : str
            Different ways to initialize the scale of the prior
            Options
                &#39;manual&#39;
                    Set the value manually, `scale` must also be specified
                &#39;auto&#39;, &#39;inflated-median&#39;
                    We set the scale such that the mean of the prior is
                    equal to the median growth values calculated
                    with linear regression squared and inflated by 100.
        dof_option : str
            How informative the prior should be (setting the dof)
                &#39;diffuse&#39;: set to the mimumum value (2)
                &#39;weak&#39;: set so that 10% of the posterior comes from the prior
                &#39;strong&#39;: set so that 50% of the posterior comes from the prior
                &#39;manual&#39;: set to the value provided in the parameter `shape`
                &#39;auto&#39;: Set to &#39;weak&#39;
        proposal_option : str
            How to set the initial dof of the proposal - this will get adjusted with
            tuning
                &#39;tight&#39;, &#39;auto&#39;
                    Set the dof to be 15, relatively strong initially
                &#39;diffuse&#39;
                    Set the dof to be 2.5, relatively diffuse initially
                &#39;manual&#39;
                    Set the dof with the parameter `proposal_dof&#39;
        target_acceptance_rate : float, str
            This is the target_acceptance rate. Options:
                &#39;auto&#39;, &#39;optimal&#39;
                    Set to 0.44
                float
                    This is the value you want
        tune : str, int
            This is how often you want to update the proposal dof
                int
                &#39;auto&#39;
                    Set to every 50 iterations
        end_tune : str, int
            This is when to stop the tuning
                &#39;half-burnin&#39;, &#39;auto&#39;
                    Half of burnin, rounded down
                int
        delay : int
            How many iterations to delay updating the value of the variance
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Set the proposal dof
        if not pl.isstr(proposal_option):
            raise TypeError(&#39;`proposal_option` ({}) must be a str&#39;.format(
                type(proposal_option)))
        elif proposal_option == &#39;manual&#39;:
            if not pl.isnumeric(proposal_dof):
                raise TypeError(&#39;`proposal_dof` ({}) must be a numeric&#39;.format(
                    type(proposal_dof)))
            if proposal_dof &lt; 2:
                raise ValueError(&#39;`proposal_dof` ({}) not proper&#39;.format(proposal_dof))
        elif proposal_option in [&#39;tight&#39;, &#39;auto&#39;]:
            proposal_dof = 15
        elif proposal_option == &#39;diffuse&#39;:
            proposal_dof = 2.5
        else:
            raise ValueError(&#39;`proposal_option` ({}) not recognized&#39;.format(
                proposal_option))
        self.proposal.dof.value = proposal_dof

        # Set the propsal parameters
        if pl.isstr(target_acceptance_rate):
            if target_acceptance_rate in [&#39;optimal&#39;, &#39;auto&#39;]:
                target_acceptance_rate = 0.44
            else:
                raise ValueError(&#39;`target_acceptance_rate` ({}) not recognized&#39;.format(
                    target_acceptance_rate))
        elif pl.isfloat(target_acceptance_rate):
            if target_acceptance_rate &lt; 0 or target_acceptance_rate &gt; 1:
                raise ValueError(&#39;`target_acceptance_rate` ({}) out of range&#39;.format(
                    target_acceptance_rate))
        else:
            raise TypeError(&#39;`target_acceptance_rate` ({}) type not recognized&#39;.format(
                type(target_acceptance_rate)))
        self.target_acceptance_rate = target_acceptance_rate

        if pl.isstr(tune):
            if tune in [&#39;auto&#39;]:
                tune = 50
            else:
                raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(tune))
        elif pl.isint(tune):
            if tune &lt; 0:
                raise ValueError(&#39;`tune` ({}) must be &gt; 0&#39;.format(
                    tune))
        else:
            raise TypeError(&#39;`tune` ({}) type not recognized&#39;.format(type(tune)))
        self.tune = tune

        if pl.isstr(end_tune):
            if end_tune in [&#39;auto&#39;, &#39;half-burnin&#39;]:
                end_tune = int(self.G.inference.burnin/2)
            else:
                raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(end_tune))
        elif pl.isint(end_tune):
            if end_tune &lt; 0 or end_tune &gt; self.G.inference.burnin:
                raise ValueError(&#39;`end_tune` ({}) out of range (0, {})&#39;.format(
                    end_tune, self.G.inference.burnin))
        else:
            raise TypeError(&#39;`end_tune` ({}) type not recognized&#39;.format(type(end_tune)))
        self.end_tune = end_tune

        # Set the prior dof
        if not pl.isstr(dof_option):
            raise TypeError(&#39;`dof_option` ({}) must be a str&#39;.format(type(dof_option)))
        if dof_option == &#39;manual&#39;:
            if not pl.isnumeric(dof):
                raise TypeError(&#39;`dof` ({}) must be a numeric&#39;.format(type(dof)))
            if dof &lt; 2:
                raise ValueError(&#39;`dof` ({}) must be &gt;= 2&#39;.format(dof))
        elif dof_option == &#39;diffuse&#39;:
            dof = 2.5
        elif dof_option in [&#39;weak&#39;, &#39;auto&#39;]:
            dof = len(self.G.data.asvs)/9
        elif dof_option == &#39;strong&#39;:
            dof = len(self.G.data.asvs)/2
        else:
            raise ValueError(&#39;`dof_option` ({}) not recognized&#39;.format(dof_option))
        if dof &lt; 2:
            raise ValueError(&#39;`dof` ({}) must be strictly larger than 2 to be a proper&#39; \
                &#39; prior&#39;.format(dof))
        self.prior.dof.override_value(dof)

        # Set the prior scale
        if not pl.isstr(scale_option):
            raise TypeError(&#39;`scale_option` ({}) must be a str&#39;.format(type(scale_option)))
        if scale_option == &#39;manual&#39;:
            if not pl.isnumeric(scale):
                raise TypeError(&#39;`scale` ({}) must be a numeric&#39;.format(type(scale)))
            if scale &lt;= 0:
                raise ValueError(&#39;`scale` ({}) must be positive&#39;.format(scale))
        elif scale_option in [&#39;auto&#39;, &#39;inflated-median&#39;]:
            # Perform linear regression
            rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y
            if self.child_name == STRNAMES.GROWTH_VALUE:
                mean = 1e4*(np.median(mean[:self.G.data.n_asvs]) ** 2)
            else:
                mean = 1e4*(np.median(mean[self.G.data.n_asvs:]) ** 2)

            # Calculate the scale
            scale = mean * (self.prior.dof.value - 2) / self.prior.dof.value
        else:
            raise ValueError(&#39;`scale_option` ({}) not recognized&#39;.format(scale_option))
        self.prior.scale.override_value(scale)

        # Set the initial value of the prior
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isnumeric(value):
                raise ValueError(&#39;If `value_option` == &#34;manual&#34;, value ({}) &#39; \
                    &#39;must be a numeric (float, int)&#39;.format(value.__class__))
        elif value_option in [&#39;inflated-median&#39;]:
            # No interactions
            rhs = [
                STRNAMES.GROWTH_VALUE,
                STRNAMES.SELF_INTERACTION_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y
            if self.child_name == STRNAMES.GROWTH_VALUE:
                value = 1e4*(np.median(mean[:self.G.data.n_asvs]) ** 2)
            else:
                value = 1e4*(np.median(mean[self.G.data.n_asvs:]) ** 2)
        elif value_option in [&#39;prior-mean&#39;, &#39;auto&#39;]:
            value = self.prior.mean()
        else:
            raise ValueError(&#39;`value_option` &#34;{}&#34; not recognized&#39;.format(value_option))
        self.value = value

    def update_dof(self):
        &#39;&#39;&#39;Updat the `dof` parameter so that we adjust the acceptance
        rate to `target_acceptance_rate`
        &#39;&#39;&#39;
        if self.sample_iter == 0:
            self.temp_acceptances = 0
            self.acceptances = np.zeros(self.G.inference.n_samples, dtype=bool)
        
        elif self.sample_iter &gt; self.end_tune:
            # Don&#39;t do any more updates
            return
        
        elif self.sample_iter % self.tune == 0:
            # Update dof
            acceptance_rate = self.temp_acceptances / self.tune
            if acceptance_rate &gt; self.target_acceptance_rate:
                self.proposal.dof.value = self.proposal.dof.value * 1.5
            else:
                self.proposal.dof.value = self.proposal.dof.value / 1.5
            self.temp_acceptances = 0

    def update(self):
        &#39;&#39;&#39;First we check if we need to tune the dof, which we do during
        the first half of burnin. We calculate the likelihoods in logspace
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return
        self.update_dof()

        # Get necessary data of the respective parameter
        var = self.G[self.child_name]
        x = var.value.ravel()
        mu = var.prior.mean.value
        low = var.low
        high = var.high

        # propose a new value
        prev_value = self.value
        prev_value_std = math.sqrt(prev_value)
        self.proposal.scale.value = self.value
        new_value = self.proposal.sample() # Sample a new value
        new_value_std = math.sqrt(new_value)

        # Calculate the target distribution ll
        prev_target_ll = 0
        for i in range(len(x)):
            prev_target_ll += pl.random.truncnormal.logpdf(
                value=x[i], mean=mu, std=prev_value_std,
                low=low, high=high)
        new_target_ll = 0
        for i in range(len(x)):
            new_target_ll += pl.random.truncnormal.logpdf(
                value=x[i], mean=mu, std=new_value_std,
                low=low, high=high)

        # Normalize by the ll of the proposal
        prev_prop_ll = self.proposal.logpdf(value=prev_value)
        new_prop_ll = self.proposal.logpdf(value=new_value)

        # Accept or reject
        r = (new_target_ll - prev_prop_ll) - \
            (prev_target_ll - new_prop_ll)
        u = np.log(pl.random.misc.fast_sample_standard_uniform())

        # print(&#39;\n\n\n{} prior_var\n----------&#39;.format(self.child_name))
        # print(&#39;prev_value&#39;, prev_value)
        # print(&#39;prev_target_ll&#39;, prev_target_ll)
        # print(&#39;prev_prop_ll&#39;, prev_prop_ll)
        # print(&#39;new value&#39;, new_value)
        # print(&#39;new_target_ll&#39;, new_target_ll)
        # print(&#39;new_prop_ll&#39;, new_prop_ll)
        # print(&#39;mu&#39;, mu)
        # print(&#39;prev_value_std&#39;, prev_value_std)
        # print(&#39;new_value_std&#39;, new_value_std)
        # print(&#39;\nr&#39;, r, u)

        if r &gt;= u:
            self.acceptances[self.sample_iter] = True
            self.value = new_value
            self.temp_acceptances += 1
        else:
            self.value = prev_value

    def visualize_posterior(self, path, f, section=&#39;posterior&#39;):
        &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
        learned values to the file `f`.

        Parameters
        ----------
        path : str
            This is the path to write the files to
        f : _io.TextIOWrapper
            File that we are writing the values to
        section : str
            Section of the trace to compute on. Options:
                &#39;posterior&#39; : posterior samples
                &#39;burnin&#39; : burn-in samples
                &#39;entire&#39; : both burn-in and posterior samples

        Returns
        -------
        _io.TextIOWrapper
        &#39;&#39;&#39;
        f.write(&#39;\n\n###################################\n&#39;)
        f.write(self.name)
        f.write(&#39;\n###################################\n&#39;)
        if not self.G.inference.tracer.is_being_traced(self):
            f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
            return f
        summ = pl.summary(self, section=section)
        for k,v in summ.items():
            f.write(&#39;\t{}: {}\n&#39;.format(k,v))

        # Plot the traces
        ax1, ax2 = visualization.render_trace(var=self, plt_type=&#39;both&#39;, section=section,
            include_burnin=True, log_scale=True, rasterized=True)

        # Plot the prior over the posterior
        l,h = ax1.get_xlim()
        xs = np.arange(l,h,step=(h-l)/100) 
        ys = []
        for x in xs:
            ys.append(pl.random.sics.pdf(value=x, 
                dof=self.prior.dof.value,
                scale=self.prior.scale.value))
        ax1.plot(xs, ys, label=&#39;prior&#39;, alpha=0.5, color=&#39;red&#39;, rasterized=True)
        ax1.legend()

        # Plot the acceptance rate over the trace
        ax3 = ax2.twinx()
        ax3 = visualization.render_acceptance_rate_trace(var=self, ax=ax3, 
            label=&#39;Acceptance Rate&#39;, color=&#39;red&#39;, scatter=False, rasterized=True)
        ax3.legend()
        fig = plt.gcf()
        fig.tight_layout()
        fig.suptitle(self.name)
        plt.savefig(path)
        plt.close()

        return f</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.SICS" href="pylab/variables.html#mdsine2.pylab.variables.SICS">SICS</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.logistic_growth.PriorVarMH.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, value_option, dof_option, scale_option, proposal_option, target_acceptance_rate, tune, end_tune, value=None, dof=None, scale=None, proposal_dof=None, delay=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the parameters of the distribution and the
proposal distribution</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>value_option</code></strong> :&ensp;<code>str</code></dt>
<dd>Different ways to initialize the values
Options
'manual'
Set the value manually, <code>value</code> must also be specified
'unregularized'
Do unregularized regression and the value is set to the
variance of the growth values
'prior-mean', 'auto'
Set the value to the prior of the mean</dd>
<dt><strong><code>scale_option</code></strong> :&ensp;<code>str</code></dt>
<dd>Different ways to initialize the scale of the prior
Options
'manual'
Set the value manually, <code>scale</code> must also be specified
'auto', 'inflated-median'
We set the scale such that the mean of the prior is
equal to the median growth values calculated
with linear regression squared and inflated by 100.</dd>
<dt><strong><code>dof_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How informative the prior should be (setting the dof)
'diffuse': set to the mimumum value (2)
'weak': set so that 10% of the posterior comes from the prior
'strong': set so that 50% of the posterior comes from the prior
'manual': set to the value provided in the parameter <code>shape</code>
'auto': Set to 'weak'</dd>
<dt><strong><code>proposal_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to set the initial dof of the proposal - this will get adjusted with
tuning
'tight', 'auto'
Set the dof to be 15, relatively strong initially
'diffuse'
Set the dof to be 2.5, relatively diffuse initially
'manual'
Set the dof with the parameter `proposal_dof'</dd>
<dt><strong><code>target_acceptance_rate</code></strong> :&ensp;<code>float, str</code></dt>
<dd>This is the target_acceptance rate. Options:
'auto', 'optimal'
Set to 0.44
float
This is the value you want</dd>
<dt><strong><code>tune</code></strong> :&ensp;<code>str, int</code></dt>
<dd>This is how often you want to update the proposal dof
int
'auto'
Set to every 50 iterations</dd>
<dt><strong><code>end_tune</code></strong> :&ensp;<code>str, int</code></dt>
<dd>This is when to stop the tuning
'half-burnin', 'auto'
Half of burnin, rounded down
int</dd>
<dt><strong><code>delay</code></strong> :&ensp;<code>int</code></dt>
<dd>How many iterations to delay updating the value of the variance</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, value_option, dof_option, scale_option, 
    proposal_option, target_acceptance_rate, tune, end_tune,
    value=None, dof=None, scale=None, proposal_dof=None, delay=0):
    &#39;&#39;&#39;Initialize the parameters of the distribution and the 
    proposal distribution

    Parameters
    ----------
    value_option : str
        Different ways to initialize the values
        Options
            &#39;manual&#39;
                Set the value manually, `value` must also be specified
            &#39;unregularized&#39;
                Do unregularized regression and the value is set to the
                variance of the growth values
            &#39;prior-mean&#39;, &#39;auto&#39;
                Set the value to the prior of the mean
    scale_option : str
        Different ways to initialize the scale of the prior
        Options
            &#39;manual&#39;
                Set the value manually, `scale` must also be specified
            &#39;auto&#39;, &#39;inflated-median&#39;
                We set the scale such that the mean of the prior is
                equal to the median growth values calculated
                with linear regression squared and inflated by 100.
    dof_option : str
        How informative the prior should be (setting the dof)
            &#39;diffuse&#39;: set to the mimumum value (2)
            &#39;weak&#39;: set so that 10% of the posterior comes from the prior
            &#39;strong&#39;: set so that 50% of the posterior comes from the prior
            &#39;manual&#39;: set to the value provided in the parameter `shape`
            &#39;auto&#39;: Set to &#39;weak&#39;
    proposal_option : str
        How to set the initial dof of the proposal - this will get adjusted with
        tuning
            &#39;tight&#39;, &#39;auto&#39;
                Set the dof to be 15, relatively strong initially
            &#39;diffuse&#39;
                Set the dof to be 2.5, relatively diffuse initially
            &#39;manual&#39;
                Set the dof with the parameter `proposal_dof&#39;
    target_acceptance_rate : float, str
        This is the target_acceptance rate. Options:
            &#39;auto&#39;, &#39;optimal&#39;
                Set to 0.44
            float
                This is the value you want
    tune : str, int
        This is how often you want to update the proposal dof
            int
            &#39;auto&#39;
                Set to every 50 iterations
    end_tune : str, int
        This is when to stop the tuning
            &#39;half-burnin&#39;, &#39;auto&#39;
                Half of burnin, rounded down
            int
    delay : int
        How many iterations to delay updating the value of the variance
    &#39;&#39;&#39;
    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    self.delay = delay

    # Set the proposal dof
    if not pl.isstr(proposal_option):
        raise TypeError(&#39;`proposal_option` ({}) must be a str&#39;.format(
            type(proposal_option)))
    elif proposal_option == &#39;manual&#39;:
        if not pl.isnumeric(proposal_dof):
            raise TypeError(&#39;`proposal_dof` ({}) must be a numeric&#39;.format(
                type(proposal_dof)))
        if proposal_dof &lt; 2:
            raise ValueError(&#39;`proposal_dof` ({}) not proper&#39;.format(proposal_dof))
    elif proposal_option in [&#39;tight&#39;, &#39;auto&#39;]:
        proposal_dof = 15
    elif proposal_option == &#39;diffuse&#39;:
        proposal_dof = 2.5
    else:
        raise ValueError(&#39;`proposal_option` ({}) not recognized&#39;.format(
            proposal_option))
    self.proposal.dof.value = proposal_dof

    # Set the propsal parameters
    if pl.isstr(target_acceptance_rate):
        if target_acceptance_rate in [&#39;optimal&#39;, &#39;auto&#39;]:
            target_acceptance_rate = 0.44
        else:
            raise ValueError(&#39;`target_acceptance_rate` ({}) not recognized&#39;.format(
                target_acceptance_rate))
    elif pl.isfloat(target_acceptance_rate):
        if target_acceptance_rate &lt; 0 or target_acceptance_rate &gt; 1:
            raise ValueError(&#39;`target_acceptance_rate` ({}) out of range&#39;.format(
                target_acceptance_rate))
    else:
        raise TypeError(&#39;`target_acceptance_rate` ({}) type not recognized&#39;.format(
            type(target_acceptance_rate)))
    self.target_acceptance_rate = target_acceptance_rate

    if pl.isstr(tune):
        if tune in [&#39;auto&#39;]:
            tune = 50
        else:
            raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(tune))
    elif pl.isint(tune):
        if tune &lt; 0:
            raise ValueError(&#39;`tune` ({}) must be &gt; 0&#39;.format(
                tune))
    else:
        raise TypeError(&#39;`tune` ({}) type not recognized&#39;.format(type(tune)))
    self.tune = tune

    if pl.isstr(end_tune):
        if end_tune in [&#39;auto&#39;, &#39;half-burnin&#39;]:
            end_tune = int(self.G.inference.burnin/2)
        else:
            raise ValueError(&#39;`tune` ({}) not recognized&#39;.format(end_tune))
    elif pl.isint(end_tune):
        if end_tune &lt; 0 or end_tune &gt; self.G.inference.burnin:
            raise ValueError(&#39;`end_tune` ({}) out of range (0, {})&#39;.format(
                end_tune, self.G.inference.burnin))
    else:
        raise TypeError(&#39;`end_tune` ({}) type not recognized&#39;.format(type(end_tune)))
    self.end_tune = end_tune

    # Set the prior dof
    if not pl.isstr(dof_option):
        raise TypeError(&#39;`dof_option` ({}) must be a str&#39;.format(type(dof_option)))
    if dof_option == &#39;manual&#39;:
        if not pl.isnumeric(dof):
            raise TypeError(&#39;`dof` ({}) must be a numeric&#39;.format(type(dof)))
        if dof &lt; 2:
            raise ValueError(&#39;`dof` ({}) must be &gt;= 2&#39;.format(dof))
    elif dof_option == &#39;diffuse&#39;:
        dof = 2.5
    elif dof_option in [&#39;weak&#39;, &#39;auto&#39;]:
        dof = len(self.G.data.asvs)/9
    elif dof_option == &#39;strong&#39;:
        dof = len(self.G.data.asvs)/2
    else:
        raise ValueError(&#39;`dof_option` ({}) not recognized&#39;.format(dof_option))
    if dof &lt; 2:
        raise ValueError(&#39;`dof` ({}) must be strictly larger than 2 to be a proper&#39; \
            &#39; prior&#39;.format(dof))
    self.prior.dof.override_value(dof)

    # Set the prior scale
    if not pl.isstr(scale_option):
        raise TypeError(&#39;`scale_option` ({}) must be a str&#39;.format(type(scale_option)))
    if scale_option == &#39;manual&#39;:
        if not pl.isnumeric(scale):
            raise TypeError(&#39;`scale` ({}) must be a numeric&#39;.format(type(scale)))
        if scale &lt;= 0:
            raise ValueError(&#39;`scale` ({}) must be positive&#39;.format(scale))
    elif scale_option in [&#39;auto&#39;, &#39;inflated-median&#39;]:
        # Perform linear regression
        rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
        X = self.G.data.construct_rhs(keys=rhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(index_out_perturbations=True)

        prec = X.T @ X
        cov = pinv(prec, self)
        mean = cov @ X.T @ y
        if self.child_name == STRNAMES.GROWTH_VALUE:
            mean = 1e4*(np.median(mean[:self.G.data.n_asvs]) ** 2)
        else:
            mean = 1e4*(np.median(mean[self.G.data.n_asvs:]) ** 2)

        # Calculate the scale
        scale = mean * (self.prior.dof.value - 2) / self.prior.dof.value
    else:
        raise ValueError(&#39;`scale_option` ({}) not recognized&#39;.format(scale_option))
    self.prior.scale.override_value(scale)

    # Set the initial value of the prior
    if not pl.isstr(value_option):
        raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
    if value_option == &#39;manual&#39;:
        if not pl.isnumeric(value):
            raise ValueError(&#39;If `value_option` == &#34;manual&#34;, value ({}) &#39; \
                &#39;must be a numeric (float, int)&#39;.format(value.__class__))
    elif value_option in [&#39;inflated-median&#39;]:
        # No interactions
        rhs = [
            STRNAMES.GROWTH_VALUE,
            STRNAMES.SELF_INTERACTION_VALUE]
        X = self.G.data.construct_rhs(keys=rhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(index_out_perturbations=True)

        prec = X.T @ X
        cov = pinv(prec, self)
        mean = cov @ X.T @ y
        if self.child_name == STRNAMES.GROWTH_VALUE:
            value = 1e4*(np.median(mean[:self.G.data.n_asvs]) ** 2)
        else:
            value = 1e4*(np.median(mean[self.G.data.n_asvs:]) ** 2)
    elif value_option in [&#39;prior-mean&#39;, &#39;auto&#39;]:
        value = self.prior.mean()
    else:
        raise ValueError(&#39;`value_option` &#34;{}&#34; not recognized&#39;.format(value_option))
    self.value = value</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.PriorVarMH.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>First we check if we need to tune the dof, which we do during
the first half of burnin. We calculate the likelihoods in logspace</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#39;&#39;&#39;First we check if we need to tune the dof, which we do during
    the first half of burnin. We calculate the likelihoods in logspace
    &#39;&#39;&#39;
    if self.sample_iter &lt; self.delay:
        return
    self.update_dof()

    # Get necessary data of the respective parameter
    var = self.G[self.child_name]
    x = var.value.ravel()
    mu = var.prior.mean.value
    low = var.low
    high = var.high

    # propose a new value
    prev_value = self.value
    prev_value_std = math.sqrt(prev_value)
    self.proposal.scale.value = self.value
    new_value = self.proposal.sample() # Sample a new value
    new_value_std = math.sqrt(new_value)

    # Calculate the target distribution ll
    prev_target_ll = 0
    for i in range(len(x)):
        prev_target_ll += pl.random.truncnormal.logpdf(
            value=x[i], mean=mu, std=prev_value_std,
            low=low, high=high)
    new_target_ll = 0
    for i in range(len(x)):
        new_target_ll += pl.random.truncnormal.logpdf(
            value=x[i], mean=mu, std=new_value_std,
            low=low, high=high)

    # Normalize by the ll of the proposal
    prev_prop_ll = self.proposal.logpdf(value=prev_value)
    new_prop_ll = self.proposal.logpdf(value=new_value)

    # Accept or reject
    r = (new_target_ll - prev_prop_ll) - \
        (prev_target_ll - new_prop_ll)
    u = np.log(pl.random.misc.fast_sample_standard_uniform())

    # print(&#39;\n\n\n{} prior_var\n----------&#39;.format(self.child_name))
    # print(&#39;prev_value&#39;, prev_value)
    # print(&#39;prev_target_ll&#39;, prev_target_ll)
    # print(&#39;prev_prop_ll&#39;, prev_prop_ll)
    # print(&#39;new value&#39;, new_value)
    # print(&#39;new_target_ll&#39;, new_target_ll)
    # print(&#39;new_prop_ll&#39;, new_prop_ll)
    # print(&#39;mu&#39;, mu)
    # print(&#39;prev_value_std&#39;, prev_value_std)
    # print(&#39;new_value_std&#39;, new_value_std)
    # print(&#39;\nr&#39;, r, u)

    if r &gt;= u:
        self.acceptances[self.sample_iter] = True
        self.value = new_value
        self.temp_acceptances += 1
    else:
        self.value = prev_value</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.PriorVarMH.update_dof"><code class="name flex">
<span>def <span class="ident">update_dof</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Updat the <code>dof</code> parameter so that we adjust the acceptance
rate to <code>target_acceptance_rate</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_dof(self):
    &#39;&#39;&#39;Updat the `dof` parameter so that we adjust the acceptance
    rate to `target_acceptance_rate`
    &#39;&#39;&#39;
    if self.sample_iter == 0:
        self.temp_acceptances = 0
        self.acceptances = np.zeros(self.G.inference.n_samples, dtype=bool)
    
    elif self.sample_iter &gt; self.end_tune:
        # Don&#39;t do any more updates
        return
    
    elif self.sample_iter % self.tune == 0:
        # Update dof
        acceptance_rate = self.temp_acceptances / self.tune
        if acceptance_rate &gt; self.target_acceptance_rate:
            self.proposal.dof.value = self.proposal.dof.value * 1.5
        else:
            self.proposal.dof.value = self.proposal.dof.value / 1.5
        self.temp_acceptances = 0</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.PriorVarMH.visualize_posterior"><code class="name flex">
<span>def <span class="ident">visualize_posterior</span></span>(<span>self, path, f, section='posterior')</span>
</code></dt>
<dd>
<div class="desc"><p>Render the traces in the folder <code>basepath</code> and write the
learned values to the file <code>f</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the path to write the files to</dd>
<dt><strong><code>f</code></strong> :&ensp;<code>_io.TextIOWrapper</code></dt>
<dd>File that we are writing the values to</dd>
<dt><strong><code>section</code></strong> :&ensp;<code>str</code></dt>
<dd>Section of the trace to compute on. Options:
'posterior' : posterior samples
'burnin' : burn-in samples
'entire' : both burn-in and posterior samples</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>_io.TextIOWrapper</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualize_posterior(self, path, f, section=&#39;posterior&#39;):
    &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
    learned values to the file `f`.

    Parameters
    ----------
    path : str
        This is the path to write the files to
    f : _io.TextIOWrapper
        File that we are writing the values to
    section : str
        Section of the trace to compute on. Options:
            &#39;posterior&#39; : posterior samples
            &#39;burnin&#39; : burn-in samples
            &#39;entire&#39; : both burn-in and posterior samples

    Returns
    -------
    _io.TextIOWrapper
    &#39;&#39;&#39;
    f.write(&#39;\n\n###################################\n&#39;)
    f.write(self.name)
    f.write(&#39;\n###################################\n&#39;)
    if not self.G.inference.tracer.is_being_traced(self):
        f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
        return f
    summ = pl.summary(self, section=section)
    for k,v in summ.items():
        f.write(&#39;\t{}: {}\n&#39;.format(k,v))

    # Plot the traces
    ax1, ax2 = visualization.render_trace(var=self, plt_type=&#39;both&#39;, section=section,
        include_burnin=True, log_scale=True, rasterized=True)

    # Plot the prior over the posterior
    l,h = ax1.get_xlim()
    xs = np.arange(l,h,step=(h-l)/100) 
    ys = []
    for x in xs:
        ys.append(pl.random.sics.pdf(value=x, 
            dof=self.prior.dof.value,
            scale=self.prior.scale.value))
    ax1.plot(xs, ys, label=&#39;prior&#39;, alpha=0.5, color=&#39;red&#39;, rasterized=True)
    ax1.legend()

    # Plot the acceptance rate over the trace
    ax3 = ax2.twinx()
    ax3 = visualization.render_acceptance_rate_trace(var=self, ax=ax3, 
        label=&#39;Acceptance Rate&#39;, color=&#39;red&#39;, scatter=False, rasterized=True)
    ax3.legend()
    fig = plt.gcf()
    fig.tight_layout()
    fig.suptitle(self.name)
    plt.savefig(path)
    plt.close()

    return f</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.SICS" href="pylab/variables.html#mdsine2.pylab.variables.SICS">SICS</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.SICS.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.logpdf" href="pylab/variables.html#mdsine2.pylab.variables.SICS.logpdf">logpdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.pdf" href="pylab/variables.html#mdsine2.pylab.variables.SICS.pdf">pdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.sample" href="pylab/variables.html#mdsine2.pylab.variables.SICS.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.logistic_growth.RegressCoeff"><code class="flex name class">
<span>class <span class="ident">RegressCoeff</span></span>
<span>(</span><span>growth, self_interactions, interactions, pert_mag, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the posterior of the regression coefficients.
The current posterior assumes a prior mean of 0.</p>
<p>This class samples the growth, self-interactions, and cluster
interactions jointly.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>growth</code></strong> :&ensp;<code>posterior.Growth</code></dt>
<dd>This is the class that has the growth variables</dd>
<dt><strong><code>self_interactions</code></strong> :&ensp;<code>posterior.SelfInteractions</code></dt>
<dd>The self interaction terms for the ASVs</dd>
<dt><strong><code>interactions</code></strong> :&ensp;<code>ClusterInteractionValue</code></dt>
<dd>These are the cluster interaction values</dd>
<dt><strong><code>pert_mag</code></strong> :&ensp;<code>PerturbationMagnitudes, None</code></dt>
<dd>These are the magnitudes of the perturbation parameters (per clsuter)
Set to None if there are no perturbations</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RegressCoeff(pl.variables.MVN):
    &#39;&#39;&#39;This is the posterior of the regression coefficients.
    The current posterior assumes a prior mean of 0.

    This class samples the growth, self-interactions, and cluster
    interactions jointly.

    Parameters
    ----------
    growth : posterior.Growth
        This is the class that has the growth variables
    self_interactions : posterior.SelfInteractions
        The self interaction terms for the ASVs
    interactions : ClusterInteractionValue
        These are the cluster interaction values
    pert_mag : PerturbationMagnitudes, None
        These are the magnitudes of the perturbation parameters (per clsuter)
        Set to None if there are no perturbations
    &#39;&#39;&#39;
    def __init__(self, growth, self_interactions, interactions,
        pert_mag, **kwargs):

        if not issubclass(growth.__class__, Growth):
            raise ValueError(&#39;`growth` ({}) must be a subclass of the Growth &#39; \
                &#39;class&#39;.format(type(growth)))
        if not issubclass(self_interactions.__class__, SelfInteractions):
            raise ValueError(&#39;`self_interactions` ({}) must be a subclass of the SelfInteractions &#39; \
                &#39;class&#39;.format(type(self_interactions)))
        if not issubclass(interactions.__class__, ClusterInteractionValue):
            raise ValueError(&#39;`interactions` ({}) must be a subclass of the Interactions &#39; \
                &#39;class&#39;.format(type(interactions)))
        if pert_mag is not None:
            if not issubclass(pert_mag.__class__, PerturbationMagnitudes):
                raise ValueError(&#39;`pert_mag` ({}) must be a subclass of the PerturbationMagnitudes &#39; \
                    &#39;class&#39;.format(type(pert_mag)))


        kwargs[&#39;name&#39;] = STRNAMES.GLV_PARAMETERS
        pl.variables.MVN.__init__(self, mean=None, cov=None, dtype=float, **kwargs)

        self.n_asvs = self.G.data.n_asvs
        self.growth = growth
        self.self_interactions = self_interactions
        self.interactions = interactions
        self.pert_mag = pert_mag
        self.clustering = interactions.clustering

        # These serve no functional purpose but we do it so that they are
        # connected in the graph structure. Each of these should have their
        # prior already initialized
        self.add_parent(self.growth)
        self.add_parent(self.self_interactions)
        self.add_parent(self.interactions)

    def __str__(self):
        &#39;&#39;&#39;Make it more readable
        &#39;&#39;&#39;
        try:
            a = &#39;Growth:\n{}\nSelf Interactions:\n{}\nInteractions:\n{}\nPerturbations:\n{}\n&#39; \
                &#39;Acceptances:\n{}&#39;.format(
                self.growth.value, self.self_interactions.value,
                str(self.G[STRNAMES.CLUSTER_INTERACTION_VALUE]),
                str(self.pert_mag), np.mean(
                    self.acceptances[ np.max([self.sample_iter-50, 0]):self.sample_iter], axis=0))
        except:
            a = &#39;Growth:\n{}\nSelf Interactions:\n{}\nInteractions:\n{}\nPerturbations:\n{}&#39;.format(
                self.growth.value, self.self_interactions.value,
                str(self.G[STRNAMES.CLUSTER_INTERACTION_VALUE]),
                str(self.pert_mag))
        return a

    def initialize(self, update_jointly_pert_inter, update_jointly_growth_si, 
        tune=None, end_tune=None):
        &#39;&#39;&#39;The interior objects are initialized by themselves. Define which variables
        get updated together.

        Note that the interactions and perturbations will always be updated before the
        growth rates and the self-interactions

        Interactions and perturbations
        ------------------------------
        These are conjugate and have a normal prior. If these are said to be updated
        jointly then we can sample directly with Gibbs sampling.

        Growths and self-interactions
        -----------------------------
        These are conjugate and have a truncated normal prior. If they are set to be 
        updated together, then we must do MH because we cannot sample from a truncated
        multivariate gaussian.

        Parameters
        ----------
        update_jointly_pert_inter : bool
            If True, update the interactions and the perturbations jointly.
            If False, update the interactions and perturbations separately - you
            randomly choose which one to update first.
        update_jointly_growth_si : bool
            If True, update the interactions and the perturbations jointly.
            If False, update the interactions and perturbations separately - you
            randomly choose which one to update first.
        &#39;&#39;&#39;
        self._there_are_perturbations = self.G.perturbations is not None
        if not pl.isbool(update_jointly_growth_si):
            raise TypeError(&#39;`update_jointly_growth_si` ({}) must be a bool&#39;.format(
                type(update_jointly_growth_si)))
        if not pl.isbool(update_jointly_pert_inter):
            raise TypeError(&#39;`update_jointly_pert_inter` ({}) must be a bool&#39;.format(
                type(update_jointly_pert_inter)))

        self.update_jointly_growth_si = update_jointly_growth_si
        self.update_jointly_pert_inter = update_jointly_pert_inter
        self.sample_iter = 0

        if self.update_jointly_growth_si:
            raise NotImplementedError(&#39;Not Implemented&#39;)
                
    # @profile
    def asarray(self):
        &#39;&#39;&#39;
        Builds the full regression coefficient vector. If `asv_id` and
        `cid` are None, build the entire thing. Else build it for
        the ASV or cluster specifically.

        Parameters
        ----------
        &#39;&#39;&#39;
        # build the entire thing
        a = np.append(self.growth.value, self.self_interactions.value)
        a = np.append(a, self.interactions.obj.get_values(use_indicators=True))
        return a

    def update(self):
        &#39;&#39;&#39;Either updated jointly using multivariate normal or update independently
        using truncated normal distributions for growth and self-interactions.

        Always update the one that the interactions is in first
        &#39;&#39;&#39;
        self._update_perts_and_inter()
        if self._there_are_perturbations:
            self.G.data.design_matrices[STRNAMES.GROWTH_VALUE].build_with_perturbations()
        
        self._update_growth_and_self_interactions()
        self.sample_iter += 1

        if self._there_are_perturbations:
            # If there are perturbations then we need to update their
            # matrix because the growths changed
            self.G.data.design_matrices[STRNAMES.PERT_VALUE].update_values()

    # @profile
    def _update_perts_and_inter(self):
        &#39;&#39;&#39;Update the with Gibbs sampling of a multivariate normal.

        Parameters
        ----------
        args : tuple
            This is a tuple of length &gt; 1 that holds the variables on what to update
            together
        &#39;&#39;&#39;
        if not self.update_jointly_pert_inter:
            # Update separately
            if pl.random.misc.fast_sample_standard_uniform() &lt; 0.5:
                self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].update()
                if self._there_are_perturbations:
                    self.G[STRNAMES.PERT_VALUE].update()
            else:
                if self._there_are_perturbations:
                    self.G[STRNAMES.PERT_VALUE].update()
                self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].update()
        else:
            # Update jointly
            rhs = []
            lhs = []
            if self.interactions.obj.sample_iter &gt;= \
                self.interactions.delay:
                rhs.append(STRNAMES.CLUSTER_INTERACTION_VALUE)
            else:
                lhs.append(STRNAMES.CLUSTER_INTERACTION_VALUE)
            if self._there_are_perturbations:
                if self.pert_mag.sample_iter &gt;= self.pert_mag.delay:
                    rhs.append(STRNAMES.PERT_VALUE)
                else:
                    lhs.append(STRNAMES.PERT_VALUE)

            if len(rhs) == 0:
                return

            lhs += [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            X = self.G.data.construct_rhs(keys=rhs)
            if X.shape[1] == 0:
                logging.info(&#39;No columns, skipping&#39;)
                return
            y = self.G.data.construct_lhs(keys=lhs,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;: False}})

            process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
                cov=False, sparse=True)
            prior_prec = build_prior_covariance(G=self.G, cov=False,
                order=rhs, sparse=True)
            prior_means = build_prior_mean(G=self.G,order=rhs).reshape(-1,1)

            # Make the prior covariance matrix and process varaince
            prec = X.T @ process_prec @ X + prior_prec
            self.cov.value = pinv(prec, self)
            self.mean.value = np.asarray(self.cov.value @ (X.T @ process_prec.dot(y) + \
                prior_prec @ prior_means)).ravel()

            # sample posterior jointly and then assign the values to each coefficient
            # type, respectfully
            try:
                value = self.sample()
            except:
                logging.critical(&#39;failed here, updating separately&#39;)
                self.pert_mag.update()
                self.interactions.update()
                return

            i = 0
            if STRNAMES.CLUSTER_INTERACTION_VALUE in rhs:
                l = self.interactions.obj.num_pos_indicators()
                self.interactions.value = value[:l]
                self.interactions.set_values(arr=value[:l], use_indicators=True)
                self.interactions.update_str()
                i += l
            if self._there_are_perturbations:
                if STRNAMES.PERT_VALUE in rhs:
                    self.pert_mag.value = value[i:]
                    self.pert_mag.set_values(arr=value[i:], use_indicators=True)
                    self.pert_mag.update_str()
                    self.G.data.design_matrices[STRNAMES.GROWTH_VALUE].update_value()
                    # self.G.data.design_matrices[STRNAMES.PERT_VALUE].build()

    def _update_acceptances(self):
        if self.growth.sample_iter == 0:
            self.temp_acceptances= np.zeros(len(self.G.data.asvs), dtype=int)
            self.acceptances = np.zeros(shape=(self.G.inference.n_samples, 
                len(self.G.data.asvs)), dtype=bool)
        elif self.growth.sample_iter &gt; self.end_tune:
            return
        elif self.growth.sample_iter % self.tune == 0:
            self.temp_acceptances = np.zeros(len(self.G.data.asvs), dtype=int)

    def _update_growth_and_self_interactions(self):
        &#39;&#39;&#39;Update the growth and self-interactions
        Our proposal is the posterior distribution.
        &#39;&#39;&#39;
        if not self.update_jointly_growth_si:
            # Update separately
            self.growth.update()
            self.self_interactions.update()
        else:
            # Update together
            raise NotImplementedError(&#39;Not Implemented&#39;)

    def add_trace(self):
        &#39;&#39;&#39;Trace values for growth, self-interactions, and cluster interaction values
        &#39;&#39;&#39;
        self.growth.add_trace()
        self.self_interactions.add_trace()
        self.interactions.add_trace()
        if self._there_are_perturbations:
            self.pert_mag.add_trace()

    def set_trace(self):
        self.growth.set_trace()
        self.self_interactions.set_trace()
        self.interactions.set_trace()
        if self._there_are_perturbations:
            self.pert_mag.set_trace()

    def add_init_value(self):
        self.growth.add_init_value()
        self.self_interactions.add_init_value()
        self.interactions.add_init_value()
        if self._there_are_perturbations:
            self.pert_mag.add_init_value()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.MVN" href="pylab/variables.html#mdsine2.pylab.variables.MVN">MVN</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.logistic_growth.RegressCoeff.add_trace"><code class="name flex">
<span>def <span class="ident">add_trace</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Trace values for growth, self-interactions, and cluster interaction values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_trace(self):
    &#39;&#39;&#39;Trace values for growth, self-interactions, and cluster interaction values
    &#39;&#39;&#39;
    self.growth.add_trace()
    self.self_interactions.add_trace()
    self.interactions.add_trace()
    if self._there_are_perturbations:
        self.pert_mag.add_trace()</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.RegressCoeff.asarray"><code class="name flex">
<span>def <span class="ident">asarray</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the full regression coefficient vector. If <code>asv_id</code> and
<code>cid</code> are None, build the entire thing. Else build it for
the ASV or cluster specifically.</p>
<h2 id="parameters">Parameters</h2></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def asarray(self):
    &#39;&#39;&#39;
    Builds the full regression coefficient vector. If `asv_id` and
    `cid` are None, build the entire thing. Else build it for
    the ASV or cluster specifically.

    Parameters
    ----------
    &#39;&#39;&#39;
    # build the entire thing
    a = np.append(self.growth.value, self.self_interactions.value)
    a = np.append(a, self.interactions.obj.get_values(use_indicators=True))
    return a</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.RegressCoeff.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, update_jointly_pert_inter, update_jointly_growth_si, tune=None, end_tune=None)</span>
</code></dt>
<dd>
<div class="desc"><p>The interior objects are initialized by themselves. Define which variables
get updated together.</p>
<p>Note that the interactions and perturbations will always be updated before the
growth rates and the self-interactions</p>
<h2 id="interactions-and-perturbations">Interactions And Perturbations</h2>
<p>These are conjugate and have a normal prior. If these are said to be updated
jointly then we can sample directly with Gibbs sampling.</p>
<h2 id="growths-and-self-interactions">Growths and self-interactions</h2>
<p>These are conjugate and have a truncated normal prior. If they are set to be
updated together, then we must do MH because we cannot sample from a truncated
multivariate gaussian.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>update_jointly_pert_inter</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, update the interactions and the perturbations jointly.
If False, update the interactions and perturbations separately - you
randomly choose which one to update first.</dd>
<dt><strong><code>update_jointly_growth_si</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, update the interactions and the perturbations jointly.
If False, update the interactions and perturbations separately - you
randomly choose which one to update first.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, update_jointly_pert_inter, update_jointly_growth_si, 
    tune=None, end_tune=None):
    &#39;&#39;&#39;The interior objects are initialized by themselves. Define which variables
    get updated together.

    Note that the interactions and perturbations will always be updated before the
    growth rates and the self-interactions

    Interactions and perturbations
    ------------------------------
    These are conjugate and have a normal prior. If these are said to be updated
    jointly then we can sample directly with Gibbs sampling.

    Growths and self-interactions
    -----------------------------
    These are conjugate and have a truncated normal prior. If they are set to be 
    updated together, then we must do MH because we cannot sample from a truncated
    multivariate gaussian.

    Parameters
    ----------
    update_jointly_pert_inter : bool
        If True, update the interactions and the perturbations jointly.
        If False, update the interactions and perturbations separately - you
        randomly choose which one to update first.
    update_jointly_growth_si : bool
        If True, update the interactions and the perturbations jointly.
        If False, update the interactions and perturbations separately - you
        randomly choose which one to update first.
    &#39;&#39;&#39;
    self._there_are_perturbations = self.G.perturbations is not None
    if not pl.isbool(update_jointly_growth_si):
        raise TypeError(&#39;`update_jointly_growth_si` ({}) must be a bool&#39;.format(
            type(update_jointly_growth_si)))
    if not pl.isbool(update_jointly_pert_inter):
        raise TypeError(&#39;`update_jointly_pert_inter` ({}) must be a bool&#39;.format(
            type(update_jointly_pert_inter)))

    self.update_jointly_growth_si = update_jointly_growth_si
    self.update_jointly_pert_inter = update_jointly_pert_inter
    self.sample_iter = 0

    if self.update_jointly_growth_si:
        raise NotImplementedError(&#39;Not Implemented&#39;)</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.RegressCoeff.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Either updated jointly using multivariate normal or update independently
using truncated normal distributions for growth and self-interactions.</p>
<p>Always update the one that the interactions is in first</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#39;&#39;&#39;Either updated jointly using multivariate normal or update independently
    using truncated normal distributions for growth and self-interactions.

    Always update the one that the interactions is in first
    &#39;&#39;&#39;
    self._update_perts_and_inter()
    if self._there_are_perturbations:
        self.G.data.design_matrices[STRNAMES.GROWTH_VALUE].build_with_perturbations()
    
    self._update_growth_and_self_interactions()
    self.sample_iter += 1

    if self._there_are_perturbations:
        # If there are perturbations then we need to update their
        # matrix because the growths changed
        self.G.data.design_matrices[STRNAMES.PERT_VALUE].update_values()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.MVN" href="pylab/variables.html#mdsine2.pylab.variables.MVN">MVN</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.MVN.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.sample" href="pylab/variables.html#mdsine2.pylab.variables.MVN.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.logistic_growth.SelfInteractions"><code class="flex name class">
<span>class <span class="ident">SelfInteractions</span></span>
<span>(</span><span>prior, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>self-interactions of Lotka-Voltera</p>
<p>Since our dynamics subtract this parameter, this parameter must be positive</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SelfInteractions(pl.variables.TruncatedNormal):
    &#39;&#39;&#39;self-interactions of Lotka-Voltera

    Since our dynamics subtract this parameter, this parameter must be positive
    &#39;&#39;&#39;
    def __init__(self, prior, **kwargs):
        kwargs[&#39;name&#39;] = STRNAMES.SELF_INTERACTION_VALUE
        pl.variables.TruncatedNormal.__init__(self, mean=None, var=None, low=0.,
            high=float(&#39;inf&#39;), dtype=float, **kwargs)
        self.set_value_shape(shape=(len(self.G.data.asvs),))
        self.add_prior(prior)

    def __str__(self):
        return str(self.value)

    def update_str(self):
        return

    def initialize(self, value_option, truncation_settings,
        value=None, delay=0, mean=None, q=None, rescale_value=None):
        &#39;&#39;&#39;Initialize the self-interactions values and hyperparamters

        Parameters
        ----------
        value_option : str
            How to initialize the values.
            Options:
               &#39;manual&#39;
                    Set the values manually. `value` must also be specified.
                &#39;fixed-growth&#39;
                    Fix the growth values and then sample the self-interactions
                &#39;strict-enforcement-partial&#39;
                    Do an unregularized regression then take the absolute value of the numbers.
                    We assume there are no interactions and we index out the time points that have
                    perturbations in them. We assume that we do not know the growths (the growths
                    are being regressed as well).
                &#39;strict-enforcement-full&#39;
                    Do an unregularized regression then take the absolute value of the numbers.
                    We assume there are no interactions and we index out the time points that have
                    perturbations in them. We assume that we know the growths (the growths are on
                    the lhs)
                &#39;steady-state&#39;, &#39;auto&#39;
                    Set to the steady state values. Must also provide the quantile with the
                    parameter `q`. In here we assume that the steady state is the `q`th quantile
                    of the off perturbation data
                &#39;prior-mean&#39;
                    Set the value to the mean of the prior
        truncation_settings : str, 2-tuple
            How to set the truncations for the normal distribution
            (low,high)
                These are the low and high values
            &#39;negative&#39;
                Truncated (-inf, 0)
            &#39;positive&#39;, &#39;auto&#39;
                Truncated (0, inf)
            &#39;human&#39;
                This assumes that the range of the steady state abundances of the human gut
                fluctuate between 1e2 and  1e13. We requie that the growth value be initialized first.
                We set the vlaues to be (growth.high/1e14, growth.low/1e2)
            &#39;mouse&#39;
                This assumes that the range of the steady state abundances of the mouse gut
                fluctuate between 1e2 and  1e12. We requie that the growth value be initialized first.
                We set the vlaues to be (growth.high/1e13, growth.low/1e2)
        value : array
            Only necessary if `value_option` is &#39;manual&#39;
        mean : array
            Only necessary if `mean_option` is &#39;manual&#39;
        delay : int
            How many MCMC iterations to delay starting to update
        rescale_value : None, float
            This is the rescale value of the qPCR. This will rescale the truncation settings.
            This is only used for either the &#39;mouse&#39; or &#39;human&#39; settings
        &#39;&#39;&#39;
        self._there_are_perturbations = self.G.perturbations is not None
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Set truncation settings
        if pl.isstr(truncation_settings):
            # if truncation_settings == &#39;negative&#39;:
            #     self.low = float(&#39;-inf&#39;)
            #     self.high= 0
            if truncation_settings in [&#39;mouse&#39;, &#39;human&#39;]:
                growth = self.G[STRNAMES.GROWTH_VALUE]
                if not growth._initialized:
                    raise ValueError(&#39;Growth values `{}` must be initialized first&#39;.format(
                        STRNAMES.GROWTH_VALUE))
                if truncation_settings == &#39;mouse&#39;:
                    high = 1e13
                else:
                    high = 1e14
                low = 1e2
                if rescale_value is not None:
                    if not pl.isnumeric(rescale_value):
                        raise TypeError(&#39;`rescale_value` ({}) must be a numeric&#39;.format(
                            type(rescale_value)))
                    if rescale_value &lt;= 0:
                        raise ValueError(&#39;`rescale_value` ({}) must be &gt; 0&#39;.format(rescale_value))
                    high *= rescale_value
                    low *= rescale_value
                self.low = growth.high/low
                self.high = growth.low/high
            elif truncation_settings in [&#39;auto&#39;, &#39;positive&#39;]:
                self.low = 0
                self.high = float(&#39;inf&#39;)
            else:
                raise ValueError(&#39;`truncation_settings) ({}) not recognized&#39;.format(
                    truncation_settings))
        elif pl.istuple(truncation_settings):
            if len(truncation_settings) != 2:
                raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                    &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
            l,h = truncation_settings

            if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
                raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                    type(l), type(h)))
            if l &lt; 0 or h &lt; 0:
                raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
            if h &lt;= l:
                raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
            self.high = h
            self.low = l
        else:
            raise TypeError(&#39;`truncation_settings` ({}) must be a tuple or str&#39;.format(
                type(truncation_settings)))

        # Set value option
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isarray(value):
                value = np.ones(len(self.G.data.asvs))*value
            if len(value) != self.G.data.n_asvs:
                raise ValueError(&#39;`value` ({}) must be ({}) long&#39;.format(
                    len(value), len(self.G.data.asvs)))
            self.value = value
        elif value_option == &#39;fixed-growth&#39;:
            X = self.G.data.construct_rhs(keys=[STRNAMES.SELF_INTERACTION_VALUE],
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=[STRNAMES.GROWTH_VALUE], kwargs_dict={
                STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            prec = X.T @ X
            cov = pinv(prec, self)
            self.value = np.absolute((cov @ X.transpose().dot(y)).ravel())
        elif &#39;strict-enforcement&#39; in value_option:
            if &#39;full&#39; in value_option:
                rhs = [STRNAMES.SELF_INTERACTION_VALUE]
                lhs = [STRNAMES.GROWTH_VALUE]
            elif &#39;partial&#39; in value_option:
                lhs = []
                rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
            else:
                raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
            X = self.G.data.construct_rhs(
                keys=rhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True)

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = (cov @ X.transpose().dot(y)).ravel()
            self.value = np.absolute(mean[len(self.G.data.asvs):])
        elif value_option == &#39;prior-mean&#39;:
            self.value = self.prior.mean.value * np.ones(self.G.data.n_asvs)
        elif value_option in [&#39;steady-state&#39;, &#39;auto&#39;]:
            # check quantile
            if not pl.isnumeric(q):
                raise TypeError(&#39;`q` ({}) must be numeric&#39;.format(type(q)))
            if q &lt; 0 or q &gt; 1:
                raise ValueError(&#39;`q` ({}) must be [0,1]&#39;.format(q))

            # Get the data off perturbation
            datas = None
            for ridx in range(self.G.data.n_replicates):
                if self._there_are_perturbations:
                    # Exclude the data thats in a perturbation
                    base_idx = 0
                    for start,end in self.G.data.tidxs_in_perturbation[ridx]:
                        if datas is None:
                            datas = self.G.data.data[ridx][:,base_idx:start]
                        else:
                            datas = np.hstack((datas, self.G.data.data[ridx][:,base_idx:start]))
                        base_idx = end
                    if end != self.G.data.data[ridx].shape[1]:
                        datas = np.hstack((datas, self.G.data.data[ridx][:,base_idx:]))
                else:
                    if datas is None:
                        datas = self.G.data.data[ridx]
                    else:
                        datas = np.hstack((datas, self.G.data.data[ridx]))

            # Set the steady-state for each ASV
            ss = np.quantile(datas, q=q, axis=1)

            # Get the self-interactions by using the values of the growth terms
            self.value = 1/ss
        elif value_option == &#39;linear-regression&#39;:
            
            rhs = [STRNAMES.SELF_INTERACTION_VALUE]
            lhs = [STRNAMES.GROWTH_VALUE]
            X = self.G.data.construct_rhs(keys=rhs,
                index_out_perturbations=True)
            y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True,
                kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}})

            prec = X.T @ X
            cov = pinv(prec, self)
            mean = cov @ X.T @ y
            self.value = np.asarray(mean).ravel()
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

        logging.info(&#39;Self-interactions value initialization: {}&#39;.format(self.value))
        logging.info(&#39;Self-interactions truncation settings: {}&#39;.format((self.low, self.high)))

    def update(self):
        if self.sample_iter &lt; self.delay:
            return

        self.calculate_posterior()
        self.sample()

        if not pl.isarray(self.value):
            # This will happen if there is 1 ASV
            self.value = np.array([self.value])

        if np.any(np.isnan(self.value)):
            logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
            logging.critical(&#39;var: {}&#39;.format(self.var.value))
            logging.critical(&#39;value: {}&#39;.format(self.value))
            raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))

    def calculate_posterior(self):

        rhs = [STRNAMES.SELF_INTERACTION_VALUE]
        if self._there_are_perturbations:
            lhs = [
                STRNAMES.GROWTH_VALUE,
                STRNAMES.CLUSTER_INTERACTION_VALUE]
        else:
            lhs = [
                STRNAMES.GROWTH_VALUE,
                STRNAMES.CLUSTER_INTERACTION_VALUE]
        X = self.G.data.construct_rhs(keys=rhs)
        y = self.G.data.construct_lhs(keys=lhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{
                &#39;with_perturbations&#39;:self._there_are_perturbations}})
        process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
            cov=False, sparse=True)
        prior_prec = build_prior_covariance(G=self.G, cov=False,
            order=rhs, sparse=True)

        pm = prior_prec @ (self.prior.mean.value * np.ones(self.G.data.n_asvs).reshape(-1,1))

        prec = X.T @ process_prec @ X + prior_prec
        cov = pinv(prec, self)
        self.mean.value = np.asarray(cov @ (X.T @ process_prec.dot(y) + pm)).ravel()
        self.var.value = np.diag(cov)

    def visualize_posterior(self, basepath, f, section=&#39;posterior&#39;, asv_formatter=&#39;%(name)s&#39;, 
        true_value=None):
        &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
        learned values to the file `f`.

        Parameters
        ----------
        basepath : str
            This is the loction to write the files to
        f : _io.TextIOWrapper
            File that we are writing the values to
        section : str
            Section of the trace to compute on. Options:
                &#39;posterior&#39; : posterior samples
                &#39;burnin&#39; : burn-in samples
                &#39;entire&#39; : both burn-in and posterior samples
        true_value : np.ndarray
            Ground truth values of the variable

        Returns
        -------
        _io.TextIOWrapper
        &#39;&#39;&#39;
        f.write(&#39;\n\n###################################\n&#39;)
        f.write(self.name)
        f.write(&#39;\n###################################\n&#39;)
        if not self.G.inference.tracer.is_being_traced(self):
            f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
            return f

        asvs = self.G.data.subjects.asvs
        summ = pl.summary(self, section=section)
        for key,arr in summ.items():
            f.write(&#39;{}\n&#39;.format(key))
            for idx,ele in enumerate(arr):
                prefix = &#39;&#39;
                if asv_formatter is not None:
                    prefix = pl.asvname_formatter(format=asv_formatter, asv=asvs[idx], asvs=asvs)
                f.write(&#39;\t&#39; + prefix + &#39;{}\n&#39;.format(ele)) 

        if section == &#39;posterior&#39;:
            len_posterior = self.G.inference.sample_iter + 1 - self.G.inference.burnin
        elif section == &#39;burnin&#39;:
            len_posterior = self.G.inference.burnin
        else:
            len_posterior = self.G.inference.sample_iter + 1

        # Plot the prior on top of the posterior
        if self.G.tracer.is_being_traced(STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS):
            prior_mean_trace = self.G[STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS].get_trace_from_disk(
                    section=section)
        else:
            prior_mean_trace = self.prior.mean.value * np.ones(len_posterior, dtype=float)
        if self.G.tracer.is_being_traced(STRNAMES.PRIOR_VAR_SELF_INTERACTIONS):
            prior_std_trace = np.sqrt(
                self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].get_trace_from_disk(section=section))
        else:
            prior_std_trace = np.sqrt(self.prior.var.value) * np.ones(len_posterior, dtype=float)

        for idx in range(len(asvs)):
            fig = plt.figure()
            ax_posterior = fig.add_subplot(1,2,1)
            visualization.render_trace(var=self, idx=idx, plt_type=&#39;hist&#39;,
                label=section, color=&#39;blue&#39;, ax=ax_posterior, section=section,
                include_burnin=True, rasterized=True, log_scale=True)

            # Get the limits and only look at the posterior within 20% range +- of
            # this number
            low_x, high_x = ax_posterior.get_xlim()

            arr = np.zeros(len(prior_std_trace), dtype=float)
            for i in range(len(prior_std_trace)):
                arr[i] = pl.random.truncnormal.sample(mean=prior_mean_trace[i], std=prior_std_trace[i], 
                    low=self.low, high=self.high)
            visualization.render_trace(var=arr, plt_type=&#39;hist&#39;, log_scale=True,
                label=&#39;prior&#39;, color=&#39;red&#39;, ax=ax_posterior, rasterized=True)

            if true_value is not None:
                ax_posterior.axvline(x=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                    label=&#39;True Value&#39;)

            ax_posterior.legend()
            ax_posterior.set_xlim(left=low_x*.8, right=high_x*1.2)

            # plot the trace
            ax_trace = fig.add_subplot(1,2,2)
            visualization.render_trace(var=self, idx=idx, plt_type=&#39;trace&#39;, 
                ax=ax_trace, section=section, include_burnin=True, rasterized=True,
                log_scale=True)

            if true_value is not None:
                ax_trace.axhline(y=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                    label=&#39;True Value&#39;)
                ax_trace.legend()

            if asv_formatter is not None:
                asvname = pl.asvname_formatter(
                    format=asv_formatter,
                    asv=asvs[idx],
                    asvs=asvs)
            else:
                asvname = asvs[idx].name
            asvname = asvname.replace(&#39;/&#39;, &#39;_&#39;).replace(&#39; &#39;, &#39;_&#39;)

            fig.suptitle(&#39;Self-Interactions {}&#39;.format(asvname))
            fig.tight_layout()
            fig.subplots_adjust(top=0.85)
            plt.savefig(basepath + &#39;{}.pdf&#39;.format(asvs[idx].name))
            plt.close()

        return f</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.TruncatedNormal" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal">TruncatedNormal</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.logistic_growth.SelfInteractions.calculate_posterior"><code class="name flex">
<span>def <span class="ident">calculate_posterior</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_posterior(self):

    rhs = [STRNAMES.SELF_INTERACTION_VALUE]
    if self._there_are_perturbations:
        lhs = [
            STRNAMES.GROWTH_VALUE,
            STRNAMES.CLUSTER_INTERACTION_VALUE]
    else:
        lhs = [
            STRNAMES.GROWTH_VALUE,
            STRNAMES.CLUSTER_INTERACTION_VALUE]
    X = self.G.data.construct_rhs(keys=rhs)
    y = self.G.data.construct_lhs(keys=lhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{
            &#39;with_perturbations&#39;:self._there_are_perturbations}})
    process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
        cov=False, sparse=True)
    prior_prec = build_prior_covariance(G=self.G, cov=False,
        order=rhs, sparse=True)

    pm = prior_prec @ (self.prior.mean.value * np.ones(self.G.data.n_asvs).reshape(-1,1))

    prec = X.T @ process_prec @ X + prior_prec
    cov = pinv(prec, self)
    self.mean.value = np.asarray(cov @ (X.T @ process_prec.dot(y) + pm)).ravel()
    self.var.value = np.diag(cov)</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.SelfInteractions.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, value_option, truncation_settings, value=None, delay=0, mean=None, q=None, rescale_value=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the self-interactions values and hyperparamters</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>value_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to initialize the values.
Options:
'manual'
Set the values manually. <code>value</code> must also be specified.
'fixed-growth'
Fix the growth values and then sample the self-interactions
'strict-enforcement-partial'
Do an unregularized regression then take the absolute value of the numbers.
We assume there are no interactions and we index out the time points that have
perturbations in them. We assume that we do not know the growths (the growths
are being regressed as well).
'strict-enforcement-full'
Do an unregularized regression then take the absolute value of the numbers.
We assume there are no interactions and we index out the time points that have
perturbations in them. We assume that we know the growths (the growths are on
the lhs)
'steady-state', 'auto'
Set to the steady state values. Must also provide the quantile with the
parameter <code>q</code>. In here we assume that the steady state is the <code>q</code>th quantile
of the off perturbation data
'prior-mean'
Set the value to the mean of the prior</dd>
<dt><strong><code>truncation_settings</code></strong> :&ensp;<code>str, 2-tuple</code></dt>
<dd>How to set the truncations for the normal distribution
(low,high)
These are the low and high values
'negative'
Truncated (-inf, 0)
'positive', 'auto'
Truncated (0, inf)
'human'
This assumes that the range of the steady state abundances of the human gut
fluctuate between 1e2 and
1e13. We requie that the growth value be initialized first.
We set the vlaues to be (growth.high/1e14, growth.low/1e2)
'mouse'
This assumes that the range of the steady state abundances of the mouse gut
fluctuate between 1e2 and
1e12. We requie that the growth value be initialized first.
We set the vlaues to be (growth.high/1e13, growth.low/1e2)</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>array</code></dt>
<dd>Only necessary if <code>value_option</code> is 'manual'</dd>
<dt><strong><code>mean</code></strong> :&ensp;<code>array</code></dt>
<dd>Only necessary if <code>mean_option</code> is 'manual'</dd>
<dt><strong><code>delay</code></strong> :&ensp;<code>int</code></dt>
<dd>How many MCMC iterations to delay starting to update</dd>
<dt><strong><code>rescale_value</code></strong> :&ensp;<code>None, float</code></dt>
<dd>This is the rescale value of the qPCR. This will rescale the truncation settings.
This is only used for either the 'mouse' or 'human' settings</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, value_option, truncation_settings,
    value=None, delay=0, mean=None, q=None, rescale_value=None):
    &#39;&#39;&#39;Initialize the self-interactions values and hyperparamters

    Parameters
    ----------
    value_option : str
        How to initialize the values.
        Options:
           &#39;manual&#39;
                Set the values manually. `value` must also be specified.
            &#39;fixed-growth&#39;
                Fix the growth values and then sample the self-interactions
            &#39;strict-enforcement-partial&#39;
                Do an unregularized regression then take the absolute value of the numbers.
                We assume there are no interactions and we index out the time points that have
                perturbations in them. We assume that we do not know the growths (the growths
                are being regressed as well).
            &#39;strict-enforcement-full&#39;
                Do an unregularized regression then take the absolute value of the numbers.
                We assume there are no interactions and we index out the time points that have
                perturbations in them. We assume that we know the growths (the growths are on
                the lhs)
            &#39;steady-state&#39;, &#39;auto&#39;
                Set to the steady state values. Must also provide the quantile with the
                parameter `q`. In here we assume that the steady state is the `q`th quantile
                of the off perturbation data
            &#39;prior-mean&#39;
                Set the value to the mean of the prior
    truncation_settings : str, 2-tuple
        How to set the truncations for the normal distribution
        (low,high)
            These are the low and high values
        &#39;negative&#39;
            Truncated (-inf, 0)
        &#39;positive&#39;, &#39;auto&#39;
            Truncated (0, inf)
        &#39;human&#39;
            This assumes that the range of the steady state abundances of the human gut
            fluctuate between 1e2 and  1e13. We requie that the growth value be initialized first.
            We set the vlaues to be (growth.high/1e14, growth.low/1e2)
        &#39;mouse&#39;
            This assumes that the range of the steady state abundances of the mouse gut
            fluctuate between 1e2 and  1e12. We requie that the growth value be initialized first.
            We set the vlaues to be (growth.high/1e13, growth.low/1e2)
    value : array
        Only necessary if `value_option` is &#39;manual&#39;
    mean : array
        Only necessary if `mean_option` is &#39;manual&#39;
    delay : int
        How many MCMC iterations to delay starting to update
    rescale_value : None, float
        This is the rescale value of the qPCR. This will rescale the truncation settings.
        This is only used for either the &#39;mouse&#39; or &#39;human&#39; settings
    &#39;&#39;&#39;
    self._there_are_perturbations = self.G.perturbations is not None
    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    self.delay = delay

    # Set truncation settings
    if pl.isstr(truncation_settings):
        # if truncation_settings == &#39;negative&#39;:
        #     self.low = float(&#39;-inf&#39;)
        #     self.high= 0
        if truncation_settings in [&#39;mouse&#39;, &#39;human&#39;]:
            growth = self.G[STRNAMES.GROWTH_VALUE]
            if not growth._initialized:
                raise ValueError(&#39;Growth values `{}` must be initialized first&#39;.format(
                    STRNAMES.GROWTH_VALUE))
            if truncation_settings == &#39;mouse&#39;:
                high = 1e13
            else:
                high = 1e14
            low = 1e2
            if rescale_value is not None:
                if not pl.isnumeric(rescale_value):
                    raise TypeError(&#39;`rescale_value` ({}) must be a numeric&#39;.format(
                        type(rescale_value)))
                if rescale_value &lt;= 0:
                    raise ValueError(&#39;`rescale_value` ({}) must be &gt; 0&#39;.format(rescale_value))
                high *= rescale_value
                low *= rescale_value
            self.low = growth.high/low
            self.high = growth.low/high
        elif truncation_settings in [&#39;auto&#39;, &#39;positive&#39;]:
            self.low = 0
            self.high = float(&#39;inf&#39;)
        else:
            raise ValueError(&#39;`truncation_settings) ({}) not recognized&#39;.format(
                truncation_settings))
    elif pl.istuple(truncation_settings):
        if len(truncation_settings) != 2:
            raise ValueError(&#39;If `truncation_settings` is a tuple, it must have a &#39; \
                &#39;length of 2 ({})&#39;.format(len(truncation_settings)))
        l,h = truncation_settings

        if (not pl.isnumeric(l)) or (not pl.isnumeric(h)):
            raise TypeError(&#39;`low` ({}) and `high` ({}) must be numerics&#39;.format(
                type(l), type(h)))
        if l &lt; 0 or h &lt; 0:
            raise ValueError(&#39;`low` ({}) and `high` ({}) must be &gt;= 0&#39;.format(l,h))
        if h &lt;= l:
            raise ValueError(&#39;`low` ({}) must be strictly less than high ({})&#39;.format(l,h))
        self.high = h
        self.low = l
    else:
        raise TypeError(&#39;`truncation_settings` ({}) must be a tuple or str&#39;.format(
            type(truncation_settings)))

    # Set value option
    if not pl.isstr(value_option):
        raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
    if value_option == &#39;manual&#39;:
        if not pl.isarray(value):
            value = np.ones(len(self.G.data.asvs))*value
        if len(value) != self.G.data.n_asvs:
            raise ValueError(&#39;`value` ({}) must be ({}) long&#39;.format(
                len(value), len(self.G.data.asvs)))
        self.value = value
    elif value_option == &#39;fixed-growth&#39;:
        X = self.G.data.construct_rhs(keys=[STRNAMES.SELF_INTERACTION_VALUE],
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(keys=[STRNAMES.GROWTH_VALUE], kwargs_dict={
            STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)
        prec = X.T @ X
        cov = pinv(prec, self)
        self.value = np.absolute((cov @ X.transpose().dot(y)).ravel())
    elif &#39;strict-enforcement&#39; in value_option:
        if &#39;full&#39; in value_option:
            rhs = [STRNAMES.SELF_INTERACTION_VALUE]
            lhs = [STRNAMES.GROWTH_VALUE]
        elif &#39;partial&#39; in value_option:
            lhs = []
            rhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
        X = self.G.data.construct_rhs(
            keys=rhs, kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}},
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True)

        prec = X.T @ X
        cov = pinv(prec, self)
        mean = (cov @ X.transpose().dot(y)).ravel()
        self.value = np.absolute(mean[len(self.G.data.asvs):])
    elif value_option == &#39;prior-mean&#39;:
        self.value = self.prior.mean.value * np.ones(self.G.data.n_asvs)
    elif value_option in [&#39;steady-state&#39;, &#39;auto&#39;]:
        # check quantile
        if not pl.isnumeric(q):
            raise TypeError(&#39;`q` ({}) must be numeric&#39;.format(type(q)))
        if q &lt; 0 or q &gt; 1:
            raise ValueError(&#39;`q` ({}) must be [0,1]&#39;.format(q))

        # Get the data off perturbation
        datas = None
        for ridx in range(self.G.data.n_replicates):
            if self._there_are_perturbations:
                # Exclude the data thats in a perturbation
                base_idx = 0
                for start,end in self.G.data.tidxs_in_perturbation[ridx]:
                    if datas is None:
                        datas = self.G.data.data[ridx][:,base_idx:start]
                    else:
                        datas = np.hstack((datas, self.G.data.data[ridx][:,base_idx:start]))
                    base_idx = end
                if end != self.G.data.data[ridx].shape[1]:
                    datas = np.hstack((datas, self.G.data.data[ridx][:,base_idx:]))
            else:
                if datas is None:
                    datas = self.G.data.data[ridx]
                else:
                    datas = np.hstack((datas, self.G.data.data[ridx]))

        # Set the steady-state for each ASV
        ss = np.quantile(datas, q=q, axis=1)

        # Get the self-interactions by using the values of the growth terms
        self.value = 1/ss
    elif value_option == &#39;linear-regression&#39;:
        
        rhs = [STRNAMES.SELF_INTERACTION_VALUE]
        lhs = [STRNAMES.GROWTH_VALUE]
        X = self.G.data.construct_rhs(keys=rhs,
            index_out_perturbations=True)
        y = self.G.data.construct_lhs(keys=lhs, index_out_perturbations=True,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;:False}})

        prec = X.T @ X
        cov = pinv(prec, self)
        mean = cov @ X.T @ y
        self.value = np.asarray(mean).ravel()
    else:
        raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

    logging.info(&#39;Self-interactions value initialization: {}&#39;.format(self.value))
    logging.info(&#39;Self-interactions truncation settings: {}&#39;.format((self.low, self.high)))</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.SelfInteractions.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    if self.sample_iter &lt; self.delay:
        return

    self.calculate_posterior()
    self.sample()

    if not pl.isarray(self.value):
        # This will happen if there is 1 ASV
        self.value = np.array([self.value])

    if np.any(np.isnan(self.value)):
        logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
        logging.critical(&#39;var: {}&#39;.format(self.var.value))
        logging.critical(&#39;value: {}&#39;.format(self.value))
        raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.SelfInteractions.update_str"><code class="name flex">
<span>def <span class="ident">update_str</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_str(self):
    return</code></pre>
</details>
</dd>
<dt id="mdsine2.logistic_growth.SelfInteractions.visualize_posterior"><code class="name flex">
<span>def <span class="ident">visualize_posterior</span></span>(<span>self, basepath, f, section='posterior', asv_formatter='%(name)s', true_value=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Render the traces in the folder <code>basepath</code> and write the
learned values to the file <code>f</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>basepath</code></strong> :&ensp;<code>str</code></dt>
<dd>This is the loction to write the files to</dd>
<dt><strong><code>f</code></strong> :&ensp;<code>_io.TextIOWrapper</code></dt>
<dd>File that we are writing the values to</dd>
<dt><strong><code>section</code></strong> :&ensp;<code>str</code></dt>
<dd>Section of the trace to compute on. Options:
'posterior' : posterior samples
'burnin' : burn-in samples
'entire' : both burn-in and posterior samples</dd>
<dt><strong><code>true_value</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Ground truth values of the variable</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>_io.TextIOWrapper</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualize_posterior(self, basepath, f, section=&#39;posterior&#39;, asv_formatter=&#39;%(name)s&#39;, 
    true_value=None):
    &#39;&#39;&#39;Render the traces in the folder `basepath` and write the 
    learned values to the file `f`.

    Parameters
    ----------
    basepath : str
        This is the loction to write the files to
    f : _io.TextIOWrapper
        File that we are writing the values to
    section : str
        Section of the trace to compute on. Options:
            &#39;posterior&#39; : posterior samples
            &#39;burnin&#39; : burn-in samples
            &#39;entire&#39; : both burn-in and posterior samples
    true_value : np.ndarray
        Ground truth values of the variable

    Returns
    -------
    _io.TextIOWrapper
    &#39;&#39;&#39;
    f.write(&#39;\n\n###################################\n&#39;)
    f.write(self.name)
    f.write(&#39;\n###################################\n&#39;)
    if not self.G.inference.tracer.is_being_traced(self):
        f.write(&#39;`{}` not learned\n\tValue: {}\n&#39;.format(self.name, self.value))
        return f

    asvs = self.G.data.subjects.asvs
    summ = pl.summary(self, section=section)
    for key,arr in summ.items():
        f.write(&#39;{}\n&#39;.format(key))
        for idx,ele in enumerate(arr):
            prefix = &#39;&#39;
            if asv_formatter is not None:
                prefix = pl.asvname_formatter(format=asv_formatter, asv=asvs[idx], asvs=asvs)
            f.write(&#39;\t&#39; + prefix + &#39;{}\n&#39;.format(ele)) 

    if section == &#39;posterior&#39;:
        len_posterior = self.G.inference.sample_iter + 1 - self.G.inference.burnin
    elif section == &#39;burnin&#39;:
        len_posterior = self.G.inference.burnin
    else:
        len_posterior = self.G.inference.sample_iter + 1

    # Plot the prior on top of the posterior
    if self.G.tracer.is_being_traced(STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS):
        prior_mean_trace = self.G[STRNAMES.PRIOR_MEAN_SELF_INTERACTIONS].get_trace_from_disk(
                section=section)
    else:
        prior_mean_trace = self.prior.mean.value * np.ones(len_posterior, dtype=float)
    if self.G.tracer.is_being_traced(STRNAMES.PRIOR_VAR_SELF_INTERACTIONS):
        prior_std_trace = np.sqrt(
            self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].get_trace_from_disk(section=section))
    else:
        prior_std_trace = np.sqrt(self.prior.var.value) * np.ones(len_posterior, dtype=float)

    for idx in range(len(asvs)):
        fig = plt.figure()
        ax_posterior = fig.add_subplot(1,2,1)
        visualization.render_trace(var=self, idx=idx, plt_type=&#39;hist&#39;,
            label=section, color=&#39;blue&#39;, ax=ax_posterior, section=section,
            include_burnin=True, rasterized=True, log_scale=True)

        # Get the limits and only look at the posterior within 20% range +- of
        # this number
        low_x, high_x = ax_posterior.get_xlim()

        arr = np.zeros(len(prior_std_trace), dtype=float)
        for i in range(len(prior_std_trace)):
            arr[i] = pl.random.truncnormal.sample(mean=prior_mean_trace[i], std=prior_std_trace[i], 
                low=self.low, high=self.high)
        visualization.render_trace(var=arr, plt_type=&#39;hist&#39;, log_scale=True,
            label=&#39;prior&#39;, color=&#39;red&#39;, ax=ax_posterior, rasterized=True)

        if true_value is not None:
            ax_posterior.axvline(x=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                label=&#39;True Value&#39;)

        ax_posterior.legend()
        ax_posterior.set_xlim(left=low_x*.8, right=high_x*1.2)

        # plot the trace
        ax_trace = fig.add_subplot(1,2,2)
        visualization.render_trace(var=self, idx=idx, plt_type=&#39;trace&#39;, 
            ax=ax_trace, section=section, include_burnin=True, rasterized=True,
            log_scale=True)

        if true_value is not None:
            ax_trace.axhline(y=true_value[idx], color=&#39;red&#39;, alpha=0.65, 
                label=&#39;True Value&#39;)
            ax_trace.legend()

        if asv_formatter is not None:
            asvname = pl.asvname_formatter(
                format=asv_formatter,
                asv=asvs[idx],
                asvs=asvs)
        else:
            asvname = asvs[idx].name
        asvname = asvname.replace(&#39;/&#39;, &#39;_&#39;).replace(&#39; &#39;, &#39;_&#39;)

        fig.suptitle(&#39;Self-Interactions {}&#39;.format(asvname))
        fig.tight_layout()
        fig.subplots_adjust(top=0.85)
        plt.savefig(basepath + &#39;{}.pdf&#39;.format(asvs[idx].name))
        plt.close()

    return f</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.TruncatedNormal" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal">TruncatedNormal</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.cdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.cdf">cdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.logcdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.logcdf">logcdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.logpdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.logpdf">logpdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.pdf" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.pdf">pdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.sample" href="pylab/variables.html#mdsine2.pylab.variables.TruncatedNormal.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.TruncatedNormal.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mdsine2" href="index.html">mdsine2</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mdsine2.logistic_growth.Growth" href="#mdsine2.logistic_growth.Growth">Growth</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.logistic_growth.Growth.calculate_posterior" href="#mdsine2.logistic_growth.Growth.calculate_posterior">calculate_posterior</a></code></li>
<li><code><a title="mdsine2.logistic_growth.Growth.initialize" href="#mdsine2.logistic_growth.Growth.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.logistic_growth.Growth.update" href="#mdsine2.logistic_growth.Growth.update">update</a></code></li>
<li><code><a title="mdsine2.logistic_growth.Growth.update_str" href="#mdsine2.logistic_growth.Growth.update_str">update_str</a></code></li>
<li><code><a title="mdsine2.logistic_growth.Growth.visualize_posterior" href="#mdsine2.logistic_growth.Growth.visualize_posterior">visualize_posterior</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.logistic_growth.PriorMeanMH" href="#mdsine2.logistic_growth.PriorMeanMH">PriorMeanMH</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.logistic_growth.PriorMeanMH.initialize" href="#mdsine2.logistic_growth.PriorMeanMH.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.logistic_growth.PriorMeanMH.update" href="#mdsine2.logistic_growth.PriorMeanMH.update">update</a></code></li>
<li><code><a title="mdsine2.logistic_growth.PriorMeanMH.update_var" href="#mdsine2.logistic_growth.PriorMeanMH.update_var">update_var</a></code></li>
<li><code><a title="mdsine2.logistic_growth.PriorMeanMH.visualize_posterior" href="#mdsine2.logistic_growth.PriorMeanMH.visualize_posterior">visualize_posterior</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.logistic_growth.PriorVarMH" href="#mdsine2.logistic_growth.PriorVarMH">PriorVarMH</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.logistic_growth.PriorVarMH.initialize" href="#mdsine2.logistic_growth.PriorVarMH.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.logistic_growth.PriorVarMH.update" href="#mdsine2.logistic_growth.PriorVarMH.update">update</a></code></li>
<li><code><a title="mdsine2.logistic_growth.PriorVarMH.update_dof" href="#mdsine2.logistic_growth.PriorVarMH.update_dof">update_dof</a></code></li>
<li><code><a title="mdsine2.logistic_growth.PriorVarMH.visualize_posterior" href="#mdsine2.logistic_growth.PriorVarMH.visualize_posterior">visualize_posterior</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.logistic_growth.RegressCoeff" href="#mdsine2.logistic_growth.RegressCoeff">RegressCoeff</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.logistic_growth.RegressCoeff.add_trace" href="#mdsine2.logistic_growth.RegressCoeff.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.logistic_growth.RegressCoeff.asarray" href="#mdsine2.logistic_growth.RegressCoeff.asarray">asarray</a></code></li>
<li><code><a title="mdsine2.logistic_growth.RegressCoeff.initialize" href="#mdsine2.logistic_growth.RegressCoeff.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.logistic_growth.RegressCoeff.update" href="#mdsine2.logistic_growth.RegressCoeff.update">update</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.logistic_growth.SelfInteractions" href="#mdsine2.logistic_growth.SelfInteractions">SelfInteractions</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.logistic_growth.SelfInteractions.calculate_posterior" href="#mdsine2.logistic_growth.SelfInteractions.calculate_posterior">calculate_posterior</a></code></li>
<li><code><a title="mdsine2.logistic_growth.SelfInteractions.initialize" href="#mdsine2.logistic_growth.SelfInteractions.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.logistic_growth.SelfInteractions.update" href="#mdsine2.logistic_growth.SelfInteractions.update">update</a></code></li>
<li><code><a title="mdsine2.logistic_growth.SelfInteractions.update_str" href="#mdsine2.logistic_growth.SelfInteractions.update_str">update_str</a></code></li>
<li><code><a title="mdsine2.logistic_growth.SelfInteractions.visualize_posterior" href="#mdsine2.logistic_growth.SelfInteractions.visualize_posterior">visualize_posterior</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>