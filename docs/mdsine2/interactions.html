<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>mdsine2.interactions API documentation</title>
<meta name="description" content="Logistic growth parameters for the posterior" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>mdsine2.interactions</code></h1>
</header>
<section id="section-intro">
<p>Logistic growth parameters for the posterior</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;Logistic growth parameters for the posterior
&#39;&#39;&#39;
import logging
import time
import numpy as np
import numba
import numpy.random as npr

import matplotlib.pyplot as plt

from .util import expected_n_clusters, build_prior_covariance, build_prior_mean, sample_categorical_log, \
    log_det, pinv
from .perturbations import PerturbationMagnitudes
from .names import STRNAMES, STRNAMES

from . import pylab as pl

class PriorVarInteractions(pl.variables.SICS):
    &#39;&#39;&#39;This is the posterior of the prior variance of regression coefficients
    for the interaction (off diagonal) variables
    &#39;&#39;&#39;
    def __init__(self, prior, value=None, **kwargs):

        kwargs[&#39;name&#39;] = STRNAMES.PRIOR_VAR_INTERACTIONS
        pl.variables.SICS.__init__(self, value=value,
            dtype=float, **kwargs)
        self.add_prior(prior)

    def initialize(self, value_option, dof_option, scale_option, value=None,
        mean_scaling_factor=None, dof=None, scale=None, delay=0):
        &#39;&#39;&#39;Initialize the hyperparameters of the self interaction variance based on the
        passed in option

        Parameters
        ----------
        value_option : str
            - Initialize the value based on the specified option
            - Options
                - &#39;manual&#39;
                    - Set the value manually, `value` must also be specified
                - &#39;auto&#39;, &#39;prior-mean&#39;
                    - Set the value to the mean of the prior
        scale_option : str
            - Initialize the scale of the prior
            - Options
                - &#39;manual&#39;
                    - Set the value manually, `scale` must also be specified
                - &#39;auto&#39;, &#39;same-as-aii&#39;
                    - Set the mean the same as the self-interactions
        dof_option : str
            Initialize the dof of the parameter
            Options:
                &#39;manual&#39;: Set the value with the parameter `dof`
                &#39;diffuse&#39;: Set the value to 2.01
                &#39;strong&#39;: Set the valuye to the expected number of interactions
                &#39;auto&#39;: Set to diffuse
        dof, scale : int, float
            - User specified values
            - Only necessary if `hyperparam_option` == &#39;manual&#39;
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        self.interactions = self.G[STRNAMES.CLUSTER_INTERACTION_VALUE]

        if not pl.isstr(dof_option):
            raise TypeError(&#39;`dof_option` ({}) must be a str&#39;.format(type(dof_option)))
        if dof_option == &#39;manual&#39;:
            if not pl.isnumeric(dof):
                raise TypeError(&#39;`dof` ({}) must be a numeric&#39;.format(type(dof)))
            if dof &lt; 0:
                raise ValueError(&#39;`dof` ({}) must be &gt; 0 for it to be a valid prior&#39;.format(dof))
        elif dof_option in [&#39;diffuse&#39;, &#39;auto&#39;]:
            dof = 2.01
        elif dof_option == &#39;strong&#39;:
            N = expected_n_clusters(G=self.G)
            dof = N * (N - 1)
        else:
            raise ValueError(&#39;`dof_option` ({}) not recognized&#39;.format(dof_option))
        self.prior.dof.override_value(dof)

        if not pl.isstr(scale_option):
            raise TypeError(&#39;`scale_option` ({}) must be a str&#39;.format(type(scale_option)))
        if scale_option == &#39;manual&#39;:
            if not pl.isnumeric(scale):
                raise TypeError(&#39;`scale` ({}) must be a numeric&#39;.format(type(scale)))
            if scale &lt; 0:
                raise ValueError(&#39;`scale` ({}) must be &gt; 0 for it to be a valid prior&#39;.format(scale))
        elif scale_option in [&#39;auto&#39;, &#39;same-as-aii&#39;]:
            mean = self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].prior.mean()
            scale = mean * (self.prior.dof.value - 2) /(self.prior.dof.value)
        else:
            raise ValueError(&#39;`scale_option` ({}) not recognized&#39;.format(scale_option))
        self.prior.scale.override_value(scale)

        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isnumeric(value):
                raise ValueError(&#39;`value` ({}) must be numeric (float,int)&#39;.format(value.__class__))
            self.value = value
        elif value_option in [&#39;auto&#39;, &#39;prior-mean&#39;]:
            if not pl.isnumeric(mean_scaling_factor):
                raise ValueError(&#39;`mean_scaling_factor` ({}) must be a numeric type &#39; \
                    &#39;(float,int)&#39;.format(mean_scaling_factor.__class__))
            self.value = self.prior.mean()
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

        logging.info(&#39;Prior Variance Interactions initialization results:\n&#39; \
            &#39;\tprior dof: {}\n&#39; \
            &#39;\tprior scale: {}\n&#39; \
            &#39;\tvalue: {}&#39;.format(
                self.prior.dof.value, self.prior.scale.value, self.value))

    # @profile
    def update(self):
        &#39;&#39;&#39;Calculate the posterior of the prior variance
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return

        x = self.interactions.obj.get_values(use_indicators=True)
        mu = self.G[STRNAMES.PRIOR_MEAN_INTERACTIONS].value

        se = np.sum(np.square(x - mu))
        n = len(x)

        self.dof.value = self.prior.dof.value + n
        self.scale.value = ((self.prior.scale.value * self.prior.dof.value) + \
           se)/self.dof.value
        self.sample()


class PriorMeanInteractions(pl.variables.Normal):
    &#39;&#39;&#39;This is the posterior mean for the interactions
    &#39;&#39;&#39;

    def __init__(self, prior, **kwargs):
        kwargs[&#39;name&#39;] = STRNAMES.PRIOR_MEAN_INTERACTIONS
        pl.variables.Normal.__init__(self, mean=None, var=None, dtype=float, **kwargs)
        self.add_prior(prior)

    def __str__(self):
        # If this fails, it is because we are dividing by 0 sampler_iter
        # If which case we just return the value 
        try:
            s = &#39;Value: {}, Acceptance rate: {}&#39;.format(
                self.value, np.mean(self.acceptances[
                    np.max([self.sample_iter-50, 0]):self.sample_iter]))
        except:
            s = str(self.value)
        return s

    def initialize(self, value_option, mean_option, var_option, value=None, 
        mean=None, var=None, delay=0):
        &#39;&#39;&#39;Initialize the hyperparameters

        Parameters
        ----------
        value_option : str
            How to set the value. Options:
                &#39;zero&#39;
                    Set to zero
                &#39;prior-mean&#39;, &#39;auto&#39;
                    Set to the mean of the prior
                &#39;manual&#39;
                    Specify with the `value` parameter
        mean_option : str
            How to set the mean of the prior
                &#39;zero&#39;, &#39;auto&#39;
                    Set to zero
                &#39;manual&#39;
                    Set with the `mean` parameter
        var_option : str
            &#39;same-as-aii&#39;, &#39;auto&#39;
                Set as the same variance as the self-interactions
            &#39;manual&#39;
                Set with the `var` parameter
        value, mean, var : float
            These are only necessary if we specify manual for any of the other 
            options
        delay : int
            How much to delay the start of the update during inference
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Set the mean
        if not pl.isstr(mean_option):
            raise TypeError(&#39;`mean_option` ({}) must be a str&#39;.format(type(mean_option)))
        if mean_option == &#39;manual&#39;:
            if not pl.isnumeric(mean):
                raise TypeError(&#39;`mean` ({}) must be a numeric&#39;.format(type(mean)))
        elif mean_option in [&#39;zero&#39;, &#39;auto&#39;]:
            mean = 0
        else:
            raise ValueError(&#39;`mean_option` ({}) not recognized&#39;.format(mean_option))
        self.prior.mean.override_value(mean)

        # Set the variance
        if not pl.isstr(var_option):
            raise TypeError(&#39;`var_option` ({}) must be a str&#39;.format(type(var_option)))
        if var_option == &#39;manual&#39;:
            if not pl.isnumeric(var):
                raise TypeError(&#39;`var` ({}) must be a numeric&#39;.format(type(var)))
            if var &lt;= 0:
                raise ValueError(&#39;`var` ({}) must be positive&#39;.format(var))
        elif var_option in [&#39;same-as-aii&#39;, &#39;auto&#39;]:
            var = self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].value
        else:
            raise ValueError(&#39;`var_option` ({}) not recognized&#39;.format(var_option))
        self.prior.var.override_value(var)

        # Set the value
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isnumeric(value):
                raise TypeError(&#39;`value` ({}) must be a numeric&#39;.format(type(value)))
        elif value_option in [&#39;prior-mean&#39;, &#39;auto&#39;]:
            value = self.prior.mean.value
        elif value_option == &#39;zero&#39;:
            value = 0
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
        self.value = value

    def update(self):
        &#39;&#39;&#39;Update using Gibbs sampling
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return

        if self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_pos_indicators == 0:
            # sample from the prior
            self.value = self.prior.sample()
            return

        x = self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].value
        prec = 1/self.G[STRNAMES.PRIOR_VAR_INTERACTIONS].value

        prior_prec = 1/self.prior.var.value
        prior_mean = self.prior.mean.value

        self.var.value = 1/(prior_prec + (len(x)*prec))
        self.mean.value = self.var.value * ((prior_mean * prior_prec) + (np.sum(x)*prec))
        self.sample()


class ClusterInteractionValue(pl.variables.MVN):
    &#39;&#39;&#39;Interactions of Lotka-Voltera

    Since we initialize the interactions object in the `initialize` function,
    make sure that you have initialized the prior of the values of the interactions
    and of the indicators of the interactions before you call the initialization of
    this class
    &#39;&#39;&#39;
    def __init__(self, prior, clustering, **kwargs):
        kwargs[&#39;name&#39;] = STRNAMES.CLUSTER_INTERACTION_VALUE
        pl.variables.MVN.__init__(self, dtype=float, **kwargs)
        self.set_value_shape(shape=(len(self.G.data.asvs),len(self.G.data.asvs)))
        self.add_prior(prior)
        self.clustering = clustering
        self.obj = pl.contrib.Interactions(
            clustering=self.clustering,
            use_indicators=True,
            name=STRNAMES.INTERACTIONS_OBJ, G=self.G,
            signal_when_clusters_change=False)
        self._strr = &#39;None&#39;

    def __str__(self):
        return self._strr

    def __len__(self):
        # Return the number of on interactions
        return self.obj.num_pos_indicators()

    def set_values(self, *args, **kwargs):
        &#39;&#39;&#39;Set the values from an array
        &#39;&#39;&#39;
        self.obj.set_values(*args, **kwargs)

    def initialize(self, value_option, hyperparam_option=None, value=None,
        indicators=None, delay=0):
        &#39;&#39;&#39;Initialize the interactions object.

        Parameters
        ----------
        value_option : str
            This is how to initialize the values
            Options:
                &#39;manual&#39;
                    Set the values of the interactions manually. `value` and `indicators`
                    must also be specified. We assume the values are only set for when
                    `indicators` is True, and that the order of the `indicators` and `values`
                    correspond to how we iterate over the interactions
                    Example
                        3 Clusters
                        indicators = [True, False, False, True, False, True]
                        value = [0.2, 0.8, -0.35]
                &#39;all-off&#39;, &#39;auto&#39;
                    Set all of the interactions and the indicators to 0
                &#39;all-on&#39;
                    Set all of the indicators to on and all the values to 0
        delay : int
            How many MCMC iterations to delay starting to update
        See also
        --------
        `pylab.cluster.Interactions.set_values`
        &#39;&#39;&#39;
        self.obj.set_signal_when_clusters_change(True)
        self.G[STRNAMES.INTERACTIONS_OBJ].value_initializer = self.prior.sample
        self.G[STRNAMES.INTERACTIONS_OBJ].indicator_initializer = self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].prior.sample

        self._there_are_perturbations = self.G.perturbations is not None

        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option in [&#39;auto&#39;, &#39;all-off&#39;]:
            for interaction in self.obj:
                interaction.value = 0
                interaction.indicator = False
        elif value_option == &#39;all-on&#39;:
            for interaction in self.obj:
                interaction.value = 0
                interaction.indicator = True
        elif value_option == &#39;manual&#39;:
            if not np.all(pl.itercheck([value, indicators], pl.isarray)):
                raise TypeError(&#39;`value` ({}) and `indicators` ({}) must be arrays&#39;.format(
                    type(value), type(indicators)))
            if len(value) != np.sum(indicators):
                raise ValueError(&#39;Length of `value` ({}) must equal the number of positive &#39; \
                    &#39;values in `indicators` ({})&#39;.format(len(value), np.sum(indicators)))
            if len(indicators) != self.obj.size:
                raise ValueError(&#39;The length of `indicators` ({}) must be the same as the &#39; \
                    &#39;number of possible interactions ({})&#39;.format(len(indicators), self.obj.size))
            ii = 0
            for i,interaction in enumerate(self.obj):
                interaction.indicator = indicators[i]
                if interaction.indicator:
                    interaction.value = value[ii]
                    ii += 1
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

        self._strr = str(self.obj.get_values(use_indicators=True))
        self.value = self.obj.get_values(use_indicators=True)

    def update(self):
        &#39;&#39;&#39;Update the values (where the indicators are positive) using a multivariate normal
        distribution - call this from regress coeff if you want to update the interactions
        conditional on all the other parameters.
        &#39;&#39;&#39;
        if self.obj.sample_iter &lt; self.delay:
            return
        if self.obj.num_pos_indicators() == 0:
            # logging.info(&#39;No positive indicators, skipping&#39;)
            self._strr = &#39;[]&#39;
            return

        rhs = [
            STRNAMES.CLUSTER_INTERACTION_VALUE]
        lhs = [
            STRNAMES.GROWTH_VALUE,
            STRNAMES.SELF_INTERACTION_VALUE]
        X = self.G.data.construct_rhs(keys=rhs)
        y = self.G.data.construct_lhs(keys=lhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{
                &#39;with_perturbations&#39;:self._there_are_perturbations}})
        process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
            cov=False, sparse=True)
        prior_prec = build_prior_covariance(G=self.G, cov=False,
            order=rhs, sparse=True)

        pm = prior_prec @ (self.prior.mean.value * np.ones(prior_prec.shape[0]).reshape(-1,1))

        prec = X.T @ process_prec @ X + prior_prec
        cov = pinv(prec, self)
        mean = (cov @ (X.T @ process_prec.dot(y) + pm)).ravel()

        # print(np.hstack((y, self.G.data.lhs.vector.reshape(-1,1))))
        # for perturbation in self.G.perturbations:
        #     print()
        #     print(perturbation.magnitude.cluster_array())
        #     print(perturbation.indicator.cluster_array())

        self.mean.value = mean
        self.cov.value = cov
        value = self.sample()
        self.obj.set_values(arr=value, use_indicators=True)
        self.update_str()

        if np.any(np.isnan(self.value)):
            logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
            logging.critical(&#39;nan in cov: {}&#39;.format(np.any(np.isnan(self.cov.value))))
            logging.critical(&#39;value: {}&#39;.format(self.value))
            raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))

    def update_str(self):
        self._strr = str(self.obj.get_values(use_indicators=True))

    def set_trace(self):
        self.obj.set_trace()

    def add_trace(self):
        self.obj.add_trace()


class ClusterInteractionIndicatorProbability(pl.variables.Beta):
    &#39;&#39;&#39;This is the posterior for the probability of a cluster being on
    &#39;&#39;&#39;
    def __init__(self, prior, **kwargs):
        &#39;&#39;&#39;Parameters

        prior (pl.variables.Beta)
            - prior probability
        **kwargs
            - Other options like graph, value
        &#39;&#39;&#39;
        kwargs[&#39;name&#39;] = STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB
        pl.variables.Beta.__init__(self, a=prior.a.value, b=prior.b.value,
            dtype=float, **kwargs)
        self.add_prior(prior)

    def initialize(self, value_option, hyperparam_option, a=None, b=None, value=None,
        N=&#39;auto&#39;, delay=0):
        &#39;&#39;&#39;Initialize the hyperparameters of the beta prior

        Parameters
        ----------
        value_option : str
            - Option to initialize the value by
            - Options
                - &#39;manual&#39;
                    - Set the values manually, `value` must be specified
                - &#39;auto&#39;
                    - Set to the mean of the prior
        hyperparam_option : str
            - If it is a string, then set it by the designated option
            - Options
                - &#39;manual&#39;
                    - Set the value manually. `a` and `b` must also be specified
                - &#39;weak-agnostic&#39;
                    - a=b=0.5
                - &#39;strong-dense&#39;
                    - a = N(N-1), N are the expected number of clusters
                    - b = 0.5
                - &#39;strong-sparse&#39;
                    - a = 0.5
                    - b = N(N-1), N are the expected number of clusters
                - &#39;very-strong-sparse&#39;
                    - a = 0.5
                    - b = n_asvs * (n_asvs-1)
        N : str, int
            This is the number of clusters to set the hyperparam options to 
            (if they are dependent on the number of cluster). If &#39;auto&#39;, set to the expected number
            of clusters from a dirichlet process. Else use this number (must be an int).
        a, b : int, float
            - User specified values
            - Only necessary if `hyperparam_option` == &#39;manual&#39;
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        if hyperparam_option == &#39;manual&#39;:
            if pl.isnumeric(a) and pl.isnumeric(b):
                self.prior.a.override_value(a)
                self.prior.b.override_value(b)
            else:
                raise ValueError(&#39;a ({}) and b ({}) must be numerics (float, int)&#39;.format(
                    a.__class__, b.__class__))
        elif hyperparam_option in [&#39;weak-agnostic&#39;, &#39;auto&#39;]:
            self.prior.a.override_value(0.5)
            self.prior.b.override_value(0.5)
        elif hyperparam_option == &#39;strong-dense&#39;:
            if pl.isstr(N):
                if N == &#39;auto&#39;:
                    N = expected_n_clusters(G=self.G)
                else:
                    raise ValueError(&#39;`N` ({}) nto recognized&#39;.format(N))
            elif pl.isint(N):
                if N &lt; 0:
                    raise ValueError(&#39;`N` ({}) must be positive&#39;.format(N))
            else:
                raise TypeError(&#39;`N` ({}) type not recognized&#39;.format(type(N)))
            self.prior.a.override_value(N * (N - 1))
            self.prior.b.override_value(0.5)
        elif hyperparam_option == &#39;strong-sparse&#39;:
            if pl.isstr(N):
                if N == &#39;auto&#39;:
                    N = expected_n_clusters(G=self.G)
                else:
                    raise ValueError(&#39;`N` ({}) nto recognized&#39;.format(N))
            elif pl.isint(N):
                if N &lt; 0:
                    raise ValueError(&#39;`N` ({}) must be positive&#39;.format(N))
            else:
                raise TypeError(&#39;`N` ({}) type not recognized&#39;.format(type(N)))
            self.prior.a.override_value(0.5)
            self.prior.b.override_value((N * (N - 1)))
        elif hyperparam_option == &#39;very-strong-sparse&#39;:
            N = self.G.data.n_asvs
            self.prior.a.override_value(0.5)
            self.prior.b.override_value((N * (N - 1)))
        else:
            raise ValueError(&#39;option `{}` not recognized&#39;.format(hyperparam_option))

        if value_option == &#39;manual&#39;:
            if pl.isnumeric(value):
                self.value = value
            else:
                raise ValueError(&#39;`value` ({}) must be a numeric (float,int)&#39;.format(
                    value.__class__))
        elif value_option == &#39;auto&#39;:
            self.value = self.prior.mean()/100000
        else:
            raise ValueError(&#39;value option &#34;{}&#34; not recognized for indicator prob&#39;.format(
                value_option))

        self.a.value = self.prior.a.value
        self.b.value = self.prior.b.value
        logging.info(&#39;Indicator Probability initialization results:\n&#39; \
            &#39;\tprior a: {}\n&#39; \
            &#39;\tprior b: {}\n&#39; \
            &#39;\tvalue: {}&#39;.format(
                self.prior.a.value, self.prior.b.value, self.value))

    def update(self):
        &#39;&#39;&#39;Sample the posterior given the data
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return
        self.a.value = self.prior.a.value + \
            self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_pos_indicators
        self.b.value = self.prior.b.value + \
            self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_neg_indicators
        self.sample()
        return self.value


class ClusterInteractionIndicators(pl.variables.Variable):
    &#39;&#39;&#39;This is the posterior of the Indicator variables on the interactions
    between clusters. These clusters are not fixed.
    If `value` is not `None`, then we set that to be the initial indicators
    of the cluster interactions
    &#39;&#39;&#39;
    def __init__(self, prior, mp=None, relative=True, **kwargs):
        &#39;&#39;&#39;Parameters

        prior : pl.variables.Beta
            This is the prior of the variable
        mp : str, None
            If `None`, then there is no multiprocessing.
            If it is a str, then there are two options:
                &#39;debug&#39;: pool is done sequentially and not sent to processors
                &#39;full&#39;: pool is done at different processors
        relative : bool
            Whether you update using the relative marginal likelihood or not.
        &#39;&#39;&#39;
        if not pl.isbool(relative):
            raise TypeError(&#39;`relative` ({}) must be a bool&#39;.format(type(relative)))
        if relative:
            if mp is not None:
                raise ValueError(&#39;Multiprocessing is slower for rel. Turn mp off&#39;)
            self.update = self.update_relative
        else:
            self.update = self.update_direct

        if mp is not None:
            if not pl.isstr(mp):
                raise TypeError(&#39;`mp` ({}) must be a str&#39;.format(type(mp)))
            if mp not in [&#39;full&#39;, &#39;debug&#39;]:
                raise ValueError(&#39;`mp` ({}) not recognized&#39;.format(mp))

        kwargs[&#39;name&#39;] = STRNAMES.CLUSTER_INTERACTION_INDICATOR
        pl.variables.Variable.__init__(self, dtype=bool, **kwargs)
        self.n_asvs = len(self.G.data.asvs)
        self.set_value_shape(shape=(self.n_asvs, self.n_asvs))
        self.add_prior(prior)
        self.clustering = self.G[STRNAMES.CLUSTERING_OBJ]
        self.mp = mp
        self.relative = relative

        # parameters used during update
        self.X = None
        self.y = None
        self.process_prec_matrix = None
        self._strr = &#39;None&#39;

    def initialize(self, delay=0, run_every_n_iterations=1):
        &#39;&#39;&#39;Do nothing, the indicators are set in `ClusterInteractionValue`.

        Parameters
        ----------
        delay : int
            How many iterations to delay starting to update the values
        run_every_n_iterations : int
            Which iteration to run on
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        if not pl.isint(run_every_n_iterations):
            raise TypeError(&#39;`run_every_n_iterations` ({}) must be an int&#39;.format(
                type(run_every_n_iterations)))
        if run_every_n_iterations &lt;= 0:
            raise ValueError(&#39;`run_every_n_iterations` ({}) must be &gt; 0&#39;.format(
                run_every_n_iterations))

        self.delay = delay
        self.run_every_n_iterations = run_every_n_iterations
        self._there_are_perturbations = self.G.perturbations is not None
        self.update_cnt_indicators()
        self.interactions = self.G[STRNAMES.INTERACTIONS_OBJ]
        self.n_asvs = len(self.G.data.asvs)

        # These are for the function `self._make_idx_for_clusters`
        self.ndts_bias = []
        self.n_replicates = self.G.data.n_replicates
        self.n_dts_for_replicate = self.G.data.n_dts_for_replicate
        self.total_dts = np.sum(self.n_dts_for_replicate)
        self.replicate_bias = np.zeros(self.n_replicates, dtype=int)
        for ridx in range(1, self.n_replicates):
            self.replicate_bias[ridx] = self.replicate_bias[ridx-1] + \
                self.n_asvs * self.n_dts_for_replicate[ridx - 1]
        for ridx in range(self.G.data.n_replicates):
            self.ndts_bias.append(
                np.arange(0, self.G.data.n_dts_for_replicate[ridx] * self.n_asvs, self.n_asvs))

        # Makes a dictionary that maps the asv index to the rows that it the ASV in
        self.oidx2rows = {}
        for oidx in range(self.n_asvs):
            idxs = np.zeros(self.total_dts, dtype=int)
            i = 0
            for ridx in range(self.n_replicates):
                temp = np.arange(0, self.n_dts_for_replicate[ridx] * self.n_asvs, self.n_asvs)
                temp = temp + oidx
                temp = temp + self.replicate_bias[ridx]
                l = len(temp)
                idxs[i:i+l] = temp
                i += l
            self.oidx2rows[oidx] = idxs

    def add_trace(self):
        self.value = self.G[STRNAMES.INTERACTIONS_OBJ].get_datalevel_indicator_matrix()
        pl.variables.Variable.add_trace(self)

    def update_cnt_indicators(self):
        self.num_pos_indicators = self.G[STRNAMES.INTERACTIONS_OBJ].num_pos_indicators()
        self.num_neg_indicators = self.G[STRNAMES.INTERACTIONS_OBJ].num_neg_indicators()

    def __str__(self):
        return self._strr

    # @profile
    def update_direct(self):
        &#39;&#39;&#39;Permute the order that the indices that are updated.

        Build the full master interaction matrix that we can then slice
        &#39;&#39;&#39;
        start = time.time()
        if self.sample_iter &lt; self.delay:
            # for interaction in self.interactions:
            #     interaction.indicator=False
            self._strr = &#39;{}\ntotal time: {}&#39;.format(
                self.interactions.get_indicators(), time.time()-start)
            return
        if self.sample_iter % self.run_every_n_iterations != 0:
            return

        # keys = npr.permutation(self.interactions.key_pairs())
        idxs = npr.permutation(self.interactions.size)
        for idx in idxs:
            # print(&#39;indicator {}/{}&#39;.format(iii, len(keys)))
            self.update_single_idx_slow(idx=idx)

        self.update_cnt_indicators()
        # Since slicing is literally so slow, it is faster to build than just slicing M
        self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
            build=True, build_for_neg_ind=False)
        iii = self.interactions.get_indicators()
        n_on = np.sum(iii)
        self._strr = &#39;{}\ntotal time: {}, n_interactions: {}/{}, {:.2f}&#39;.format(
            iii, time.time()-start, n_on, len(iii), n_on/len(iii))

    def update_single_idx_slow(self, idx):
        &#39;&#39;&#39;Update the likelihood for interaction `idx`

        Parameters
        ----------
        idx : int
            This is the index of the interaction we are updating
        &#39;&#39;&#39;
        prior_ll_on = np.log(self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].value)
        prior_ll_off = np.log(1 - self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].value)

        d_on = self.calculate_marginal_loglikelihood(idx=idx, val=True)
        d_off = self.calculate_marginal_loglikelihood(idx=idx, val=False)

        ll_on = d_on[&#39;ret&#39;] + prior_ll_on
        ll_off = d_off[&#39;ret&#39;] + prior_ll_off

        # print(&#39;slow\n\ttotal: {}\n\tbeta_logdet_diff: {}\n\t&#39; \
        #     &#39;priorvar_logdet_diff: {}\n\tbEb_diff: {}\n\t&#39; \
        #     &#39;bEbprior_diff: {}\n\tn_on_when_off: {}&#39;.format(
        #         ll_on - ll_off,
        #         d_on[&#39;beta_logdet&#39;] - d_off[&#39;beta_logdet&#39;],
        #         d_on[&#39;priorvar_logdet&#39;] - d_off[&#39;priorvar_logdet&#39;],
        #         d_on[&#39;bEb&#39;] - d_off[&#39;bEb&#39;],
        #         d_on[&#39;bEbprior&#39;] - d_off[&#39;bEbprior&#39;],
        #         self.interactions.num_pos_indicators()))

        dd = [ll_off, ll_on]

        res = bool(sample_categorical_log(dd))
        self.interactions.iloc(idx).indicator = res
        self.update_cnt_indicators()

    # @profile
    def _make_idx_vector_for_clusters(self):
        &#39;&#39;&#39;Creates a dictionary that maps the cluster id to the
        rows that correspond to each ASV in the cluster.

        We cannot cast this with numba because it does not support Fortran style
        raveling :(.

        Returns
        -------
        dict: int -&gt; np.ndarray
            Maps the cluster ID to the row indices corresponding to it
        &#39;&#39;&#39;
        clusters = [np.asarray(oidxs, dtype=int).reshape(-1,1) \
            for oidxs in self.clustering.toarray()]

        d = {}
        cids = self.clustering.order

        for cidx,cid in enumerate(cids):
            a = np.zeros(len(clusters[cidx]) * self.total_dts, dtype=int)
            i = 0
            for ridx in range(self.n_replicates):
                idxs = np.zeros(
                    (len(clusters[cidx]),
                    self.n_dts_for_replicate[ridx]), int)
                idxs = idxs + clusters[cidx]
                idxs = idxs + self.ndts_bias[ridx]
                idxs = idxs + self.replicate_bias[ridx]
                idxs = idxs.ravel(&#39;F&#39;)
                l = len(idxs)
                a[i:i+l] = idxs
                i += l

            d[cid] = a
        
        if self.G.data.zero_inflation_transition_policy is not None:
            # We need to convert the indices that are meant from no zero inflation to 
            # ones that take into account zero inflation - use the array from 
            # `data.Data._setrows_to_include_zero_inflation`. If the index should be
            # included, then we subtract the number of indexes that are previously off
            # before that index. If it should not be included then we exclude it
            prevoff_arr = self.G.data.off_previously_arr_zero_inflation
            rows_to_include = self.G.data.rows_to_include_zero_inflation
            for cid in d:
                arr = d[cid]
                new_arr = np.zeros(len(arr), dtype=int)
                n = 0
                for idx in arr:
                    if rows_to_include[idx]:
                        new_arr[n] = idx - prevoff_arr[idx]
                        n += 1

                new_arr = new_arr[:n]
                d[cid] = new_arr
        return d

    # @profile
    def make_rel_params(self):
        &#39;&#39;&#39;We make the parameters needed to update the relative log-likelihod.
        This function is called once at the beginning of the update.

        Parameters that we create with this function
        --------------------------------------------
        ys : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the observation matrix that it
            corresponds to (only the ASVs in the target cluster). This 
            array already has the growth and self-interactions subtracted
            out:
                $ \frac{log(x_{k+1}) - log(x_{k})}{dt} - a_{1,k} - a_{2,k}x_{k} $
        process_precs : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the vector of the process precision
            that corresponds to the target cluster (only the ASVs in the target
            cluster). This is a 1D array that corresponds to the diagonal of what
            would be the precision matrix.
        interactionXs : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the matrix of the design matrix of the
            interactions. Only includes the rows that correspond to the ASVs in the
            target cluster. It includes every single column as if all of the indicators
            are on. We only index out the columns when we are doing the marginalization.
        prior_prec_interaction : float
            Prior precision of the interaction value. We then use this
            value to make the diagonal of the prior precision.
        prior_var_interaction : float
            Prior variance of the interaction value.
        prior_mean_interaction : float
            Prior mean of the interaction values. We use this value
            to make the prior mean vector during the marginalization.
        n_on_master : int
            How many interactions are on at any one time. We adjust this
            throughout the update depending on what interactions we turn off and
            on.
        prior_ll_on : float
            Prior log likelihood of a positive interaction
        prior_ll_off : float
            Prior log likelihood of the negative interaction
        priorvar_logdet_diff : float
            This is the prior variance log determinant that we add when the indicator
            is positive.

        Parameters created if there are perturbations
        ---------------------------------------------
        perturbationsXs : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the design matrix that corresponds to 
            the on perturbations of the target clusters. This is preindexed in
            both rows and columns
        prior_prec_perturbations : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the diagonal of the prior precision
            of the perturbations
        prior_var_perturbations : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the diagonal of the prior variance 
            of the perturbations
        prior_mean_perturbations : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the vector of the prior mean of the
            perturbations
        &#39;&#39;&#39;
        # Get the row indices for each cluster
        row_idxs = self._make_idx_vector_for_clusters()

        # Create ys
        self.ys = {}
        y = self.G.data.construct_lhs(keys=[
            STRNAMES.SELF_INTERACTION_VALUE, STRNAMES.GROWTH_VALUE],
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;: False}})
        for tcid in self.clustering.order:
            self.ys[tcid] = y[row_idxs[tcid], :]

        # Create process_precs
        self.process_precs = {}
        process_prec_diag = self.G[STRNAMES.PROCESSVAR].prec
        for tcid in self.clustering.order:
            self.process_precs[tcid] = process_prec_diag[row_idxs[tcid]]

        # Make interactionXs
        self.interactionXs = {}
        self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
            build=True, build_for_neg_ind=True)
        XM_master = self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].toarray()
        for tcid in self.clustering.order:
            self.interactionXs[tcid] = XM_master[row_idxs[tcid], :]

        # Make prior parameters
        self.prior_var_interaction = self.G[STRNAMES.PRIOR_VAR_INTERACTIONS].value
        self.prior_prec_interaction = 1/self.prior_var_interaction
        self.prior_mean_interaction = self.G[STRNAMES.PRIOR_MEAN_INTERACTIONS].value
        self.prior_ll_on = np.log(self.prior.value)
        self.prior_ll_off = np.log(1 - self.prior.value)
        self.n_on_master = self.interactions.num_pos_indicators()

        # Make priorvar_logdet
        self.priorvar_logdet = np.log(self.prior_var_interaction)

        if self._there_are_perturbations:
            XMpert_master = self.G.data.design_matrices[STRNAMES.PERT_VALUE].toarray()

            # Make perturbationsXs
            self.perturbationsXs = {}
            for tcid in self.clustering.order:
                rows = row_idxs[tcid]
                cols = []
                i = 0
                for perturbation in self.G.perturbations:
                    for cid in perturbation.indicator.value:
                        if perturbation.indicator.value[cid]:
                            if cid == tcid:
                                cols.append(i)
                            i += 1
                cols = np.asarray(cols, dtype=int)

                self.perturbationsXs[tcid] = pl.util.fast_index(M=XMpert_master,
                    rows=rows, cols=cols)

            # Make prior perturbation parameters
            self.prior_mean_perturbations = {}
            self.prior_var_perturbations = {}
            self.prior_prec_perturbations = {}
            for tcid in self.clustering.order:
                mean = []
                var = []
                for perturbation in self.G.perturbations:
                    if perturbation.indicator.value[tcid]:
                        # This is on, get the parameters
                        mean.append(perturbation.magnitude.prior.mean.value)
                        var.append(perturbation.magnitude.prior.var.value)
                self.prior_mean_perturbations[tcid] = np.asarray(mean)
                self.prior_var_perturbations[tcid] = np.asarray(var)
                self.prior_prec_perturbations[tcid] = 1/self.prior_var_perturbations[tcid]

            # Make priorvar_det_perturbations
            self.priorvar_det_perturbations = 0
            for perturbation in self.G.perturbations:
                self.priorvar_det_perturbations += \
                    perturbation.indicator.num_on_clusters() * \
                    perturbation.magnitude.prior.var.value

    # @profile
    def update_relative(self):
        &#39;&#39;&#39;Update the indicators variables by calculating the relative loglikelihoods
        of it being on as supposed to off. Because this is a relative loglikelihood,
        we only need to take into account the following parameters of the model:
            - Only the ASVs in the target cluster of the interaction
            - Only the positively indicated interactions going into the
              target cluster.

        This is 1000&#39;s of times faster than `update` because we are operating on matrices
        that are MUCH smaller than in a full system. These matrices are also considered dense
        so we do all of our computations without sparse matrices.

        We permute the order that the indices are updated for more robust mixing.
        &#39;&#39;&#39;
        start = time.time()
        if self.sample_iter &lt; self.delay:
            self._strr = &#39;{}\ntotal time: {}&#39;.format(
                self.interactions.get_indicators(), time.time()-start)
            return
        if self.sample_iter % self.run_every_n_iterations != 0:
            return

        idxs = npr.permutation(self.interactions.size)

        self.make_rel_params()
        for idx in idxs:
            self.update_single_idx_fast(idx=idx)

        self.update_cnt_indicators()
        # Since slicing is literally so slow, it is faster to build than just slicing M
        self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
            build=True, build_for_neg_ind=False)
        iii = self.interactions.get_indicators()
        n_on = np.sum(iii)
        self._strr = &#39;{}\ntotal time: {}, n_interactions: {}/{}, {:.2f}&#39;.format(
            iii, time.time()-start, n_on, len(iii), n_on/len(iii))

    def calculate_marginal_loglikelihood(self, idx, val):
        &#39;&#39;&#39;Calculate the likelihood of interaction `idx` with the value `val`
        &#39;&#39;&#39;
        # Build and initialize
        self.interactions.iloc(idx).indicator = val
        self.update_cnt_indicators()
        self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build()

        lhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
        if self._there_are_perturbations:
            rhs = [STRNAMES.PERT_VALUE, STRNAMES.CLUSTER_INTERACTION_VALUE]
        else:
            rhs = [STRNAMES.CLUSTER_INTERACTION_VALUE]

        y = self.G.data.construct_lhs(lhs, 
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;: False}})
        X = self.G.data.construct_rhs(rhs, toarray=True)

        if X.shape[1] == 0:
            return {
            &#39;ret&#39;: 0,
            &#39;beta_logdet&#39;: 0,
            &#39;priorvar_logdet&#39;: 0,
            &#39;bEb&#39;: 0,
            &#39;bEbprior&#39;: 0}

        process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(cov=False, sparse=False)
        prior_prec = build_prior_covariance(G=self.G, cov=False, order=rhs, sparse=False)
        prior_var = build_prior_covariance(G=self.G, cov=True, order=rhs, sparse=False)
        prior_mean = build_prior_mean(G=self.G, order=rhs, shape=(-1,1))


        # Calculate the posterior
        beta_prec = X.T @ process_prec @ X + prior_prec
        beta_cov = pinv(beta_prec, self)
        beta_mean = beta_cov @ ( X.T @ process_prec @ y + prior_prec @ prior_mean )
        
        beta_mean = np.asarray(beta_mean).reshape(-1,1)

        # Perform the marginalization
        try:
            beta_logdet = log_det(beta_cov, self)
        except:
            logging.critical(&#39;Crashed in log_det&#39;)
            logging.critical(&#39;beta_cov:\n{}&#39;.format(beta_cov))
            logging.critical(&#39;prior_prec\n{}&#39;.format(prior_prec))
            raise
        priorvar_logdet = log_det(prior_var, self)
        ll2 = 0.5 * (beta_logdet - priorvar_logdet)

        a = np.asarray(prior_mean.T @ prior_prec @ prior_mean)[0,0]
        b = np.asarray(beta_mean.T @ beta_prec @ beta_mean)[0,0]
        ll3 = -0.5 * (a  - b)

        return {
            &#39;ret&#39;: ll2+ll3,
            &#39;beta_logdet&#39;: beta_logdet,
            &#39;priorvar_logdet&#39;: priorvar_logdet,
            &#39;bEb&#39;: b,
            &#39;bEbprior&#39;: a}

    def update_single_idx_fast(self, idx):
        &#39;&#39;&#39;Calculate the relative log likelihood of changing the indicator of the
        interaction at index `idx`.

        This is about 20X faster than `update_single_idx_slow`.

        Parameters
        ----------
        idx : int
            This is the index of the interaction index we are sampling
        &#39;&#39;&#39;
        # Get the current interaction by the index
        self.curr_interaction = self.interactions.iloc(idx)
        start_sign = self.curr_interaction.indicator
        
        tcid = self.curr_interaction.target_cid
        self.curr_interaction.indicator = False
        self.col_idxs = np.asarray(
            self.interactions.get_arg_indicators(target_cid=tcid),
            dtype=int)

        if not start_sign:
            self.n_on_master += 1
            self.num_pos_indicators += 1
            self.num_neg_indicators -= 1

        d_on = self.calculate_relative_marginal_loglikelihood(idx=idx, val=True)

        self.n_on_master -= 1
        self.num_pos_indicators -= 1
        self.num_neg_indicators += 1
        d_off = self.calculate_relative_marginal_loglikelihood(idx=idx, val=False)

        ll_on = d_on + self.prior_ll_on
        ll_off = d_off + self.prior_ll_off

        dd = [ll_off, ll_on]

        # print(&#39;\nindicator&#39;, idx)
        # print(&#39;fast\n\ttotal: {}\n\tbeta_logdet_diff: {}\n\t&#39; \
        #     &#39;priorvar_logdet_diff: {}\n\tbEb_diff: {}\n\t&#39; \
        #     &#39;bEbprior_diff: {}\n\tn_on_when_off: {}&#39;.format(
        #         ll_on - ll_off,
        #         d_on[&#39;beta_logdet&#39;] - d_off[&#39;beta_logdet&#39;],
        #         d_on[&#39;priorvar_logdet&#39;] - d_off[&#39;priorvar_logdet&#39;],
        #         d_on[&#39;bEb&#39;] - d_off[&#39;bEb&#39;],
        #         d_on[&#39;bEbprior&#39;] - d_off[&#39;bEbprior&#39;],
        #         self.n_on_master))
        # print(&#39;log(prior_var)&#39;, np.log(self.prior_var_interaction))
        # self.update_single_idx_slow(idx)

        res = bool(sample_categorical_log(dd))
        if res:
            self.n_on_master += 1
            self.num_pos_indicators += 1
            self.num_neg_indicators -= 1
            self.curr_interaction.indicator = True

    def calculate_relative_marginal_loglikelihood(self, idx, val):
        &#39;&#39;&#39;Calculate the relative marginal log likelihood for the interaction index
        `idx` with the indicator `val`

        Parameters
        ----------
        idx : int
            This is the index of the interaction
        val : bool
            This is the value to calculate it as
        &#39;&#39;&#39;
        tcid = self.curr_interaction.target_cid

        y = self.ys[tcid]
        process_prec = self.process_precs[tcid]

        # Make X, prior mean, and prior_var
        if val:
            cols = np.append(self.col_idxs, idx)
        else:
            cols = self.col_idxs
        
        X = self.interactionXs[tcid][:, cols]
        prior_mean = np.full(len(cols), self.prior_mean_interaction)
        prior_prec_diag = np.full(len(cols), self.prior_prec_interaction)

        if self._there_are_perturbations:
            Xpert = self.perturbationsXs[tcid]
            X = np.hstack((X, Xpert))

            prior_mean = np.append(
                prior_mean,
                self.prior_mean_perturbations[tcid])
            
            prior_prec_diag = np.append(
                prior_prec_diag,
                self.prior_prec_perturbations[tcid])

        if X.shape[1] == 0:
            # return {
            #     &#39;ret&#39;: 0,
            #     &#39;beta_logdet&#39;: 0,
            #     &#39;priorvar_logdet&#39;: 0,
            #     &#39;bEb&#39;: 0,
            #     &#39;bEbprior&#39;: 0}
            return 0

        prior_prec = np.diag(prior_prec_diag)
        pm = (prior_prec_diag * prior_mean).reshape(-1,1)

        # Do the marginalization
        a = X.T * process_prec

        beta_prec = (a @ X) + prior_prec
        beta_cov = pinv(beta_prec, self)
        beta_mean = beta_cov @ ((a @ y) + pm )

        bEb = (beta_mean.T @ beta_prec @ beta_mean)[0,0]
        try:
            beta_logdet = log_det(beta_cov, self)
        except:
            logging.critical(&#39;Crashed in log_det&#39;)
            logging.critical(&#39;beta_cov:\n{}&#39;.format(beta_cov))
            logging.critical(&#39;prior_prec\n{}&#39;.format(prior_prec))

            logging.critical(&#39;here&#39;)
            print(&#39;y&#39;)
            print(y.shape)
            print(y)
            print(&#39;process_prec&#39;)
            print(process_prec.shape)
            print(&#39;X&#39;)
            print(X.shape)
            print(X)
            print(&#39;priors&#39;)
            print(prior_mean)
            print(prior_prec_diag)
            print(&#39;self-interactions&#39;)
            X = pl.toarray(self.G.data.design_matrices[STRNAMES.SELF_INTERACTION_VALUE].matrix)
            print(X.shape)
            print(np.any(np.isnan(X)))
            print(&#39;growth&#39;)
            X = pl.toarray(self.G.data.design_matrices[STRNAMES.GROWTH_VALUE].matrix_without_perturbations)
            print(X.shape)
            print(np.any(np.isnan(X)))
            print(&#39;orig y&#39;)
            y = self.G.data.lhs.vector
            print(y.shape)
            print(np.any(np.isnan(y)))
            print(&#39;cluster-interactions&#39;)
            X = pl.toarray(self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].matrix)
            print(X.shape)
            print(np.any(np.isnan(X)))

            n_on = 0
            for row in range(X.shape[0]):
                n_on += np.any(np.isnan(X[row]))

            print(&#39;nans on {}/{} rows&#39;.format(n_on, X.shape[0]))
                    

            raise
        
        if val:
            bEbprior = (self.prior_mean_interaction**2)/self.prior_var_interaction
            priorvar_logdet = self.priorvar_logdet
        else:
            bEbprior = 0
            priorvar_logdet = 0

        ll2 = 0.5 * (beta_logdet - priorvar_logdet)
        ll3 = 0.5 * (bEb - bEbprior)

        # return {
        #     &#39;ret&#39;: ll2+ll3,
        #     &#39;beta_logdet&#39;: beta_logdet,
        #     &#39;priorvar_logdet&#39;: priorvar_logdet,
        #     &#39;bEb&#39;: bEb,
        #     &#39;bEbprior&#39;: bEbprior}
        return ll2 + ll3
            
    def kill(self):
        pass</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mdsine2.interactions.ClusterInteractionIndicatorProbability"><code class="flex name class">
<span>class <span class="ident">ClusterInteractionIndicatorProbability</span></span>
<span>(</span><span>prior, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the posterior for the probability of a cluster being on</p>
<p>Parameters</p>
<p>prior (pl.variables.Beta)
- prior probability
**kwargs
- Other options like graph, value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClusterInteractionIndicatorProbability(pl.variables.Beta):
    &#39;&#39;&#39;This is the posterior for the probability of a cluster being on
    &#39;&#39;&#39;
    def __init__(self, prior, **kwargs):
        &#39;&#39;&#39;Parameters

        prior (pl.variables.Beta)
            - prior probability
        **kwargs
            - Other options like graph, value
        &#39;&#39;&#39;
        kwargs[&#39;name&#39;] = STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB
        pl.variables.Beta.__init__(self, a=prior.a.value, b=prior.b.value,
            dtype=float, **kwargs)
        self.add_prior(prior)

    def initialize(self, value_option, hyperparam_option, a=None, b=None, value=None,
        N=&#39;auto&#39;, delay=0):
        &#39;&#39;&#39;Initialize the hyperparameters of the beta prior

        Parameters
        ----------
        value_option : str
            - Option to initialize the value by
            - Options
                - &#39;manual&#39;
                    - Set the values manually, `value` must be specified
                - &#39;auto&#39;
                    - Set to the mean of the prior
        hyperparam_option : str
            - If it is a string, then set it by the designated option
            - Options
                - &#39;manual&#39;
                    - Set the value manually. `a` and `b` must also be specified
                - &#39;weak-agnostic&#39;
                    - a=b=0.5
                - &#39;strong-dense&#39;
                    - a = N(N-1), N are the expected number of clusters
                    - b = 0.5
                - &#39;strong-sparse&#39;
                    - a = 0.5
                    - b = N(N-1), N are the expected number of clusters
                - &#39;very-strong-sparse&#39;
                    - a = 0.5
                    - b = n_asvs * (n_asvs-1)
        N : str, int
            This is the number of clusters to set the hyperparam options to 
            (if they are dependent on the number of cluster). If &#39;auto&#39;, set to the expected number
            of clusters from a dirichlet process. Else use this number (must be an int).
        a, b : int, float
            - User specified values
            - Only necessary if `hyperparam_option` == &#39;manual&#39;
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        if hyperparam_option == &#39;manual&#39;:
            if pl.isnumeric(a) and pl.isnumeric(b):
                self.prior.a.override_value(a)
                self.prior.b.override_value(b)
            else:
                raise ValueError(&#39;a ({}) and b ({}) must be numerics (float, int)&#39;.format(
                    a.__class__, b.__class__))
        elif hyperparam_option in [&#39;weak-agnostic&#39;, &#39;auto&#39;]:
            self.prior.a.override_value(0.5)
            self.prior.b.override_value(0.5)
        elif hyperparam_option == &#39;strong-dense&#39;:
            if pl.isstr(N):
                if N == &#39;auto&#39;:
                    N = expected_n_clusters(G=self.G)
                else:
                    raise ValueError(&#39;`N` ({}) nto recognized&#39;.format(N))
            elif pl.isint(N):
                if N &lt; 0:
                    raise ValueError(&#39;`N` ({}) must be positive&#39;.format(N))
            else:
                raise TypeError(&#39;`N` ({}) type not recognized&#39;.format(type(N)))
            self.prior.a.override_value(N * (N - 1))
            self.prior.b.override_value(0.5)
        elif hyperparam_option == &#39;strong-sparse&#39;:
            if pl.isstr(N):
                if N == &#39;auto&#39;:
                    N = expected_n_clusters(G=self.G)
                else:
                    raise ValueError(&#39;`N` ({}) nto recognized&#39;.format(N))
            elif pl.isint(N):
                if N &lt; 0:
                    raise ValueError(&#39;`N` ({}) must be positive&#39;.format(N))
            else:
                raise TypeError(&#39;`N` ({}) type not recognized&#39;.format(type(N)))
            self.prior.a.override_value(0.5)
            self.prior.b.override_value((N * (N - 1)))
        elif hyperparam_option == &#39;very-strong-sparse&#39;:
            N = self.G.data.n_asvs
            self.prior.a.override_value(0.5)
            self.prior.b.override_value((N * (N - 1)))
        else:
            raise ValueError(&#39;option `{}` not recognized&#39;.format(hyperparam_option))

        if value_option == &#39;manual&#39;:
            if pl.isnumeric(value):
                self.value = value
            else:
                raise ValueError(&#39;`value` ({}) must be a numeric (float,int)&#39;.format(
                    value.__class__))
        elif value_option == &#39;auto&#39;:
            self.value = self.prior.mean()/100000
        else:
            raise ValueError(&#39;value option &#34;{}&#34; not recognized for indicator prob&#39;.format(
                value_option))

        self.a.value = self.prior.a.value
        self.b.value = self.prior.b.value
        logging.info(&#39;Indicator Probability initialization results:\n&#39; \
            &#39;\tprior a: {}\n&#39; \
            &#39;\tprior b: {}\n&#39; \
            &#39;\tvalue: {}&#39;.format(
                self.prior.a.value, self.prior.b.value, self.value))

    def update(self):
        &#39;&#39;&#39;Sample the posterior given the data
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return
        self.a.value = self.prior.a.value + \
            self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_pos_indicators
        self.b.value = self.prior.b.value + \
            self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_neg_indicators
        self.sample()
        return self.value</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.Beta" href="pylab/variables.html#mdsine2.pylab.variables.Beta">Beta</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.interactions.ClusterInteractionIndicatorProbability.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, value_option, hyperparam_option, a=None, b=None, value=None, N='auto', delay=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the hyperparameters of the beta prior</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>value_option</code></strong> :&ensp;<code>str</code></dt>
<dd>
<ul>
<li>Option to initialize the value by</li>
<li>Options<ul>
<li>'manual'<ul>
<li>Set the values manually, <code>value</code> must be specified</li>
</ul>
</li>
<li>'auto'<ul>
<li>Set to the mean of the prior</li>
</ul>
</li>
</ul>
</li>
</ul>
</dd>
<dt><strong><code>hyperparam_option</code></strong> :&ensp;<code>str</code></dt>
<dd>
<ul>
<li>If it is a string, then set it by the designated option</li>
<li>Options<ul>
<li>'manual'<ul>
<li>Set the value manually. <code>a</code> and <code>b</code> must also be specified</li>
</ul>
</li>
<li>'weak-agnostic'<ul>
<li>a=b=0.5</li>
</ul>
</li>
<li>'strong-dense'<ul>
<li>a = N(N-1), N are the expected number of clusters</li>
<li>b = 0.5</li>
</ul>
</li>
<li>'strong-sparse'<ul>
<li>a = 0.5</li>
<li>b = N(N-1), N are the expected number of clusters</li>
</ul>
</li>
<li>'very-strong-sparse'<ul>
<li>a = 0.5</li>
<li>b = n_asvs * (n_asvs-1)</li>
</ul>
</li>
</ul>
</li>
</ul>
</dd>
<dt><strong><code>N</code></strong> :&ensp;<code>str, int</code></dt>
<dd>This is the number of clusters to set the hyperparam options to
(if they are dependent on the number of cluster). If 'auto', set to the expected number
of clusters from a dirichlet process. Else use this number (must be an int).</dd>
<dt><strong><code>a</code></strong>, <strong><code>b</code></strong> :&ensp;<code>int, float</code></dt>
<dd>
<ul>
<li>User specified values</li>
<li>Only necessary if <code>hyperparam_option</code> == 'manual'</li>
</ul>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, value_option, hyperparam_option, a=None, b=None, value=None,
    N=&#39;auto&#39;, delay=0):
    &#39;&#39;&#39;Initialize the hyperparameters of the beta prior

    Parameters
    ----------
    value_option : str
        - Option to initialize the value by
        - Options
            - &#39;manual&#39;
                - Set the values manually, `value` must be specified
            - &#39;auto&#39;
                - Set to the mean of the prior
    hyperparam_option : str
        - If it is a string, then set it by the designated option
        - Options
            - &#39;manual&#39;
                - Set the value manually. `a` and `b` must also be specified
            - &#39;weak-agnostic&#39;
                - a=b=0.5
            - &#39;strong-dense&#39;
                - a = N(N-1), N are the expected number of clusters
                - b = 0.5
            - &#39;strong-sparse&#39;
                - a = 0.5
                - b = N(N-1), N are the expected number of clusters
            - &#39;very-strong-sparse&#39;
                - a = 0.5
                - b = n_asvs * (n_asvs-1)
    N : str, int
        This is the number of clusters to set the hyperparam options to 
        (if they are dependent on the number of cluster). If &#39;auto&#39;, set to the expected number
        of clusters from a dirichlet process. Else use this number (must be an int).
    a, b : int, float
        - User specified values
        - Only necessary if `hyperparam_option` == &#39;manual&#39;
    &#39;&#39;&#39;
    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    self.delay = delay

    if hyperparam_option == &#39;manual&#39;:
        if pl.isnumeric(a) and pl.isnumeric(b):
            self.prior.a.override_value(a)
            self.prior.b.override_value(b)
        else:
            raise ValueError(&#39;a ({}) and b ({}) must be numerics (float, int)&#39;.format(
                a.__class__, b.__class__))
    elif hyperparam_option in [&#39;weak-agnostic&#39;, &#39;auto&#39;]:
        self.prior.a.override_value(0.5)
        self.prior.b.override_value(0.5)
    elif hyperparam_option == &#39;strong-dense&#39;:
        if pl.isstr(N):
            if N == &#39;auto&#39;:
                N = expected_n_clusters(G=self.G)
            else:
                raise ValueError(&#39;`N` ({}) nto recognized&#39;.format(N))
        elif pl.isint(N):
            if N &lt; 0:
                raise ValueError(&#39;`N` ({}) must be positive&#39;.format(N))
        else:
            raise TypeError(&#39;`N` ({}) type not recognized&#39;.format(type(N)))
        self.prior.a.override_value(N * (N - 1))
        self.prior.b.override_value(0.5)
    elif hyperparam_option == &#39;strong-sparse&#39;:
        if pl.isstr(N):
            if N == &#39;auto&#39;:
                N = expected_n_clusters(G=self.G)
            else:
                raise ValueError(&#39;`N` ({}) nto recognized&#39;.format(N))
        elif pl.isint(N):
            if N &lt; 0:
                raise ValueError(&#39;`N` ({}) must be positive&#39;.format(N))
        else:
            raise TypeError(&#39;`N` ({}) type not recognized&#39;.format(type(N)))
        self.prior.a.override_value(0.5)
        self.prior.b.override_value((N * (N - 1)))
    elif hyperparam_option == &#39;very-strong-sparse&#39;:
        N = self.G.data.n_asvs
        self.prior.a.override_value(0.5)
        self.prior.b.override_value((N * (N - 1)))
    else:
        raise ValueError(&#39;option `{}` not recognized&#39;.format(hyperparam_option))

    if value_option == &#39;manual&#39;:
        if pl.isnumeric(value):
            self.value = value
        else:
            raise ValueError(&#39;`value` ({}) must be a numeric (float,int)&#39;.format(
                value.__class__))
    elif value_option == &#39;auto&#39;:
        self.value = self.prior.mean()/100000
    else:
        raise ValueError(&#39;value option &#34;{}&#34; not recognized for indicator prob&#39;.format(
            value_option))

    self.a.value = self.prior.a.value
    self.b.value = self.prior.b.value
    logging.info(&#39;Indicator Probability initialization results:\n&#39; \
        &#39;\tprior a: {}\n&#39; \
        &#39;\tprior b: {}\n&#39; \
        &#39;\tvalue: {}&#39;.format(
            self.prior.a.value, self.prior.b.value, self.value))</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicatorProbability.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Sample the posterior given the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#39;&#39;&#39;Sample the posterior given the data
    &#39;&#39;&#39;
    if self.sample_iter &lt; self.delay:
        return
    self.a.value = self.prior.a.value + \
        self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_pos_indicators
    self.b.value = self.prior.b.value + \
        self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_neg_indicators
    self.sample()
    return self.value</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.Beta" href="pylab/variables.html#mdsine2.pylab.variables.Beta">Beta</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.Beta.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.mean" href="pylab/variables.html#mdsine2.pylab.variables.Beta.mean">mean</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.sample" href="pylab/variables.html#mdsine2.pylab.variables.Beta.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Beta.variance" href="pylab/variables.html#mdsine2.pylab.variables.Beta.variance">variance</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators"><code class="flex name class">
<span>class <span class="ident">ClusterInteractionIndicators</span></span>
<span>(</span><span>prior, mp=None, relative=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the posterior of the Indicator variables on the interactions
between clusters. These clusters are not fixed.
If <code>value</code> is not <code>None</code>, then we set that to be the initial indicators
of the cluster interactions</p>
<p>Parameters</p>
<p>prior : pl.variables.Beta
This is the prior of the variable
mp : str, None
If <code>None</code>, then there is no multiprocessing.
If it is a str, then there are two options:
'debug': pool is done sequentially and not sent to processors
'full': pool is done at different processors
relative : bool
Whether you update using the relative marginal likelihood or not.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClusterInteractionIndicators(pl.variables.Variable):
    &#39;&#39;&#39;This is the posterior of the Indicator variables on the interactions
    between clusters. These clusters are not fixed.
    If `value` is not `None`, then we set that to be the initial indicators
    of the cluster interactions
    &#39;&#39;&#39;
    def __init__(self, prior, mp=None, relative=True, **kwargs):
        &#39;&#39;&#39;Parameters

        prior : pl.variables.Beta
            This is the prior of the variable
        mp : str, None
            If `None`, then there is no multiprocessing.
            If it is a str, then there are two options:
                &#39;debug&#39;: pool is done sequentially and not sent to processors
                &#39;full&#39;: pool is done at different processors
        relative : bool
            Whether you update using the relative marginal likelihood or not.
        &#39;&#39;&#39;
        if not pl.isbool(relative):
            raise TypeError(&#39;`relative` ({}) must be a bool&#39;.format(type(relative)))
        if relative:
            if mp is not None:
                raise ValueError(&#39;Multiprocessing is slower for rel. Turn mp off&#39;)
            self.update = self.update_relative
        else:
            self.update = self.update_direct

        if mp is not None:
            if not pl.isstr(mp):
                raise TypeError(&#39;`mp` ({}) must be a str&#39;.format(type(mp)))
            if mp not in [&#39;full&#39;, &#39;debug&#39;]:
                raise ValueError(&#39;`mp` ({}) not recognized&#39;.format(mp))

        kwargs[&#39;name&#39;] = STRNAMES.CLUSTER_INTERACTION_INDICATOR
        pl.variables.Variable.__init__(self, dtype=bool, **kwargs)
        self.n_asvs = len(self.G.data.asvs)
        self.set_value_shape(shape=(self.n_asvs, self.n_asvs))
        self.add_prior(prior)
        self.clustering = self.G[STRNAMES.CLUSTERING_OBJ]
        self.mp = mp
        self.relative = relative

        # parameters used during update
        self.X = None
        self.y = None
        self.process_prec_matrix = None
        self._strr = &#39;None&#39;

    def initialize(self, delay=0, run_every_n_iterations=1):
        &#39;&#39;&#39;Do nothing, the indicators are set in `ClusterInteractionValue`.

        Parameters
        ----------
        delay : int
            How many iterations to delay starting to update the values
        run_every_n_iterations : int
            Which iteration to run on
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        if not pl.isint(run_every_n_iterations):
            raise TypeError(&#39;`run_every_n_iterations` ({}) must be an int&#39;.format(
                type(run_every_n_iterations)))
        if run_every_n_iterations &lt;= 0:
            raise ValueError(&#39;`run_every_n_iterations` ({}) must be &gt; 0&#39;.format(
                run_every_n_iterations))

        self.delay = delay
        self.run_every_n_iterations = run_every_n_iterations
        self._there_are_perturbations = self.G.perturbations is not None
        self.update_cnt_indicators()
        self.interactions = self.G[STRNAMES.INTERACTIONS_OBJ]
        self.n_asvs = len(self.G.data.asvs)

        # These are for the function `self._make_idx_for_clusters`
        self.ndts_bias = []
        self.n_replicates = self.G.data.n_replicates
        self.n_dts_for_replicate = self.G.data.n_dts_for_replicate
        self.total_dts = np.sum(self.n_dts_for_replicate)
        self.replicate_bias = np.zeros(self.n_replicates, dtype=int)
        for ridx in range(1, self.n_replicates):
            self.replicate_bias[ridx] = self.replicate_bias[ridx-1] + \
                self.n_asvs * self.n_dts_for_replicate[ridx - 1]
        for ridx in range(self.G.data.n_replicates):
            self.ndts_bias.append(
                np.arange(0, self.G.data.n_dts_for_replicate[ridx] * self.n_asvs, self.n_asvs))

        # Makes a dictionary that maps the asv index to the rows that it the ASV in
        self.oidx2rows = {}
        for oidx in range(self.n_asvs):
            idxs = np.zeros(self.total_dts, dtype=int)
            i = 0
            for ridx in range(self.n_replicates):
                temp = np.arange(0, self.n_dts_for_replicate[ridx] * self.n_asvs, self.n_asvs)
                temp = temp + oidx
                temp = temp + self.replicate_bias[ridx]
                l = len(temp)
                idxs[i:i+l] = temp
                i += l
            self.oidx2rows[oidx] = idxs

    def add_trace(self):
        self.value = self.G[STRNAMES.INTERACTIONS_OBJ].get_datalevel_indicator_matrix()
        pl.variables.Variable.add_trace(self)

    def update_cnt_indicators(self):
        self.num_pos_indicators = self.G[STRNAMES.INTERACTIONS_OBJ].num_pos_indicators()
        self.num_neg_indicators = self.G[STRNAMES.INTERACTIONS_OBJ].num_neg_indicators()

    def __str__(self):
        return self._strr

    # @profile
    def update_direct(self):
        &#39;&#39;&#39;Permute the order that the indices that are updated.

        Build the full master interaction matrix that we can then slice
        &#39;&#39;&#39;
        start = time.time()
        if self.sample_iter &lt; self.delay:
            # for interaction in self.interactions:
            #     interaction.indicator=False
            self._strr = &#39;{}\ntotal time: {}&#39;.format(
                self.interactions.get_indicators(), time.time()-start)
            return
        if self.sample_iter % self.run_every_n_iterations != 0:
            return

        # keys = npr.permutation(self.interactions.key_pairs())
        idxs = npr.permutation(self.interactions.size)
        for idx in idxs:
            # print(&#39;indicator {}/{}&#39;.format(iii, len(keys)))
            self.update_single_idx_slow(idx=idx)

        self.update_cnt_indicators()
        # Since slicing is literally so slow, it is faster to build than just slicing M
        self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
            build=True, build_for_neg_ind=False)
        iii = self.interactions.get_indicators()
        n_on = np.sum(iii)
        self._strr = &#39;{}\ntotal time: {}, n_interactions: {}/{}, {:.2f}&#39;.format(
            iii, time.time()-start, n_on, len(iii), n_on/len(iii))

    def update_single_idx_slow(self, idx):
        &#39;&#39;&#39;Update the likelihood for interaction `idx`

        Parameters
        ----------
        idx : int
            This is the index of the interaction we are updating
        &#39;&#39;&#39;
        prior_ll_on = np.log(self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].value)
        prior_ll_off = np.log(1 - self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].value)

        d_on = self.calculate_marginal_loglikelihood(idx=idx, val=True)
        d_off = self.calculate_marginal_loglikelihood(idx=idx, val=False)

        ll_on = d_on[&#39;ret&#39;] + prior_ll_on
        ll_off = d_off[&#39;ret&#39;] + prior_ll_off

        # print(&#39;slow\n\ttotal: {}\n\tbeta_logdet_diff: {}\n\t&#39; \
        #     &#39;priorvar_logdet_diff: {}\n\tbEb_diff: {}\n\t&#39; \
        #     &#39;bEbprior_diff: {}\n\tn_on_when_off: {}&#39;.format(
        #         ll_on - ll_off,
        #         d_on[&#39;beta_logdet&#39;] - d_off[&#39;beta_logdet&#39;],
        #         d_on[&#39;priorvar_logdet&#39;] - d_off[&#39;priorvar_logdet&#39;],
        #         d_on[&#39;bEb&#39;] - d_off[&#39;bEb&#39;],
        #         d_on[&#39;bEbprior&#39;] - d_off[&#39;bEbprior&#39;],
        #         self.interactions.num_pos_indicators()))

        dd = [ll_off, ll_on]

        res = bool(sample_categorical_log(dd))
        self.interactions.iloc(idx).indicator = res
        self.update_cnt_indicators()

    # @profile
    def _make_idx_vector_for_clusters(self):
        &#39;&#39;&#39;Creates a dictionary that maps the cluster id to the
        rows that correspond to each ASV in the cluster.

        We cannot cast this with numba because it does not support Fortran style
        raveling :(.

        Returns
        -------
        dict: int -&gt; np.ndarray
            Maps the cluster ID to the row indices corresponding to it
        &#39;&#39;&#39;
        clusters = [np.asarray(oidxs, dtype=int).reshape(-1,1) \
            for oidxs in self.clustering.toarray()]

        d = {}
        cids = self.clustering.order

        for cidx,cid in enumerate(cids):
            a = np.zeros(len(clusters[cidx]) * self.total_dts, dtype=int)
            i = 0
            for ridx in range(self.n_replicates):
                idxs = np.zeros(
                    (len(clusters[cidx]),
                    self.n_dts_for_replicate[ridx]), int)
                idxs = idxs + clusters[cidx]
                idxs = idxs + self.ndts_bias[ridx]
                idxs = idxs + self.replicate_bias[ridx]
                idxs = idxs.ravel(&#39;F&#39;)
                l = len(idxs)
                a[i:i+l] = idxs
                i += l

            d[cid] = a
        
        if self.G.data.zero_inflation_transition_policy is not None:
            # We need to convert the indices that are meant from no zero inflation to 
            # ones that take into account zero inflation - use the array from 
            # `data.Data._setrows_to_include_zero_inflation`. If the index should be
            # included, then we subtract the number of indexes that are previously off
            # before that index. If it should not be included then we exclude it
            prevoff_arr = self.G.data.off_previously_arr_zero_inflation
            rows_to_include = self.G.data.rows_to_include_zero_inflation
            for cid in d:
                arr = d[cid]
                new_arr = np.zeros(len(arr), dtype=int)
                n = 0
                for idx in arr:
                    if rows_to_include[idx]:
                        new_arr[n] = idx - prevoff_arr[idx]
                        n += 1

                new_arr = new_arr[:n]
                d[cid] = new_arr
        return d

    # @profile
    def make_rel_params(self):
        &#39;&#39;&#39;We make the parameters needed to update the relative log-likelihod.
        This function is called once at the beginning of the update.

        Parameters that we create with this function
        --------------------------------------------
        ys : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the observation matrix that it
            corresponds to (only the ASVs in the target cluster). This 
            array already has the growth and self-interactions subtracted
            out:
                $ \frac{log(x_{k+1}) - log(x_{k})}{dt} - a_{1,k} - a_{2,k}x_{k} $
        process_precs : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the vector of the process precision
            that corresponds to the target cluster (only the ASVs in the target
            cluster). This is a 1D array that corresponds to the diagonal of what
            would be the precision matrix.
        interactionXs : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the matrix of the design matrix of the
            interactions. Only includes the rows that correspond to the ASVs in the
            target cluster. It includes every single column as if all of the indicators
            are on. We only index out the columns when we are doing the marginalization.
        prior_prec_interaction : float
            Prior precision of the interaction value. We then use this
            value to make the diagonal of the prior precision.
        prior_var_interaction : float
            Prior variance of the interaction value.
        prior_mean_interaction : float
            Prior mean of the interaction values. We use this value
            to make the prior mean vector during the marginalization.
        n_on_master : int
            How many interactions are on at any one time. We adjust this
            throughout the update depending on what interactions we turn off and
            on.
        prior_ll_on : float
            Prior log likelihood of a positive interaction
        prior_ll_off : float
            Prior log likelihood of the negative interaction
        priorvar_logdet_diff : float
            This is the prior variance log determinant that we add when the indicator
            is positive.

        Parameters created if there are perturbations
        ---------------------------------------------
        perturbationsXs : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the design matrix that corresponds to 
            the on perturbations of the target clusters. This is preindexed in
            both rows and columns
        prior_prec_perturbations : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the diagonal of the prior precision
            of the perturbations
        prior_var_perturbations : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the diagonal of the prior variance 
            of the perturbations
        prior_mean_perturbations : dict (int -&gt; np.ndarray)
            Maps the target cluster id to the vector of the prior mean of the
            perturbations
        &#39;&#39;&#39;
        # Get the row indices for each cluster
        row_idxs = self._make_idx_vector_for_clusters()

        # Create ys
        self.ys = {}
        y = self.G.data.construct_lhs(keys=[
            STRNAMES.SELF_INTERACTION_VALUE, STRNAMES.GROWTH_VALUE],
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;: False}})
        for tcid in self.clustering.order:
            self.ys[tcid] = y[row_idxs[tcid], :]

        # Create process_precs
        self.process_precs = {}
        process_prec_diag = self.G[STRNAMES.PROCESSVAR].prec
        for tcid in self.clustering.order:
            self.process_precs[tcid] = process_prec_diag[row_idxs[tcid]]

        # Make interactionXs
        self.interactionXs = {}
        self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
            build=True, build_for_neg_ind=True)
        XM_master = self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].toarray()
        for tcid in self.clustering.order:
            self.interactionXs[tcid] = XM_master[row_idxs[tcid], :]

        # Make prior parameters
        self.prior_var_interaction = self.G[STRNAMES.PRIOR_VAR_INTERACTIONS].value
        self.prior_prec_interaction = 1/self.prior_var_interaction
        self.prior_mean_interaction = self.G[STRNAMES.PRIOR_MEAN_INTERACTIONS].value
        self.prior_ll_on = np.log(self.prior.value)
        self.prior_ll_off = np.log(1 - self.prior.value)
        self.n_on_master = self.interactions.num_pos_indicators()

        # Make priorvar_logdet
        self.priorvar_logdet = np.log(self.prior_var_interaction)

        if self._there_are_perturbations:
            XMpert_master = self.G.data.design_matrices[STRNAMES.PERT_VALUE].toarray()

            # Make perturbationsXs
            self.perturbationsXs = {}
            for tcid in self.clustering.order:
                rows = row_idxs[tcid]
                cols = []
                i = 0
                for perturbation in self.G.perturbations:
                    for cid in perturbation.indicator.value:
                        if perturbation.indicator.value[cid]:
                            if cid == tcid:
                                cols.append(i)
                            i += 1
                cols = np.asarray(cols, dtype=int)

                self.perturbationsXs[tcid] = pl.util.fast_index(M=XMpert_master,
                    rows=rows, cols=cols)

            # Make prior perturbation parameters
            self.prior_mean_perturbations = {}
            self.prior_var_perturbations = {}
            self.prior_prec_perturbations = {}
            for tcid in self.clustering.order:
                mean = []
                var = []
                for perturbation in self.G.perturbations:
                    if perturbation.indicator.value[tcid]:
                        # This is on, get the parameters
                        mean.append(perturbation.magnitude.prior.mean.value)
                        var.append(perturbation.magnitude.prior.var.value)
                self.prior_mean_perturbations[tcid] = np.asarray(mean)
                self.prior_var_perturbations[tcid] = np.asarray(var)
                self.prior_prec_perturbations[tcid] = 1/self.prior_var_perturbations[tcid]

            # Make priorvar_det_perturbations
            self.priorvar_det_perturbations = 0
            for perturbation in self.G.perturbations:
                self.priorvar_det_perturbations += \
                    perturbation.indicator.num_on_clusters() * \
                    perturbation.magnitude.prior.var.value

    # @profile
    def update_relative(self):
        &#39;&#39;&#39;Update the indicators variables by calculating the relative loglikelihoods
        of it being on as supposed to off. Because this is a relative loglikelihood,
        we only need to take into account the following parameters of the model:
            - Only the ASVs in the target cluster of the interaction
            - Only the positively indicated interactions going into the
              target cluster.

        This is 1000&#39;s of times faster than `update` because we are operating on matrices
        that are MUCH smaller than in a full system. These matrices are also considered dense
        so we do all of our computations without sparse matrices.

        We permute the order that the indices are updated for more robust mixing.
        &#39;&#39;&#39;
        start = time.time()
        if self.sample_iter &lt; self.delay:
            self._strr = &#39;{}\ntotal time: {}&#39;.format(
                self.interactions.get_indicators(), time.time()-start)
            return
        if self.sample_iter % self.run_every_n_iterations != 0:
            return

        idxs = npr.permutation(self.interactions.size)

        self.make_rel_params()
        for idx in idxs:
            self.update_single_idx_fast(idx=idx)

        self.update_cnt_indicators()
        # Since slicing is literally so slow, it is faster to build than just slicing M
        self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
            build=True, build_for_neg_ind=False)
        iii = self.interactions.get_indicators()
        n_on = np.sum(iii)
        self._strr = &#39;{}\ntotal time: {}, n_interactions: {}/{}, {:.2f}&#39;.format(
            iii, time.time()-start, n_on, len(iii), n_on/len(iii))

    def calculate_marginal_loglikelihood(self, idx, val):
        &#39;&#39;&#39;Calculate the likelihood of interaction `idx` with the value `val`
        &#39;&#39;&#39;
        # Build and initialize
        self.interactions.iloc(idx).indicator = val
        self.update_cnt_indicators()
        self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build()

        lhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
        if self._there_are_perturbations:
            rhs = [STRNAMES.PERT_VALUE, STRNAMES.CLUSTER_INTERACTION_VALUE]
        else:
            rhs = [STRNAMES.CLUSTER_INTERACTION_VALUE]

        y = self.G.data.construct_lhs(lhs, 
            kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;: False}})
        X = self.G.data.construct_rhs(rhs, toarray=True)

        if X.shape[1] == 0:
            return {
            &#39;ret&#39;: 0,
            &#39;beta_logdet&#39;: 0,
            &#39;priorvar_logdet&#39;: 0,
            &#39;bEb&#39;: 0,
            &#39;bEbprior&#39;: 0}

        process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(cov=False, sparse=False)
        prior_prec = build_prior_covariance(G=self.G, cov=False, order=rhs, sparse=False)
        prior_var = build_prior_covariance(G=self.G, cov=True, order=rhs, sparse=False)
        prior_mean = build_prior_mean(G=self.G, order=rhs, shape=(-1,1))


        # Calculate the posterior
        beta_prec = X.T @ process_prec @ X + prior_prec
        beta_cov = pinv(beta_prec, self)
        beta_mean = beta_cov @ ( X.T @ process_prec @ y + prior_prec @ prior_mean )
        
        beta_mean = np.asarray(beta_mean).reshape(-1,1)

        # Perform the marginalization
        try:
            beta_logdet = log_det(beta_cov, self)
        except:
            logging.critical(&#39;Crashed in log_det&#39;)
            logging.critical(&#39;beta_cov:\n{}&#39;.format(beta_cov))
            logging.critical(&#39;prior_prec\n{}&#39;.format(prior_prec))
            raise
        priorvar_logdet = log_det(prior_var, self)
        ll2 = 0.5 * (beta_logdet - priorvar_logdet)

        a = np.asarray(prior_mean.T @ prior_prec @ prior_mean)[0,0]
        b = np.asarray(beta_mean.T @ beta_prec @ beta_mean)[0,0]
        ll3 = -0.5 * (a  - b)

        return {
            &#39;ret&#39;: ll2+ll3,
            &#39;beta_logdet&#39;: beta_logdet,
            &#39;priorvar_logdet&#39;: priorvar_logdet,
            &#39;bEb&#39;: b,
            &#39;bEbprior&#39;: a}

    def update_single_idx_fast(self, idx):
        &#39;&#39;&#39;Calculate the relative log likelihood of changing the indicator of the
        interaction at index `idx`.

        This is about 20X faster than `update_single_idx_slow`.

        Parameters
        ----------
        idx : int
            This is the index of the interaction index we are sampling
        &#39;&#39;&#39;
        # Get the current interaction by the index
        self.curr_interaction = self.interactions.iloc(idx)
        start_sign = self.curr_interaction.indicator
        
        tcid = self.curr_interaction.target_cid
        self.curr_interaction.indicator = False
        self.col_idxs = np.asarray(
            self.interactions.get_arg_indicators(target_cid=tcid),
            dtype=int)

        if not start_sign:
            self.n_on_master += 1
            self.num_pos_indicators += 1
            self.num_neg_indicators -= 1

        d_on = self.calculate_relative_marginal_loglikelihood(idx=idx, val=True)

        self.n_on_master -= 1
        self.num_pos_indicators -= 1
        self.num_neg_indicators += 1
        d_off = self.calculate_relative_marginal_loglikelihood(idx=idx, val=False)

        ll_on = d_on + self.prior_ll_on
        ll_off = d_off + self.prior_ll_off

        dd = [ll_off, ll_on]

        # print(&#39;\nindicator&#39;, idx)
        # print(&#39;fast\n\ttotal: {}\n\tbeta_logdet_diff: {}\n\t&#39; \
        #     &#39;priorvar_logdet_diff: {}\n\tbEb_diff: {}\n\t&#39; \
        #     &#39;bEbprior_diff: {}\n\tn_on_when_off: {}&#39;.format(
        #         ll_on - ll_off,
        #         d_on[&#39;beta_logdet&#39;] - d_off[&#39;beta_logdet&#39;],
        #         d_on[&#39;priorvar_logdet&#39;] - d_off[&#39;priorvar_logdet&#39;],
        #         d_on[&#39;bEb&#39;] - d_off[&#39;bEb&#39;],
        #         d_on[&#39;bEbprior&#39;] - d_off[&#39;bEbprior&#39;],
        #         self.n_on_master))
        # print(&#39;log(prior_var)&#39;, np.log(self.prior_var_interaction))
        # self.update_single_idx_slow(idx)

        res = bool(sample_categorical_log(dd))
        if res:
            self.n_on_master += 1
            self.num_pos_indicators += 1
            self.num_neg_indicators -= 1
            self.curr_interaction.indicator = True

    def calculate_relative_marginal_loglikelihood(self, idx, val):
        &#39;&#39;&#39;Calculate the relative marginal log likelihood for the interaction index
        `idx` with the indicator `val`

        Parameters
        ----------
        idx : int
            This is the index of the interaction
        val : bool
            This is the value to calculate it as
        &#39;&#39;&#39;
        tcid = self.curr_interaction.target_cid

        y = self.ys[tcid]
        process_prec = self.process_precs[tcid]

        # Make X, prior mean, and prior_var
        if val:
            cols = np.append(self.col_idxs, idx)
        else:
            cols = self.col_idxs
        
        X = self.interactionXs[tcid][:, cols]
        prior_mean = np.full(len(cols), self.prior_mean_interaction)
        prior_prec_diag = np.full(len(cols), self.prior_prec_interaction)

        if self._there_are_perturbations:
            Xpert = self.perturbationsXs[tcid]
            X = np.hstack((X, Xpert))

            prior_mean = np.append(
                prior_mean,
                self.prior_mean_perturbations[tcid])
            
            prior_prec_diag = np.append(
                prior_prec_diag,
                self.prior_prec_perturbations[tcid])

        if X.shape[1] == 0:
            # return {
            #     &#39;ret&#39;: 0,
            #     &#39;beta_logdet&#39;: 0,
            #     &#39;priorvar_logdet&#39;: 0,
            #     &#39;bEb&#39;: 0,
            #     &#39;bEbprior&#39;: 0}
            return 0

        prior_prec = np.diag(prior_prec_diag)
        pm = (prior_prec_diag * prior_mean).reshape(-1,1)

        # Do the marginalization
        a = X.T * process_prec

        beta_prec = (a @ X) + prior_prec
        beta_cov = pinv(beta_prec, self)
        beta_mean = beta_cov @ ((a @ y) + pm )

        bEb = (beta_mean.T @ beta_prec @ beta_mean)[0,0]
        try:
            beta_logdet = log_det(beta_cov, self)
        except:
            logging.critical(&#39;Crashed in log_det&#39;)
            logging.critical(&#39;beta_cov:\n{}&#39;.format(beta_cov))
            logging.critical(&#39;prior_prec\n{}&#39;.format(prior_prec))

            logging.critical(&#39;here&#39;)
            print(&#39;y&#39;)
            print(y.shape)
            print(y)
            print(&#39;process_prec&#39;)
            print(process_prec.shape)
            print(&#39;X&#39;)
            print(X.shape)
            print(X)
            print(&#39;priors&#39;)
            print(prior_mean)
            print(prior_prec_diag)
            print(&#39;self-interactions&#39;)
            X = pl.toarray(self.G.data.design_matrices[STRNAMES.SELF_INTERACTION_VALUE].matrix)
            print(X.shape)
            print(np.any(np.isnan(X)))
            print(&#39;growth&#39;)
            X = pl.toarray(self.G.data.design_matrices[STRNAMES.GROWTH_VALUE].matrix_without_perturbations)
            print(X.shape)
            print(np.any(np.isnan(X)))
            print(&#39;orig y&#39;)
            y = self.G.data.lhs.vector
            print(y.shape)
            print(np.any(np.isnan(y)))
            print(&#39;cluster-interactions&#39;)
            X = pl.toarray(self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].matrix)
            print(X.shape)
            print(np.any(np.isnan(X)))

            n_on = 0
            for row in range(X.shape[0]):
                n_on += np.any(np.isnan(X[row]))

            print(&#39;nans on {}/{} rows&#39;.format(n_on, X.shape[0]))
                    

            raise
        
        if val:
            bEbprior = (self.prior_mean_interaction**2)/self.prior_var_interaction
            priorvar_logdet = self.priorvar_logdet
        else:
            bEbprior = 0
            priorvar_logdet = 0

        ll2 = 0.5 * (beta_logdet - priorvar_logdet)
        ll3 = 0.5 * (bEb - bEbprior)

        # return {
        #     &#39;ret&#39;: ll2+ll3,
        #     &#39;beta_logdet&#39;: beta_logdet,
        #     &#39;priorvar_logdet&#39;: priorvar_logdet,
        #     &#39;bEb&#39;: bEb,
        #     &#39;bEbprior&#39;: bEbprior}
        return ll2 + ll3
            
    def kill(self):
        pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.calculate_marginal_loglikelihood"><code class="name flex">
<span>def <span class="ident">calculate_marginal_loglikelihood</span></span>(<span>self, idx, val)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the likelihood of interaction <code>idx</code> with the value <code>val</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_marginal_loglikelihood(self, idx, val):
    &#39;&#39;&#39;Calculate the likelihood of interaction `idx` with the value `val`
    &#39;&#39;&#39;
    # Build and initialize
    self.interactions.iloc(idx).indicator = val
    self.update_cnt_indicators()
    self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build()

    lhs = [STRNAMES.GROWTH_VALUE, STRNAMES.SELF_INTERACTION_VALUE]
    if self._there_are_perturbations:
        rhs = [STRNAMES.PERT_VALUE, STRNAMES.CLUSTER_INTERACTION_VALUE]
    else:
        rhs = [STRNAMES.CLUSTER_INTERACTION_VALUE]

    y = self.G.data.construct_lhs(lhs, 
        kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;: False}})
    X = self.G.data.construct_rhs(rhs, toarray=True)

    if X.shape[1] == 0:
        return {
        &#39;ret&#39;: 0,
        &#39;beta_logdet&#39;: 0,
        &#39;priorvar_logdet&#39;: 0,
        &#39;bEb&#39;: 0,
        &#39;bEbprior&#39;: 0}

    process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(cov=False, sparse=False)
    prior_prec = build_prior_covariance(G=self.G, cov=False, order=rhs, sparse=False)
    prior_var = build_prior_covariance(G=self.G, cov=True, order=rhs, sparse=False)
    prior_mean = build_prior_mean(G=self.G, order=rhs, shape=(-1,1))


    # Calculate the posterior
    beta_prec = X.T @ process_prec @ X + prior_prec
    beta_cov = pinv(beta_prec, self)
    beta_mean = beta_cov @ ( X.T @ process_prec @ y + prior_prec @ prior_mean )
    
    beta_mean = np.asarray(beta_mean).reshape(-1,1)

    # Perform the marginalization
    try:
        beta_logdet = log_det(beta_cov, self)
    except:
        logging.critical(&#39;Crashed in log_det&#39;)
        logging.critical(&#39;beta_cov:\n{}&#39;.format(beta_cov))
        logging.critical(&#39;prior_prec\n{}&#39;.format(prior_prec))
        raise
    priorvar_logdet = log_det(prior_var, self)
    ll2 = 0.5 * (beta_logdet - priorvar_logdet)

    a = np.asarray(prior_mean.T @ prior_prec @ prior_mean)[0,0]
    b = np.asarray(beta_mean.T @ beta_prec @ beta_mean)[0,0]
    ll3 = -0.5 * (a  - b)

    return {
        &#39;ret&#39;: ll2+ll3,
        &#39;beta_logdet&#39;: beta_logdet,
        &#39;priorvar_logdet&#39;: priorvar_logdet,
        &#39;bEb&#39;: b,
        &#39;bEbprior&#39;: a}</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.calculate_relative_marginal_loglikelihood"><code class="name flex">
<span>def <span class="ident">calculate_relative_marginal_loglikelihood</span></span>(<span>self, idx, val)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the relative marginal log likelihood for the interaction index
<code>idx</code> with the indicator <code>val</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>This is the index of the interaction</dd>
<dt><strong><code>val</code></strong> :&ensp;<code>bool</code></dt>
<dd>This is the value to calculate it as</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_relative_marginal_loglikelihood(self, idx, val):
    &#39;&#39;&#39;Calculate the relative marginal log likelihood for the interaction index
    `idx` with the indicator `val`

    Parameters
    ----------
    idx : int
        This is the index of the interaction
    val : bool
        This is the value to calculate it as
    &#39;&#39;&#39;
    tcid = self.curr_interaction.target_cid

    y = self.ys[tcid]
    process_prec = self.process_precs[tcid]

    # Make X, prior mean, and prior_var
    if val:
        cols = np.append(self.col_idxs, idx)
    else:
        cols = self.col_idxs
    
    X = self.interactionXs[tcid][:, cols]
    prior_mean = np.full(len(cols), self.prior_mean_interaction)
    prior_prec_diag = np.full(len(cols), self.prior_prec_interaction)

    if self._there_are_perturbations:
        Xpert = self.perturbationsXs[tcid]
        X = np.hstack((X, Xpert))

        prior_mean = np.append(
            prior_mean,
            self.prior_mean_perturbations[tcid])
        
        prior_prec_diag = np.append(
            prior_prec_diag,
            self.prior_prec_perturbations[tcid])

    if X.shape[1] == 0:
        # return {
        #     &#39;ret&#39;: 0,
        #     &#39;beta_logdet&#39;: 0,
        #     &#39;priorvar_logdet&#39;: 0,
        #     &#39;bEb&#39;: 0,
        #     &#39;bEbprior&#39;: 0}
        return 0

    prior_prec = np.diag(prior_prec_diag)
    pm = (prior_prec_diag * prior_mean).reshape(-1,1)

    # Do the marginalization
    a = X.T * process_prec

    beta_prec = (a @ X) + prior_prec
    beta_cov = pinv(beta_prec, self)
    beta_mean = beta_cov @ ((a @ y) + pm )

    bEb = (beta_mean.T @ beta_prec @ beta_mean)[0,0]
    try:
        beta_logdet = log_det(beta_cov, self)
    except:
        logging.critical(&#39;Crashed in log_det&#39;)
        logging.critical(&#39;beta_cov:\n{}&#39;.format(beta_cov))
        logging.critical(&#39;prior_prec\n{}&#39;.format(prior_prec))

        logging.critical(&#39;here&#39;)
        print(&#39;y&#39;)
        print(y.shape)
        print(y)
        print(&#39;process_prec&#39;)
        print(process_prec.shape)
        print(&#39;X&#39;)
        print(X.shape)
        print(X)
        print(&#39;priors&#39;)
        print(prior_mean)
        print(prior_prec_diag)
        print(&#39;self-interactions&#39;)
        X = pl.toarray(self.G.data.design_matrices[STRNAMES.SELF_INTERACTION_VALUE].matrix)
        print(X.shape)
        print(np.any(np.isnan(X)))
        print(&#39;growth&#39;)
        X = pl.toarray(self.G.data.design_matrices[STRNAMES.GROWTH_VALUE].matrix_without_perturbations)
        print(X.shape)
        print(np.any(np.isnan(X)))
        print(&#39;orig y&#39;)
        y = self.G.data.lhs.vector
        print(y.shape)
        print(np.any(np.isnan(y)))
        print(&#39;cluster-interactions&#39;)
        X = pl.toarray(self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].matrix)
        print(X.shape)
        print(np.any(np.isnan(X)))

        n_on = 0
        for row in range(X.shape[0]):
            n_on += np.any(np.isnan(X[row]))

        print(&#39;nans on {}/{} rows&#39;.format(n_on, X.shape[0]))
                

        raise
    
    if val:
        bEbprior = (self.prior_mean_interaction**2)/self.prior_var_interaction
        priorvar_logdet = self.priorvar_logdet
    else:
        bEbprior = 0
        priorvar_logdet = 0

    ll2 = 0.5 * (beta_logdet - priorvar_logdet)
    ll3 = 0.5 * (bEb - bEbprior)

    # return {
    #     &#39;ret&#39;: ll2+ll3,
    #     &#39;beta_logdet&#39;: beta_logdet,
    #     &#39;priorvar_logdet&#39;: priorvar_logdet,
    #     &#39;bEb&#39;: bEb,
    #     &#39;bEbprior&#39;: bEbprior}
    return ll2 + ll3</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, delay=0, run_every_n_iterations=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Do nothing, the indicators are set in <code><a title="mdsine2.interactions.ClusterInteractionValue" href="#mdsine2.interactions.ClusterInteractionValue">ClusterInteractionValue</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>delay</code></strong> :&ensp;<code>int</code></dt>
<dd>How many iterations to delay starting to update the values</dd>
<dt><strong><code>run_every_n_iterations</code></strong> :&ensp;<code>int</code></dt>
<dd>Which iteration to run on</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, delay=0, run_every_n_iterations=1):
    &#39;&#39;&#39;Do nothing, the indicators are set in `ClusterInteractionValue`.

    Parameters
    ----------
    delay : int
        How many iterations to delay starting to update the values
    run_every_n_iterations : int
        Which iteration to run on
    &#39;&#39;&#39;
    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    if not pl.isint(run_every_n_iterations):
        raise TypeError(&#39;`run_every_n_iterations` ({}) must be an int&#39;.format(
            type(run_every_n_iterations)))
    if run_every_n_iterations &lt;= 0:
        raise ValueError(&#39;`run_every_n_iterations` ({}) must be &gt; 0&#39;.format(
            run_every_n_iterations))

    self.delay = delay
    self.run_every_n_iterations = run_every_n_iterations
    self._there_are_perturbations = self.G.perturbations is not None
    self.update_cnt_indicators()
    self.interactions = self.G[STRNAMES.INTERACTIONS_OBJ]
    self.n_asvs = len(self.G.data.asvs)

    # These are for the function `self._make_idx_for_clusters`
    self.ndts_bias = []
    self.n_replicates = self.G.data.n_replicates
    self.n_dts_for_replicate = self.G.data.n_dts_for_replicate
    self.total_dts = np.sum(self.n_dts_for_replicate)
    self.replicate_bias = np.zeros(self.n_replicates, dtype=int)
    for ridx in range(1, self.n_replicates):
        self.replicate_bias[ridx] = self.replicate_bias[ridx-1] + \
            self.n_asvs * self.n_dts_for_replicate[ridx - 1]
    for ridx in range(self.G.data.n_replicates):
        self.ndts_bias.append(
            np.arange(0, self.G.data.n_dts_for_replicate[ridx] * self.n_asvs, self.n_asvs))

    # Makes a dictionary that maps the asv index to the rows that it the ASV in
    self.oidx2rows = {}
    for oidx in range(self.n_asvs):
        idxs = np.zeros(self.total_dts, dtype=int)
        i = 0
        for ridx in range(self.n_replicates):
            temp = np.arange(0, self.n_dts_for_replicate[ridx] * self.n_asvs, self.n_asvs)
            temp = temp + oidx
            temp = temp + self.replicate_bias[ridx]
            l = len(temp)
            idxs[i:i+l] = temp
            i += l
        self.oidx2rows[oidx] = idxs</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.kill"><code class="name flex">
<span>def <span class="ident">kill</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kill(self):
    pass</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.make_rel_params"><code class="name flex">
<span>def <span class="ident">make_rel_params</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>We make the parameters needed to update the relative log-likelihod.
This function is called once at the beginning of the update.</p>
<h2 id="parameters-that-we-create-with-this-function">Parameters That We Create With This Function</h2>
<p>ys : dict (int -&gt; np.ndarray)
Maps the target cluster id to the observation matrix that it
corresponds to (only the ASVs in the target cluster). This
array already has the growth and self-interactions subtracted
out:
$
rac{log(x_{k+1}) - log(x_{k})}{dt} - a_{1,k} - a_{2,k}x_{k} $
process_precs : dict (int -&gt; np.ndarray)
Maps the target cluster id to the vector of the process precision
that corresponds to the target cluster (only the ASVs in the target
cluster). This is a 1D array that corresponds to the diagonal of what
would be the precision matrix.
interactionXs : dict (int -&gt; np.ndarray)
Maps the target cluster id to the matrix of the design matrix of the
interactions. Only includes the rows that correspond to the ASVs in the
target cluster. It includes every single column as if all of the indicators
are on. We only index out the columns when we are doing the marginalization.
prior_prec_interaction : float
Prior precision of the interaction value. We then use this
value to make the diagonal of the prior precision.
prior_var_interaction : float
Prior variance of the interaction value.
prior_mean_interaction : float
Prior mean of the interaction values. We use this value
to make the prior mean vector during the marginalization.
n_on_master : int
How many interactions are on at any one time. We adjust this
throughout the update depending on what interactions we turn off and
on.
prior_ll_on : float
Prior log likelihood of a positive interaction
prior_ll_off : float
Prior log likelihood of the negative interaction
priorvar_logdet_diff : float
This is the prior variance log determinant that we add when the indicator
is positive.</p>
<h2 id="parameters-created-if-there-are-perturbations">Parameters Created If There Are Perturbations</h2>
<p>perturbationsXs : dict (int -&gt; np.ndarray)
Maps the target cluster id to the design matrix that corresponds to
the on perturbations of the target clusters. This is preindexed in
both rows and columns
prior_prec_perturbations : dict (int -&gt; np.ndarray)
Maps the target cluster id to the diagonal of the prior precision
of the perturbations
prior_var_perturbations : dict (int -&gt; np.ndarray)
Maps the target cluster id to the diagonal of the prior variance
of the perturbations
prior_mean_perturbations : dict (int -&gt; np.ndarray)
Maps the target cluster id to the vector of the prior mean of the
perturbations</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_rel_params(self):
    &#39;&#39;&#39;We make the parameters needed to update the relative log-likelihod.
    This function is called once at the beginning of the update.

    Parameters that we create with this function
    --------------------------------------------
    ys : dict (int -&gt; np.ndarray)
        Maps the target cluster id to the observation matrix that it
        corresponds to (only the ASVs in the target cluster). This 
        array already has the growth and self-interactions subtracted
        out:
            $ \frac{log(x_{k+1}) - log(x_{k})}{dt} - a_{1,k} - a_{2,k}x_{k} $
    process_precs : dict (int -&gt; np.ndarray)
        Maps the target cluster id to the vector of the process precision
        that corresponds to the target cluster (only the ASVs in the target
        cluster). This is a 1D array that corresponds to the diagonal of what
        would be the precision matrix.
    interactionXs : dict (int -&gt; np.ndarray)
        Maps the target cluster id to the matrix of the design matrix of the
        interactions. Only includes the rows that correspond to the ASVs in the
        target cluster. It includes every single column as if all of the indicators
        are on. We only index out the columns when we are doing the marginalization.
    prior_prec_interaction : float
        Prior precision of the interaction value. We then use this
        value to make the diagonal of the prior precision.
    prior_var_interaction : float
        Prior variance of the interaction value.
    prior_mean_interaction : float
        Prior mean of the interaction values. We use this value
        to make the prior mean vector during the marginalization.
    n_on_master : int
        How many interactions are on at any one time. We adjust this
        throughout the update depending on what interactions we turn off and
        on.
    prior_ll_on : float
        Prior log likelihood of a positive interaction
    prior_ll_off : float
        Prior log likelihood of the negative interaction
    priorvar_logdet_diff : float
        This is the prior variance log determinant that we add when the indicator
        is positive.

    Parameters created if there are perturbations
    ---------------------------------------------
    perturbationsXs : dict (int -&gt; np.ndarray)
        Maps the target cluster id to the design matrix that corresponds to 
        the on perturbations of the target clusters. This is preindexed in
        both rows and columns
    prior_prec_perturbations : dict (int -&gt; np.ndarray)
        Maps the target cluster id to the diagonal of the prior precision
        of the perturbations
    prior_var_perturbations : dict (int -&gt; np.ndarray)
        Maps the target cluster id to the diagonal of the prior variance 
        of the perturbations
    prior_mean_perturbations : dict (int -&gt; np.ndarray)
        Maps the target cluster id to the vector of the prior mean of the
        perturbations
    &#39;&#39;&#39;
    # Get the row indices for each cluster
    row_idxs = self._make_idx_vector_for_clusters()

    # Create ys
    self.ys = {}
    y = self.G.data.construct_lhs(keys=[
        STRNAMES.SELF_INTERACTION_VALUE, STRNAMES.GROWTH_VALUE],
        kwargs_dict={STRNAMES.GROWTH_VALUE:{&#39;with_perturbations&#39;: False}})
    for tcid in self.clustering.order:
        self.ys[tcid] = y[row_idxs[tcid], :]

    # Create process_precs
    self.process_precs = {}
    process_prec_diag = self.G[STRNAMES.PROCESSVAR].prec
    for tcid in self.clustering.order:
        self.process_precs[tcid] = process_prec_diag[row_idxs[tcid]]

    # Make interactionXs
    self.interactionXs = {}
    self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
        build=True, build_for_neg_ind=True)
    XM_master = self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].toarray()
    for tcid in self.clustering.order:
        self.interactionXs[tcid] = XM_master[row_idxs[tcid], :]

    # Make prior parameters
    self.prior_var_interaction = self.G[STRNAMES.PRIOR_VAR_INTERACTIONS].value
    self.prior_prec_interaction = 1/self.prior_var_interaction
    self.prior_mean_interaction = self.G[STRNAMES.PRIOR_MEAN_INTERACTIONS].value
    self.prior_ll_on = np.log(self.prior.value)
    self.prior_ll_off = np.log(1 - self.prior.value)
    self.n_on_master = self.interactions.num_pos_indicators()

    # Make priorvar_logdet
    self.priorvar_logdet = np.log(self.prior_var_interaction)

    if self._there_are_perturbations:
        XMpert_master = self.G.data.design_matrices[STRNAMES.PERT_VALUE].toarray()

        # Make perturbationsXs
        self.perturbationsXs = {}
        for tcid in self.clustering.order:
            rows = row_idxs[tcid]
            cols = []
            i = 0
            for perturbation in self.G.perturbations:
                for cid in perturbation.indicator.value:
                    if perturbation.indicator.value[cid]:
                        if cid == tcid:
                            cols.append(i)
                        i += 1
            cols = np.asarray(cols, dtype=int)

            self.perturbationsXs[tcid] = pl.util.fast_index(M=XMpert_master,
                rows=rows, cols=cols)

        # Make prior perturbation parameters
        self.prior_mean_perturbations = {}
        self.prior_var_perturbations = {}
        self.prior_prec_perturbations = {}
        for tcid in self.clustering.order:
            mean = []
            var = []
            for perturbation in self.G.perturbations:
                if perturbation.indicator.value[tcid]:
                    # This is on, get the parameters
                    mean.append(perturbation.magnitude.prior.mean.value)
                    var.append(perturbation.magnitude.prior.var.value)
            self.prior_mean_perturbations[tcid] = np.asarray(mean)
            self.prior_var_perturbations[tcid] = np.asarray(var)
            self.prior_prec_perturbations[tcid] = 1/self.prior_var_perturbations[tcid]

        # Make priorvar_det_perturbations
        self.priorvar_det_perturbations = 0
        for perturbation in self.G.perturbations:
            self.priorvar_det_perturbations += \
                perturbation.indicator.num_on_clusters() * \
                perturbation.magnitude.prior.var.value</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.update_cnt_indicators"><code class="name flex">
<span>def <span class="ident">update_cnt_indicators</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_cnt_indicators(self):
    self.num_pos_indicators = self.G[STRNAMES.INTERACTIONS_OBJ].num_pos_indicators()
    self.num_neg_indicators = self.G[STRNAMES.INTERACTIONS_OBJ].num_neg_indicators()</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.update_direct"><code class="name flex">
<span>def <span class="ident">update_direct</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Permute the order that the indices that are updated.</p>
<p>Build the full master interaction matrix that we can then slice</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_direct(self):
    &#39;&#39;&#39;Permute the order that the indices that are updated.

    Build the full master interaction matrix that we can then slice
    &#39;&#39;&#39;
    start = time.time()
    if self.sample_iter &lt; self.delay:
        # for interaction in self.interactions:
        #     interaction.indicator=False
        self._strr = &#39;{}\ntotal time: {}&#39;.format(
            self.interactions.get_indicators(), time.time()-start)
        return
    if self.sample_iter % self.run_every_n_iterations != 0:
        return

    # keys = npr.permutation(self.interactions.key_pairs())
    idxs = npr.permutation(self.interactions.size)
    for idx in idxs:
        # print(&#39;indicator {}/{}&#39;.format(iii, len(keys)))
        self.update_single_idx_slow(idx=idx)

    self.update_cnt_indicators()
    # Since slicing is literally so slow, it is faster to build than just slicing M
    self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
        build=True, build_for_neg_ind=False)
    iii = self.interactions.get_indicators()
    n_on = np.sum(iii)
    self._strr = &#39;{}\ntotal time: {}, n_interactions: {}/{}, {:.2f}&#39;.format(
        iii, time.time()-start, n_on, len(iii), n_on/len(iii))</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.update_relative"><code class="name flex">
<span>def <span class="ident">update_relative</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the indicators variables by calculating the relative loglikelihoods
of it being on as supposed to off. Because this is a relative loglikelihood,
we only need to take into account the following parameters of the model:
- Only the ASVs in the target cluster of the interaction
- Only the positively indicated interactions going into the
target cluster.</p>
<p>This is 1000's of times faster than <code>update</code> because we are operating on matrices
that are MUCH smaller than in a full system. These matrices are also considered dense
so we do all of our computations without sparse matrices.</p>
<p>We permute the order that the indices are updated for more robust mixing.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_relative(self):
    &#39;&#39;&#39;Update the indicators variables by calculating the relative loglikelihoods
    of it being on as supposed to off. Because this is a relative loglikelihood,
    we only need to take into account the following parameters of the model:
        - Only the ASVs in the target cluster of the interaction
        - Only the positively indicated interactions going into the
          target cluster.

    This is 1000&#39;s of times faster than `update` because we are operating on matrices
    that are MUCH smaller than in a full system. These matrices are also considered dense
    so we do all of our computations without sparse matrices.

    We permute the order that the indices are updated for more robust mixing.
    &#39;&#39;&#39;
    start = time.time()
    if self.sample_iter &lt; self.delay:
        self._strr = &#39;{}\ntotal time: {}&#39;.format(
            self.interactions.get_indicators(), time.time()-start)
        return
    if self.sample_iter % self.run_every_n_iterations != 0:
        return

    idxs = npr.permutation(self.interactions.size)

    self.make_rel_params()
    for idx in idxs:
        self.update_single_idx_fast(idx=idx)

    self.update_cnt_indicators()
    # Since slicing is literally so slow, it is faster to build than just slicing M
    self.G.data.design_matrices[STRNAMES.CLUSTER_INTERACTION_VALUE].M.build(
        build=True, build_for_neg_ind=False)
    iii = self.interactions.get_indicators()
    n_on = np.sum(iii)
    self._strr = &#39;{}\ntotal time: {}, n_interactions: {}/{}, {:.2f}&#39;.format(
        iii, time.time()-start, n_on, len(iii), n_on/len(iii))</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.update_single_idx_fast"><code class="name flex">
<span>def <span class="ident">update_single_idx_fast</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the relative log likelihood of changing the indicator of the
interaction at index <code>idx</code>.</p>
<p>This is about 20X faster than <code>update_single_idx_slow</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>This is the index of the interaction index we are sampling</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_single_idx_fast(self, idx):
    &#39;&#39;&#39;Calculate the relative log likelihood of changing the indicator of the
    interaction at index `idx`.

    This is about 20X faster than `update_single_idx_slow`.

    Parameters
    ----------
    idx : int
        This is the index of the interaction index we are sampling
    &#39;&#39;&#39;
    # Get the current interaction by the index
    self.curr_interaction = self.interactions.iloc(idx)
    start_sign = self.curr_interaction.indicator
    
    tcid = self.curr_interaction.target_cid
    self.curr_interaction.indicator = False
    self.col_idxs = np.asarray(
        self.interactions.get_arg_indicators(target_cid=tcid),
        dtype=int)

    if not start_sign:
        self.n_on_master += 1
        self.num_pos_indicators += 1
        self.num_neg_indicators -= 1

    d_on = self.calculate_relative_marginal_loglikelihood(idx=idx, val=True)

    self.n_on_master -= 1
    self.num_pos_indicators -= 1
    self.num_neg_indicators += 1
    d_off = self.calculate_relative_marginal_loglikelihood(idx=idx, val=False)

    ll_on = d_on + self.prior_ll_on
    ll_off = d_off + self.prior_ll_off

    dd = [ll_off, ll_on]

    # print(&#39;\nindicator&#39;, idx)
    # print(&#39;fast\n\ttotal: {}\n\tbeta_logdet_diff: {}\n\t&#39; \
    #     &#39;priorvar_logdet_diff: {}\n\tbEb_diff: {}\n\t&#39; \
    #     &#39;bEbprior_diff: {}\n\tn_on_when_off: {}&#39;.format(
    #         ll_on - ll_off,
    #         d_on[&#39;beta_logdet&#39;] - d_off[&#39;beta_logdet&#39;],
    #         d_on[&#39;priorvar_logdet&#39;] - d_off[&#39;priorvar_logdet&#39;],
    #         d_on[&#39;bEb&#39;] - d_off[&#39;bEb&#39;],
    #         d_on[&#39;bEbprior&#39;] - d_off[&#39;bEbprior&#39;],
    #         self.n_on_master))
    # print(&#39;log(prior_var)&#39;, np.log(self.prior_var_interaction))
    # self.update_single_idx_slow(idx)

    res = bool(sample_categorical_log(dd))
    if res:
        self.n_on_master += 1
        self.num_pos_indicators += 1
        self.num_neg_indicators -= 1
        self.curr_interaction.indicator = True</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionIndicators.update_single_idx_slow"><code class="name flex">
<span>def <span class="ident">update_single_idx_slow</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the likelihood for interaction <code>idx</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>This is the index of the interaction we are updating</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_single_idx_slow(self, idx):
    &#39;&#39;&#39;Update the likelihood for interaction `idx`

    Parameters
    ----------
    idx : int
        This is the index of the interaction we are updating
    &#39;&#39;&#39;
    prior_ll_on = np.log(self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].value)
    prior_ll_off = np.log(1 - self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].value)

    d_on = self.calculate_marginal_loglikelihood(idx=idx, val=True)
    d_off = self.calculate_marginal_loglikelihood(idx=idx, val=False)

    ll_on = d_on[&#39;ret&#39;] + prior_ll_on
    ll_off = d_off[&#39;ret&#39;] + prior_ll_off

    # print(&#39;slow\n\ttotal: {}\n\tbeta_logdet_diff: {}\n\t&#39; \
    #     &#39;priorvar_logdet_diff: {}\n\tbEb_diff: {}\n\t&#39; \
    #     &#39;bEbprior_diff: {}\n\tn_on_when_off: {}&#39;.format(
    #         ll_on - ll_off,
    #         d_on[&#39;beta_logdet&#39;] - d_off[&#39;beta_logdet&#39;],
    #         d_on[&#39;priorvar_logdet&#39;] - d_off[&#39;priorvar_logdet&#39;],
    #         d_on[&#39;bEb&#39;] - d_off[&#39;bEb&#39;],
    #         d_on[&#39;bEbprior&#39;] - d_off[&#39;bEbprior&#39;],
    #         self.interactions.num_pos_indicators()))

    dd = [ll_off, ll_on]

    res = bool(sample_categorical_log(dd))
    self.interactions.iloc(idx).indicator = res
    self.update_cnt_indicators()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.Variable.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Variable.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionValue"><code class="flex name class">
<span>class <span class="ident">ClusterInteractionValue</span></span>
<span>(</span><span>prior, clustering, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Interactions of Lotka-Voltera</p>
<p>Since we initialize the interactions object in the <code>initialize</code> function,
make sure that you have initialized the prior of the values of the interactions
and of the indicators of the interactions before you call the initialization of
this class</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClusterInteractionValue(pl.variables.MVN):
    &#39;&#39;&#39;Interactions of Lotka-Voltera

    Since we initialize the interactions object in the `initialize` function,
    make sure that you have initialized the prior of the values of the interactions
    and of the indicators of the interactions before you call the initialization of
    this class
    &#39;&#39;&#39;
    def __init__(self, prior, clustering, **kwargs):
        kwargs[&#39;name&#39;] = STRNAMES.CLUSTER_INTERACTION_VALUE
        pl.variables.MVN.__init__(self, dtype=float, **kwargs)
        self.set_value_shape(shape=(len(self.G.data.asvs),len(self.G.data.asvs)))
        self.add_prior(prior)
        self.clustering = clustering
        self.obj = pl.contrib.Interactions(
            clustering=self.clustering,
            use_indicators=True,
            name=STRNAMES.INTERACTIONS_OBJ, G=self.G,
            signal_when_clusters_change=False)
        self._strr = &#39;None&#39;

    def __str__(self):
        return self._strr

    def __len__(self):
        # Return the number of on interactions
        return self.obj.num_pos_indicators()

    def set_values(self, *args, **kwargs):
        &#39;&#39;&#39;Set the values from an array
        &#39;&#39;&#39;
        self.obj.set_values(*args, **kwargs)

    def initialize(self, value_option, hyperparam_option=None, value=None,
        indicators=None, delay=0):
        &#39;&#39;&#39;Initialize the interactions object.

        Parameters
        ----------
        value_option : str
            This is how to initialize the values
            Options:
                &#39;manual&#39;
                    Set the values of the interactions manually. `value` and `indicators`
                    must also be specified. We assume the values are only set for when
                    `indicators` is True, and that the order of the `indicators` and `values`
                    correspond to how we iterate over the interactions
                    Example
                        3 Clusters
                        indicators = [True, False, False, True, False, True]
                        value = [0.2, 0.8, -0.35]
                &#39;all-off&#39;, &#39;auto&#39;
                    Set all of the interactions and the indicators to 0
                &#39;all-on&#39;
                    Set all of the indicators to on and all the values to 0
        delay : int
            How many MCMC iterations to delay starting to update
        See also
        --------
        `pylab.cluster.Interactions.set_values`
        &#39;&#39;&#39;
        self.obj.set_signal_when_clusters_change(True)
        self.G[STRNAMES.INTERACTIONS_OBJ].value_initializer = self.prior.sample
        self.G[STRNAMES.INTERACTIONS_OBJ].indicator_initializer = self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].prior.sample

        self._there_are_perturbations = self.G.perturbations is not None

        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option in [&#39;auto&#39;, &#39;all-off&#39;]:
            for interaction in self.obj:
                interaction.value = 0
                interaction.indicator = False
        elif value_option == &#39;all-on&#39;:
            for interaction in self.obj:
                interaction.value = 0
                interaction.indicator = True
        elif value_option == &#39;manual&#39;:
            if not np.all(pl.itercheck([value, indicators], pl.isarray)):
                raise TypeError(&#39;`value` ({}) and `indicators` ({}) must be arrays&#39;.format(
                    type(value), type(indicators)))
            if len(value) != np.sum(indicators):
                raise ValueError(&#39;Length of `value` ({}) must equal the number of positive &#39; \
                    &#39;values in `indicators` ({})&#39;.format(len(value), np.sum(indicators)))
            if len(indicators) != self.obj.size:
                raise ValueError(&#39;The length of `indicators` ({}) must be the same as the &#39; \
                    &#39;number of possible interactions ({})&#39;.format(len(indicators), self.obj.size))
            ii = 0
            for i,interaction in enumerate(self.obj):
                interaction.indicator = indicators[i]
                if interaction.indicator:
                    interaction.value = value[ii]
                    ii += 1
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

        self._strr = str(self.obj.get_values(use_indicators=True))
        self.value = self.obj.get_values(use_indicators=True)

    def update(self):
        &#39;&#39;&#39;Update the values (where the indicators are positive) using a multivariate normal
        distribution - call this from regress coeff if you want to update the interactions
        conditional on all the other parameters.
        &#39;&#39;&#39;
        if self.obj.sample_iter &lt; self.delay:
            return
        if self.obj.num_pos_indicators() == 0:
            # logging.info(&#39;No positive indicators, skipping&#39;)
            self._strr = &#39;[]&#39;
            return

        rhs = [
            STRNAMES.CLUSTER_INTERACTION_VALUE]
        lhs = [
            STRNAMES.GROWTH_VALUE,
            STRNAMES.SELF_INTERACTION_VALUE]
        X = self.G.data.construct_rhs(keys=rhs)
        y = self.G.data.construct_lhs(keys=lhs,
            kwargs_dict={STRNAMES.GROWTH_VALUE:{
                &#39;with_perturbations&#39;:self._there_are_perturbations}})
        process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
            cov=False, sparse=True)
        prior_prec = build_prior_covariance(G=self.G, cov=False,
            order=rhs, sparse=True)

        pm = prior_prec @ (self.prior.mean.value * np.ones(prior_prec.shape[0]).reshape(-1,1))

        prec = X.T @ process_prec @ X + prior_prec
        cov = pinv(prec, self)
        mean = (cov @ (X.T @ process_prec.dot(y) + pm)).ravel()

        # print(np.hstack((y, self.G.data.lhs.vector.reshape(-1,1))))
        # for perturbation in self.G.perturbations:
        #     print()
        #     print(perturbation.magnitude.cluster_array())
        #     print(perturbation.indicator.cluster_array())

        self.mean.value = mean
        self.cov.value = cov
        value = self.sample()
        self.obj.set_values(arr=value, use_indicators=True)
        self.update_str()

        if np.any(np.isnan(self.value)):
            logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
            logging.critical(&#39;nan in cov: {}&#39;.format(np.any(np.isnan(self.cov.value))))
            logging.critical(&#39;value: {}&#39;.format(self.value))
            raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))

    def update_str(self):
        self._strr = str(self.obj.get_values(use_indicators=True))

    def set_trace(self):
        self.obj.set_trace()

    def add_trace(self):
        self.obj.add_trace()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.MVN" href="pylab/variables.html#mdsine2.pylab.variables.MVN">MVN</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.interactions.ClusterInteractionValue.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, value_option, hyperparam_option=None, value=None, indicators=None, delay=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the interactions object.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>value_option</code></strong> :&ensp;<code>str</code></dt>
<dd>This is how to initialize the values
Options:
'manual'
Set the values of the interactions manually. <code>value</code> and <code>indicators</code>
must also be specified. We assume the values are only set for when
<code>indicators</code> is True, and that the order of the <code>indicators</code> and <code>values</code>
correspond to how we iterate over the interactions
Example
3 Clusters
indicators = [True, False, False, True, False, True]
value = [0.2, 0.8, -0.35]
'all-off', 'auto'
Set all of the interactions and the indicators to 0
'all-on'
Set all of the indicators to on and all the values to 0</dd>
<dt><strong><code>delay</code></strong> :&ensp;<code>int</code></dt>
<dd>How many MCMC iterations to delay starting to update</dd>
</dl>
<h2 id="see-also">See Also</h2>
<p><code>pylab.cluster.Interactions.set_values</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, value_option, hyperparam_option=None, value=None,
    indicators=None, delay=0):
    &#39;&#39;&#39;Initialize the interactions object.

    Parameters
    ----------
    value_option : str
        This is how to initialize the values
        Options:
            &#39;manual&#39;
                Set the values of the interactions manually. `value` and `indicators`
                must also be specified. We assume the values are only set for when
                `indicators` is True, and that the order of the `indicators` and `values`
                correspond to how we iterate over the interactions
                Example
                    3 Clusters
                    indicators = [True, False, False, True, False, True]
                    value = [0.2, 0.8, -0.35]
            &#39;all-off&#39;, &#39;auto&#39;
                Set all of the interactions and the indicators to 0
            &#39;all-on&#39;
                Set all of the indicators to on and all the values to 0
    delay : int
        How many MCMC iterations to delay starting to update
    See also
    --------
    `pylab.cluster.Interactions.set_values`
    &#39;&#39;&#39;
    self.obj.set_signal_when_clusters_change(True)
    self.G[STRNAMES.INTERACTIONS_OBJ].value_initializer = self.prior.sample
    self.G[STRNAMES.INTERACTIONS_OBJ].indicator_initializer = self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR_PROB].prior.sample

    self._there_are_perturbations = self.G.perturbations is not None

    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    self.delay = delay

    if not pl.isstr(value_option):
        raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
    if value_option in [&#39;auto&#39;, &#39;all-off&#39;]:
        for interaction in self.obj:
            interaction.value = 0
            interaction.indicator = False
    elif value_option == &#39;all-on&#39;:
        for interaction in self.obj:
            interaction.value = 0
            interaction.indicator = True
    elif value_option == &#39;manual&#39;:
        if not np.all(pl.itercheck([value, indicators], pl.isarray)):
            raise TypeError(&#39;`value` ({}) and `indicators` ({}) must be arrays&#39;.format(
                type(value), type(indicators)))
        if len(value) != np.sum(indicators):
            raise ValueError(&#39;Length of `value` ({}) must equal the number of positive &#39; \
                &#39;values in `indicators` ({})&#39;.format(len(value), np.sum(indicators)))
        if len(indicators) != self.obj.size:
            raise ValueError(&#39;The length of `indicators` ({}) must be the same as the &#39; \
                &#39;number of possible interactions ({})&#39;.format(len(indicators), self.obj.size))
        ii = 0
        for i,interaction in enumerate(self.obj):
            interaction.indicator = indicators[i]
            if interaction.indicator:
                interaction.value = value[ii]
                ii += 1
    else:
        raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

    self._strr = str(self.obj.get_values(use_indicators=True))
    self.value = self.obj.get_values(use_indicators=True)</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionValue.set_values"><code class="name flex">
<span>def <span class="ident">set_values</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the values from an array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_values(self, *args, **kwargs):
    &#39;&#39;&#39;Set the values from an array
    &#39;&#39;&#39;
    self.obj.set_values(*args, **kwargs)</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionValue.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the values (where the indicators are positive) using a multivariate normal
distribution - call this from regress coeff if you want to update the interactions
conditional on all the other parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#39;&#39;&#39;Update the values (where the indicators are positive) using a multivariate normal
    distribution - call this from regress coeff if you want to update the interactions
    conditional on all the other parameters.
    &#39;&#39;&#39;
    if self.obj.sample_iter &lt; self.delay:
        return
    if self.obj.num_pos_indicators() == 0:
        # logging.info(&#39;No positive indicators, skipping&#39;)
        self._strr = &#39;[]&#39;
        return

    rhs = [
        STRNAMES.CLUSTER_INTERACTION_VALUE]
    lhs = [
        STRNAMES.GROWTH_VALUE,
        STRNAMES.SELF_INTERACTION_VALUE]
    X = self.G.data.construct_rhs(keys=rhs)
    y = self.G.data.construct_lhs(keys=lhs,
        kwargs_dict={STRNAMES.GROWTH_VALUE:{
            &#39;with_perturbations&#39;:self._there_are_perturbations}})
    process_prec = self.G[STRNAMES.PROCESSVAR].build_matrix(
        cov=False, sparse=True)
    prior_prec = build_prior_covariance(G=self.G, cov=False,
        order=rhs, sparse=True)

    pm = prior_prec @ (self.prior.mean.value * np.ones(prior_prec.shape[0]).reshape(-1,1))

    prec = X.T @ process_prec @ X + prior_prec
    cov = pinv(prec, self)
    mean = (cov @ (X.T @ process_prec.dot(y) + pm)).ravel()

    # print(np.hstack((y, self.G.data.lhs.vector.reshape(-1,1))))
    # for perturbation in self.G.perturbations:
    #     print()
    #     print(perturbation.magnitude.cluster_array())
    #     print(perturbation.indicator.cluster_array())

    self.mean.value = mean
    self.cov.value = cov
    value = self.sample()
    self.obj.set_values(arr=value, use_indicators=True)
    self.update_str()

    if np.any(np.isnan(self.value)):
        logging.critical(&#39;mean: {}&#39;.format(self.mean.value))
        logging.critical(&#39;nan in cov: {}&#39;.format(np.any(np.isnan(self.cov.value))))
        logging.critical(&#39;value: {}&#39;.format(self.value))
        raise ValueError(&#39;`Values in {} are nan: {}&#39;.format(self.name, self.value))</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.ClusterInteractionValue.update_str"><code class="name flex">
<span>def <span class="ident">update_str</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_str(self):
    self._strr = str(self.obj.get_values(use_indicators=True))</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.MVN" href="pylab/variables.html#mdsine2.pylab.variables.MVN">MVN</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.MVN.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.sample" href="pylab/variables.html#mdsine2.pylab.variables.MVN.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.MVN.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.interactions.PriorMeanInteractions"><code class="flex name class">
<span>class <span class="ident">PriorMeanInteractions</span></span>
<span>(</span><span>prior, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the posterior mean for the interactions</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PriorMeanInteractions(pl.variables.Normal):
    &#39;&#39;&#39;This is the posterior mean for the interactions
    &#39;&#39;&#39;

    def __init__(self, prior, **kwargs):
        kwargs[&#39;name&#39;] = STRNAMES.PRIOR_MEAN_INTERACTIONS
        pl.variables.Normal.__init__(self, mean=None, var=None, dtype=float, **kwargs)
        self.add_prior(prior)

    def __str__(self):
        # If this fails, it is because we are dividing by 0 sampler_iter
        # If which case we just return the value 
        try:
            s = &#39;Value: {}, Acceptance rate: {}&#39;.format(
                self.value, np.mean(self.acceptances[
                    np.max([self.sample_iter-50, 0]):self.sample_iter]))
        except:
            s = str(self.value)
        return s

    def initialize(self, value_option, mean_option, var_option, value=None, 
        mean=None, var=None, delay=0):
        &#39;&#39;&#39;Initialize the hyperparameters

        Parameters
        ----------
        value_option : str
            How to set the value. Options:
                &#39;zero&#39;
                    Set to zero
                &#39;prior-mean&#39;, &#39;auto&#39;
                    Set to the mean of the prior
                &#39;manual&#39;
                    Specify with the `value` parameter
        mean_option : str
            How to set the mean of the prior
                &#39;zero&#39;, &#39;auto&#39;
                    Set to zero
                &#39;manual&#39;
                    Set with the `mean` parameter
        var_option : str
            &#39;same-as-aii&#39;, &#39;auto&#39;
                Set as the same variance as the self-interactions
            &#39;manual&#39;
                Set with the `var` parameter
        value, mean, var : float
            These are only necessary if we specify manual for any of the other 
            options
        delay : int
            How much to delay the start of the update during inference
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        # Set the mean
        if not pl.isstr(mean_option):
            raise TypeError(&#39;`mean_option` ({}) must be a str&#39;.format(type(mean_option)))
        if mean_option == &#39;manual&#39;:
            if not pl.isnumeric(mean):
                raise TypeError(&#39;`mean` ({}) must be a numeric&#39;.format(type(mean)))
        elif mean_option in [&#39;zero&#39;, &#39;auto&#39;]:
            mean = 0
        else:
            raise ValueError(&#39;`mean_option` ({}) not recognized&#39;.format(mean_option))
        self.prior.mean.override_value(mean)

        # Set the variance
        if not pl.isstr(var_option):
            raise TypeError(&#39;`var_option` ({}) must be a str&#39;.format(type(var_option)))
        if var_option == &#39;manual&#39;:
            if not pl.isnumeric(var):
                raise TypeError(&#39;`var` ({}) must be a numeric&#39;.format(type(var)))
            if var &lt;= 0:
                raise ValueError(&#39;`var` ({}) must be positive&#39;.format(var))
        elif var_option in [&#39;same-as-aii&#39;, &#39;auto&#39;]:
            var = self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].value
        else:
            raise ValueError(&#39;`var_option` ({}) not recognized&#39;.format(var_option))
        self.prior.var.override_value(var)

        # Set the value
        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isnumeric(value):
                raise TypeError(&#39;`value` ({}) must be a numeric&#39;.format(type(value)))
        elif value_option in [&#39;prior-mean&#39;, &#39;auto&#39;]:
            value = self.prior.mean.value
        elif value_option == &#39;zero&#39;:
            value = 0
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
        self.value = value

    def update(self):
        &#39;&#39;&#39;Update using Gibbs sampling
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return

        if self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_pos_indicators == 0:
            # sample from the prior
            self.value = self.prior.sample()
            return

        x = self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].value
        prec = 1/self.G[STRNAMES.PRIOR_VAR_INTERACTIONS].value

        prior_prec = 1/self.prior.var.value
        prior_mean = self.prior.mean.value

        self.var.value = 1/(prior_prec + (len(x)*prec))
        self.mean.value = self.var.value * ((prior_mean * prior_prec) + (np.sum(x)*prec))
        self.sample()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.Normal" href="pylab/variables.html#mdsine2.pylab.variables.Normal">Normal</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.interactions.PriorMeanInteractions.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, value_option, mean_option, var_option, value=None, mean=None, var=None, delay=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the hyperparameters</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>value_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to set the value. Options:
'zero'
Set to zero
'prior-mean', 'auto'
Set to the mean of the prior
'manual'
Specify with the <code>value</code> parameter</dd>
<dt><strong><code>mean_option</code></strong> :&ensp;<code>str</code></dt>
<dd>How to set the mean of the prior
'zero', 'auto'
Set to zero
'manual'
Set with the <code>mean</code> parameter</dd>
<dt><strong><code>var_option</code></strong> :&ensp;<code>str</code></dt>
<dd>'same-as-aii', 'auto'
Set as the same variance as the self-interactions
'manual'
Set with the <code>var</code> parameter</dd>
<dt><strong><code>value</code></strong>, <strong><code>mean</code></strong>, <strong><code>var</code></strong> :&ensp;<code>float</code></dt>
<dd>These are only necessary if we specify manual for any of the other
options</dd>
<dt><strong><code>delay</code></strong> :&ensp;<code>int</code></dt>
<dd>How much to delay the start of the update during inference</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, value_option, mean_option, var_option, value=None, 
    mean=None, var=None, delay=0):
    &#39;&#39;&#39;Initialize the hyperparameters

    Parameters
    ----------
    value_option : str
        How to set the value. Options:
            &#39;zero&#39;
                Set to zero
            &#39;prior-mean&#39;, &#39;auto&#39;
                Set to the mean of the prior
            &#39;manual&#39;
                Specify with the `value` parameter
    mean_option : str
        How to set the mean of the prior
            &#39;zero&#39;, &#39;auto&#39;
                Set to zero
            &#39;manual&#39;
                Set with the `mean` parameter
    var_option : str
        &#39;same-as-aii&#39;, &#39;auto&#39;
            Set as the same variance as the self-interactions
        &#39;manual&#39;
            Set with the `var` parameter
    value, mean, var : float
        These are only necessary if we specify manual for any of the other 
        options
    delay : int
        How much to delay the start of the update during inference
    &#39;&#39;&#39;
    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    self.delay = delay

    # Set the mean
    if not pl.isstr(mean_option):
        raise TypeError(&#39;`mean_option` ({}) must be a str&#39;.format(type(mean_option)))
    if mean_option == &#39;manual&#39;:
        if not pl.isnumeric(mean):
            raise TypeError(&#39;`mean` ({}) must be a numeric&#39;.format(type(mean)))
    elif mean_option in [&#39;zero&#39;, &#39;auto&#39;]:
        mean = 0
    else:
        raise ValueError(&#39;`mean_option` ({}) not recognized&#39;.format(mean_option))
    self.prior.mean.override_value(mean)

    # Set the variance
    if not pl.isstr(var_option):
        raise TypeError(&#39;`var_option` ({}) must be a str&#39;.format(type(var_option)))
    if var_option == &#39;manual&#39;:
        if not pl.isnumeric(var):
            raise TypeError(&#39;`var` ({}) must be a numeric&#39;.format(type(var)))
        if var &lt;= 0:
            raise ValueError(&#39;`var` ({}) must be positive&#39;.format(var))
    elif var_option in [&#39;same-as-aii&#39;, &#39;auto&#39;]:
        var = self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].value
    else:
        raise ValueError(&#39;`var_option` ({}) not recognized&#39;.format(var_option))
    self.prior.var.override_value(var)

    # Set the value
    if not pl.isstr(value_option):
        raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
    if value_option == &#39;manual&#39;:
        if not pl.isnumeric(value):
            raise TypeError(&#39;`value` ({}) must be a numeric&#39;.format(type(value)))
    elif value_option in [&#39;prior-mean&#39;, &#39;auto&#39;]:
        value = self.prior.mean.value
    elif value_option == &#39;zero&#39;:
        value = 0
    else:
        raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))
    self.value = value</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.PriorMeanInteractions.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Update using Gibbs sampling</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#39;&#39;&#39;Update using Gibbs sampling
    &#39;&#39;&#39;
    if self.sample_iter &lt; self.delay:
        return

    if self.G[STRNAMES.CLUSTER_INTERACTION_INDICATOR].num_pos_indicators == 0:
        # sample from the prior
        self.value = self.prior.sample()
        return

    x = self.G[STRNAMES.CLUSTER_INTERACTION_VALUE].value
    prec = 1/self.G[STRNAMES.PRIOR_VAR_INTERACTIONS].value

    prior_prec = 1/self.prior.var.value
    prior_mean = self.prior.mean.value

    self.var.value = 1/(prior_prec + (len(x)*prec))
    self.mean.value = self.var.value * ((prior_mean * prior_prec) + (np.sum(x)*prec))
    self.sample()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.Normal" href="pylab/variables.html#mdsine2.pylab.variables.Normal">Normal</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.Normal.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.cdf" href="pylab/variables.html#mdsine2.pylab.variables.Normal.cdf">cdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.logcdf" href="pylab/variables.html#mdsine2.pylab.variables.Normal.logcdf">logcdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.logpdf" href="pylab/variables.html#mdsine2.pylab.variables.Normal.logpdf">logpdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.pdf" href="pylab/variables.html#mdsine2.pylab.variables.Normal.pdf">pdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.sample" href="pylab/variables.html#mdsine2.pylab.variables.Normal.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.Normal.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="mdsine2.interactions.PriorVarInteractions"><code class="flex name class">
<span>class <span class="ident">PriorVarInteractions</span></span>
<span>(</span><span>prior, value=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the posterior of the prior variance of regression coefficients
for the interaction (off diagonal) variables</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PriorVarInteractions(pl.variables.SICS):
    &#39;&#39;&#39;This is the posterior of the prior variance of regression coefficients
    for the interaction (off diagonal) variables
    &#39;&#39;&#39;
    def __init__(self, prior, value=None, **kwargs):

        kwargs[&#39;name&#39;] = STRNAMES.PRIOR_VAR_INTERACTIONS
        pl.variables.SICS.__init__(self, value=value,
            dtype=float, **kwargs)
        self.add_prior(prior)

    def initialize(self, value_option, dof_option, scale_option, value=None,
        mean_scaling_factor=None, dof=None, scale=None, delay=0):
        &#39;&#39;&#39;Initialize the hyperparameters of the self interaction variance based on the
        passed in option

        Parameters
        ----------
        value_option : str
            - Initialize the value based on the specified option
            - Options
                - &#39;manual&#39;
                    - Set the value manually, `value` must also be specified
                - &#39;auto&#39;, &#39;prior-mean&#39;
                    - Set the value to the mean of the prior
        scale_option : str
            - Initialize the scale of the prior
            - Options
                - &#39;manual&#39;
                    - Set the value manually, `scale` must also be specified
                - &#39;auto&#39;, &#39;same-as-aii&#39;
                    - Set the mean the same as the self-interactions
        dof_option : str
            Initialize the dof of the parameter
            Options:
                &#39;manual&#39;: Set the value with the parameter `dof`
                &#39;diffuse&#39;: Set the value to 2.01
                &#39;strong&#39;: Set the valuye to the expected number of interactions
                &#39;auto&#39;: Set to diffuse
        dof, scale : int, float
            - User specified values
            - Only necessary if `hyperparam_option` == &#39;manual&#39;
        &#39;&#39;&#39;
        if not pl.isint(delay):
            raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
        if delay &lt; 0:
            raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
        self.delay = delay

        self.interactions = self.G[STRNAMES.CLUSTER_INTERACTION_VALUE]

        if not pl.isstr(dof_option):
            raise TypeError(&#39;`dof_option` ({}) must be a str&#39;.format(type(dof_option)))
        if dof_option == &#39;manual&#39;:
            if not pl.isnumeric(dof):
                raise TypeError(&#39;`dof` ({}) must be a numeric&#39;.format(type(dof)))
            if dof &lt; 0:
                raise ValueError(&#39;`dof` ({}) must be &gt; 0 for it to be a valid prior&#39;.format(dof))
        elif dof_option in [&#39;diffuse&#39;, &#39;auto&#39;]:
            dof = 2.01
        elif dof_option == &#39;strong&#39;:
            N = expected_n_clusters(G=self.G)
            dof = N * (N - 1)
        else:
            raise ValueError(&#39;`dof_option` ({}) not recognized&#39;.format(dof_option))
        self.prior.dof.override_value(dof)

        if not pl.isstr(scale_option):
            raise TypeError(&#39;`scale_option` ({}) must be a str&#39;.format(type(scale_option)))
        if scale_option == &#39;manual&#39;:
            if not pl.isnumeric(scale):
                raise TypeError(&#39;`scale` ({}) must be a numeric&#39;.format(type(scale)))
            if scale &lt; 0:
                raise ValueError(&#39;`scale` ({}) must be &gt; 0 for it to be a valid prior&#39;.format(scale))
        elif scale_option in [&#39;auto&#39;, &#39;same-as-aii&#39;]:
            mean = self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].prior.mean()
            scale = mean * (self.prior.dof.value - 2) /(self.prior.dof.value)
        else:
            raise ValueError(&#39;`scale_option` ({}) not recognized&#39;.format(scale_option))
        self.prior.scale.override_value(scale)

        if not pl.isstr(value_option):
            raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
        if value_option == &#39;manual&#39;:
            if not pl.isnumeric(value):
                raise ValueError(&#39;`value` ({}) must be numeric (float,int)&#39;.format(value.__class__))
            self.value = value
        elif value_option in [&#39;auto&#39;, &#39;prior-mean&#39;]:
            if not pl.isnumeric(mean_scaling_factor):
                raise ValueError(&#39;`mean_scaling_factor` ({}) must be a numeric type &#39; \
                    &#39;(float,int)&#39;.format(mean_scaling_factor.__class__))
            self.value = self.prior.mean()
        else:
            raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

        logging.info(&#39;Prior Variance Interactions initialization results:\n&#39; \
            &#39;\tprior dof: {}\n&#39; \
            &#39;\tprior scale: {}\n&#39; \
            &#39;\tvalue: {}&#39;.format(
                self.prior.dof.value, self.prior.scale.value, self.value))

    # @profile
    def update(self):
        &#39;&#39;&#39;Calculate the posterior of the prior variance
        &#39;&#39;&#39;
        if self.sample_iter &lt; self.delay:
            return

        x = self.interactions.obj.get_values(use_indicators=True)
        mu = self.G[STRNAMES.PRIOR_MEAN_INTERACTIONS].value

        se = np.sum(np.square(x - mu))
        n = len(x)

        self.dof.value = self.prior.dof.value + n
        self.scale.value = ((self.prior.scale.value * self.prior.dof.value) + \
           se)/self.dof.value
        self.sample()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mdsine2.pylab.variables.SICS" href="pylab/variables.html#mdsine2.pylab.variables.SICS">SICS</a></li>
<li><a title="mdsine2.pylab.variables.Variable" href="pylab/variables.html#mdsine2.pylab.variables.Variable">Variable</a></li>
<li><a title="mdsine2.pylab.graph.Node" href="pylab/graph.html#mdsine2.pylab.graph.Node">Node</a></li>
<li><a title="mdsine2.pylab.graph.BaseNode" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode">BaseNode</a></li>
<li><a title="mdsine2.pylab.base.Saveable" href="pylab/base.html#mdsine2.pylab.base.Saveable">Saveable</a></li>
<li>mdsine2.pylab.variables._BaseArithmeticClass</li>
<li><a title="mdsine2.pylab.base.Traceable" href="pylab/base.html#mdsine2.pylab.base.Traceable">Traceable</a></li>
<li>mdsine2.pylab.variables._RandomBase</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mdsine2.interactions.PriorVarInteractions.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, value_option, dof_option, scale_option, value=None, mean_scaling_factor=None, dof=None, scale=None, delay=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the hyperparameters of the self interaction variance based on the
passed in option</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>value_option</code></strong> :&ensp;<code>str</code></dt>
<dd>
<ul>
<li>Initialize the value based on the specified option</li>
<li>Options<ul>
<li>'manual'<ul>
<li>Set the value manually, <code>value</code> must also be specified</li>
</ul>
</li>
<li>'auto', 'prior-mean'<ul>
<li>Set the value to the mean of the prior</li>
</ul>
</li>
</ul>
</li>
</ul>
</dd>
<dt><strong><code>scale_option</code></strong> :&ensp;<code>str</code></dt>
<dd>
<ul>
<li>Initialize the scale of the prior</li>
<li>Options<ul>
<li>'manual'<ul>
<li>Set the value manually, <code>scale</code> must also be specified</li>
</ul>
</li>
<li>'auto', 'same-as-aii'<ul>
<li>Set the mean the same as the self-interactions</li>
</ul>
</li>
</ul>
</li>
</ul>
</dd>
<dt><strong><code>dof_option</code></strong> :&ensp;<code>str</code></dt>
<dd>Initialize the dof of the parameter
Options:
'manual': Set the value with the parameter <code>dof</code>
'diffuse': Set the value to 2.01
'strong': Set the valuye to the expected number of interactions
'auto': Set to diffuse</dd>
<dt><strong><code>dof</code></strong>, <strong><code>scale</code></strong> :&ensp;<code>int, float</code></dt>
<dd>
<ul>
<li>User specified values</li>
<li>Only necessary if <code>hyperparam_option</code> == 'manual'</li>
</ul>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize(self, value_option, dof_option, scale_option, value=None,
    mean_scaling_factor=None, dof=None, scale=None, delay=0):
    &#39;&#39;&#39;Initialize the hyperparameters of the self interaction variance based on the
    passed in option

    Parameters
    ----------
    value_option : str
        - Initialize the value based on the specified option
        - Options
            - &#39;manual&#39;
                - Set the value manually, `value` must also be specified
            - &#39;auto&#39;, &#39;prior-mean&#39;
                - Set the value to the mean of the prior
    scale_option : str
        - Initialize the scale of the prior
        - Options
            - &#39;manual&#39;
                - Set the value manually, `scale` must also be specified
            - &#39;auto&#39;, &#39;same-as-aii&#39;
                - Set the mean the same as the self-interactions
    dof_option : str
        Initialize the dof of the parameter
        Options:
            &#39;manual&#39;: Set the value with the parameter `dof`
            &#39;diffuse&#39;: Set the value to 2.01
            &#39;strong&#39;: Set the valuye to the expected number of interactions
            &#39;auto&#39;: Set to diffuse
    dof, scale : int, float
        - User specified values
        - Only necessary if `hyperparam_option` == &#39;manual&#39;
    &#39;&#39;&#39;
    if not pl.isint(delay):
        raise TypeError(&#39;`delay` ({}) must be an int&#39;.format(type(delay)))
    if delay &lt; 0:
        raise ValueError(&#39;`delay` ({}) must be &gt;= 0&#39;.format(delay))
    self.delay = delay

    self.interactions = self.G[STRNAMES.CLUSTER_INTERACTION_VALUE]

    if not pl.isstr(dof_option):
        raise TypeError(&#39;`dof_option` ({}) must be a str&#39;.format(type(dof_option)))
    if dof_option == &#39;manual&#39;:
        if not pl.isnumeric(dof):
            raise TypeError(&#39;`dof` ({}) must be a numeric&#39;.format(type(dof)))
        if dof &lt; 0:
            raise ValueError(&#39;`dof` ({}) must be &gt; 0 for it to be a valid prior&#39;.format(dof))
    elif dof_option in [&#39;diffuse&#39;, &#39;auto&#39;]:
        dof = 2.01
    elif dof_option == &#39;strong&#39;:
        N = expected_n_clusters(G=self.G)
        dof = N * (N - 1)
    else:
        raise ValueError(&#39;`dof_option` ({}) not recognized&#39;.format(dof_option))
    self.prior.dof.override_value(dof)

    if not pl.isstr(scale_option):
        raise TypeError(&#39;`scale_option` ({}) must be a str&#39;.format(type(scale_option)))
    if scale_option == &#39;manual&#39;:
        if not pl.isnumeric(scale):
            raise TypeError(&#39;`scale` ({}) must be a numeric&#39;.format(type(scale)))
        if scale &lt; 0:
            raise ValueError(&#39;`scale` ({}) must be &gt; 0 for it to be a valid prior&#39;.format(scale))
    elif scale_option in [&#39;auto&#39;, &#39;same-as-aii&#39;]:
        mean = self.G[STRNAMES.PRIOR_VAR_SELF_INTERACTIONS].prior.mean()
        scale = mean * (self.prior.dof.value - 2) /(self.prior.dof.value)
    else:
        raise ValueError(&#39;`scale_option` ({}) not recognized&#39;.format(scale_option))
    self.prior.scale.override_value(scale)

    if not pl.isstr(value_option):
        raise TypeError(&#39;`value_option` ({}) must be a str&#39;.format(type(value_option)))
    if value_option == &#39;manual&#39;:
        if not pl.isnumeric(value):
            raise ValueError(&#39;`value` ({}) must be numeric (float,int)&#39;.format(value.__class__))
        self.value = value
    elif value_option in [&#39;auto&#39;, &#39;prior-mean&#39;]:
        if not pl.isnumeric(mean_scaling_factor):
            raise ValueError(&#39;`mean_scaling_factor` ({}) must be a numeric type &#39; \
                &#39;(float,int)&#39;.format(mean_scaling_factor.__class__))
        self.value = self.prior.mean()
    else:
        raise ValueError(&#39;`value_option` ({}) not recognized&#39;.format(value_option))

    logging.info(&#39;Prior Variance Interactions initialization results:\n&#39; \
        &#39;\tprior dof: {}\n&#39; \
        &#39;\tprior scale: {}\n&#39; \
        &#39;\tvalue: {}&#39;.format(
            self.prior.dof.value, self.prior.scale.value, self.value))</code></pre>
</details>
</dd>
<dt id="mdsine2.interactions.PriorVarInteractions.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the posterior of the prior variance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self):
    &#39;&#39;&#39;Calculate the posterior of the prior variance
    &#39;&#39;&#39;
    if self.sample_iter &lt; self.delay:
        return

    x = self.interactions.obj.get_values(use_indicators=True)
    mu = self.G[STRNAMES.PRIOR_MEAN_INTERACTIONS].value

    se = np.sum(np.square(x - mu))
    n = len(x)

    self.dof.value = self.prior.dof.value + n
    self.scale.value = ((self.prior.scale.value * self.prior.dof.value) + \
       se)/self.dof.value
    self.sample()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="mdsine2.pylab.variables.SICS" href="pylab/variables.html#mdsine2.pylab.variables.SICS">SICS</a></b></code>:
<ul class="hlist">
<li><code><a title="mdsine2.pylab.variables.SICS.T" href="pylab/variables.html#mdsine2.pylab.variables.Variable.T">T</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_child" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_child">add_child</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_init_value" href="pylab/variables.html#mdsine2.pylab.variables.Variable.add_init_value">add_init_value</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_parent" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_parent">add_parent</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_prior" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_prior">add_prior</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.add_trace">add_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.add_undirected" href="pylab/graph.html#mdsine2.pylab.graph.Node.add_undirected">add_undirected</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.degree" href="pylab/graph.html#mdsine2.pylab.graph.Node.degree">degree</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.delete" href="pylab/graph.html#mdsine2.pylab.graph.BaseNode.delete">delete</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.get_adjacent_keys" href="pylab/graph.html#mdsine2.pylab.graph.Node.get_adjacent_keys">get_adjacent_keys</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.get_iter" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_iter">get_iter</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.get_trace_from_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.get_trace_from_disk">get_trace_from_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.load" href="pylab/base.html#mdsine2.pylab.base.Saveable.load">load</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.logpdf" href="pylab/variables.html#mdsine2.pylab.variables.SICS.logpdf">logpdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.metropolis" href="pylab/graph.html#mdsine2.pylab.graph.Node.metropolis">metropolis</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.overwrite_entire_trace_on_disk" href="pylab/base.html#mdsine2.pylab.base.Traceable.overwrite_entire_trace_on_disk">overwrite_entire_trace_on_disk</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.pdf" href="pylab/variables.html#mdsine2.pylab.variables.SICS.pdf">pdf</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.sample" href="pylab/variables.html#mdsine2.pylab.variables.SICS.sample">sample</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.save" href="pylab/base.html#mdsine2.pylab.base.Saveable.save">save</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.set_save_location" href="pylab/base.html#mdsine2.pylab.base.Saveable.set_save_location">set_save_location</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.set_trace" href="pylab/base.html#mdsine2.pylab.base.Traceable.set_trace">set_trace</a></code></li>
<li><code><a title="mdsine2.pylab.variables.SICS.set_value_shape" href="pylab/variables.html#mdsine2.pylab.variables.Variable.set_value_shape">set_value_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="mdsine2" href="index.html">mdsine2</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="mdsine2.interactions.ClusterInteractionIndicatorProbability" href="#mdsine2.interactions.ClusterInteractionIndicatorProbability">ClusterInteractionIndicatorProbability</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicatorProbability.initialize" href="#mdsine2.interactions.ClusterInteractionIndicatorProbability.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicatorProbability.update" href="#mdsine2.interactions.ClusterInteractionIndicatorProbability.update">update</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.interactions.ClusterInteractionIndicators" href="#mdsine2.interactions.ClusterInteractionIndicators">ClusterInteractionIndicators</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.calculate_marginal_loglikelihood" href="#mdsine2.interactions.ClusterInteractionIndicators.calculate_marginal_loglikelihood">calculate_marginal_loglikelihood</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.calculate_relative_marginal_loglikelihood" href="#mdsine2.interactions.ClusterInteractionIndicators.calculate_relative_marginal_loglikelihood">calculate_relative_marginal_loglikelihood</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.initialize" href="#mdsine2.interactions.ClusterInteractionIndicators.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.kill" href="#mdsine2.interactions.ClusterInteractionIndicators.kill">kill</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.make_rel_params" href="#mdsine2.interactions.ClusterInteractionIndicators.make_rel_params">make_rel_params</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.update_cnt_indicators" href="#mdsine2.interactions.ClusterInteractionIndicators.update_cnt_indicators">update_cnt_indicators</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.update_direct" href="#mdsine2.interactions.ClusterInteractionIndicators.update_direct">update_direct</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.update_relative" href="#mdsine2.interactions.ClusterInteractionIndicators.update_relative">update_relative</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.update_single_idx_fast" href="#mdsine2.interactions.ClusterInteractionIndicators.update_single_idx_fast">update_single_idx_fast</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionIndicators.update_single_idx_slow" href="#mdsine2.interactions.ClusterInteractionIndicators.update_single_idx_slow">update_single_idx_slow</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.interactions.ClusterInteractionValue" href="#mdsine2.interactions.ClusterInteractionValue">ClusterInteractionValue</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.interactions.ClusterInteractionValue.initialize" href="#mdsine2.interactions.ClusterInteractionValue.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionValue.set_values" href="#mdsine2.interactions.ClusterInteractionValue.set_values">set_values</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionValue.update" href="#mdsine2.interactions.ClusterInteractionValue.update">update</a></code></li>
<li><code><a title="mdsine2.interactions.ClusterInteractionValue.update_str" href="#mdsine2.interactions.ClusterInteractionValue.update_str">update_str</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.interactions.PriorMeanInteractions" href="#mdsine2.interactions.PriorMeanInteractions">PriorMeanInteractions</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.interactions.PriorMeanInteractions.initialize" href="#mdsine2.interactions.PriorMeanInteractions.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.interactions.PriorMeanInteractions.update" href="#mdsine2.interactions.PriorMeanInteractions.update">update</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="mdsine2.interactions.PriorVarInteractions" href="#mdsine2.interactions.PriorVarInteractions">PriorVarInteractions</a></code></h4>
<ul class="">
<li><code><a title="mdsine2.interactions.PriorVarInteractions.initialize" href="#mdsine2.interactions.PriorVarInteractions.initialize">initialize</a></code></li>
<li><code><a title="mdsine2.interactions.PriorVarInteractions.update" href="#mdsine2.interactions.PriorVarInteractions.update">update</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>